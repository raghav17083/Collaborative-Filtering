More details of this reordering approach are described in (Kanthak et al. , 2005). 
But, the number of permutations examined can be reduced by using heuristic forward pruning or by constraining the permutations to be within a local window of adjustable size (also see (Kanthak et al. , 2005)). 
A few exceptions are the hierarchical (possibly syntax-based) transduction models (Wu, 1997; Alshawi et al. , 1998; Yamada and Knight, 2001; Chiang, 2005) and the string transduction models (Kanthak et al. , 2005). 
Then, we introduce reorderings into this graph as described in (Kanthak et al. , 2005). 
While decoding by composition simply resembles the principle of memoization (i.e. here: all state hypotheses of a whole sentence are kept in memory), it is necessary to either use heuristic forward pruning or constrain permutations to be within a local window of adjustable size (also see (Kanthak et al. , 2005)). 
