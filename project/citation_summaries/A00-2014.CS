The speech data for the training set is used for building the acoustic model; whereas, the parse trees for the training set are generated following the policy that if the context-free grammar constituent bracketing can be found in the WSJ PTB, it becomes the parse tree for the training sentence; otherwise, we use the corresponding tree in the BLLIP treebank (Charniak et al. , 2000). 
Representing each multiplicand in Equation (3) as the conditional probability ^ P(xjy 1 ;y 2 ;:::;y n )wherey 1 ;y 2 ;:::;y n belong to a mixed set of words and SuperARVs, the recursive linear interpolation is calculated as follows: 1 We have annotated a moderate-sized corpus, DARPA Naval Resource Management (Price et al. , 1988), with CDG parse relations as reported in (Harper et al. , 2000; Harper and Wang, 2001). 
In order to derive the constraints directly from CDG annotated sentences, we have developed an algorithm to extract grammar relations using information derived directly from annotated sentences (Harper et al. , 2000; Harper and Wang, 2001). 
Currently, we calculate the weight depending on the temporal distance as follows: )(] 2000 )( exp[)( in in tt tt tt g in   = (2) Equation (2) indicates that at a given time t n (measured in milliseconds), the closer a gesture (at t i ) is to the time t n, the higher impact this gesture has on the salience distribution (Chai et al. , 2004b). 
Although wordbased LMs (with bigram and trigram being the most common) remain the mainstay in many continuous speech recognition systems, recent e orts have explored a variety of ways to improve LM performance (Niesler and Woodland, 1996; Chelba et al. , 1997; Srinivas, 1997; Heeman, 1998; Chelba, 2000; Rosenfeld, 2000; Goodman, 2001; Roark, 2001; Charniak, 2001). 
