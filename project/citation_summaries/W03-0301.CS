This years shared task follows on the success of the previous word alignment evaluation that was organized during the HLT/NAACL 2003 workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond (Mihalcea and Pedersen, 2003). 
The alignments produced by MEBA were compared to the ones produced by YAWA and evaluated against the Gold Standard (GS)1 annotations used in the Word Alignment Shared Tasks (Romanian-English track) organized at HLT-NAACL2003 (Mihalcea and Pedersen 2003). 
HLT-03 best is Ralign.EF.1 (Mihalcea and Pedersen, 2003). 
This data set was used for the 2003 NAACL shared task (Mihalcea and Pedersen, 2003), where the word-aligned sentences weresplitintoa37sentencetrialsetanda447sentence testing set. 
5 Data and Methodology for Evaluation We evaluated our models using data from the bilingual word alignment workshop held at HLT-NAACL 2003 (Mihalcea and Pedersen, 2003). 
