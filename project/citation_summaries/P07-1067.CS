Besides the common practice of employing a thesaurus (e.g. WordNet) in semantic consistency checking, much research has been done to explore various kinds of semantic information, such as semantic similarity (Harabagiu et al 2000), semantic compatibility (Yang et al 2005, 2007), and semantic class information (Soon et al 2001; Ng 2007). 
For example, Yang et al (2005) proposed a template-based statistical approach to compute the semantic compatibility between a pronominal anaphor and an antecedent candidate, and Yang and Su (2007) explored semantic relatedness information from automatically discovered patterns, while Ng (2007) automatically induced semantic class knowledge from a treebank and explored its application in coreference resolution. 
We accordingly introduce approaches which attempt to include semantic information into the coreference models from a variety of knowledge sources, e.g. WordNet (Harabagiu et al., 2001), Wikipedia (Ponzetto & Strube, 2006) and automatically harvested patterns (Poesio et al., 2002; Markert & Nissim, 2005; Yang & Su, 2007). 
2 Baseline Coreference Resolution System Our baseline coreference system implements the standard machine learning approach to coreference resolution (see Ng and Cardie (2002b), Ponzetto and Strube (2006), Yang and Su (2007), for instance), which consists of probabilistic classification and clustering, as described below. 
Bootstrapping was initially proposed by Riloff and Jones (1999), and has since been successfully applied to extracting general semantic lexicons (Riloff and Jones, 1999; Thelen and Riloff, 2002), biomedical entities (Yu and Agichtein, 2003), facts (Pasca et al., 2006), and coreference data (Yang and Su, 2007). 
