# -*- coding: utf-8 -*-
"""KernelKmeans.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1putl7JYI7b0yBfVW0fapvt9aIyjraveS
"""

import pandas as pd
import numpy as np
import pickle
from tqdm import tqdm
from sklearn.model_selection import KFold
from sklearn.metrics import pairwise_distances
from collections import Counter
from sklearn.model_selection import KFold
from sklearn import preprocessing 
from scipy.spatial import distance
import math
from sklearn import preprocessing
from Kernel_K_Means import Kernel_K_Means
from paper_class import paper


papers={}

with open("datasets_inUse/paper_ids.txt","r", encoding="utf8") as file:
    pid=0
    for i in file.readlines():
        l=i.split()
        # making the entire title sentence
        title=' '.join(l[1:len(l)-1])
        # paper id pid is increasing values of 1 with eveyr loop
        papers[l[0]]=paper(pid, l[0], title, l[-1])
        pid+=1


#Number of papers in total
nop=len(papers)

""""Paper Citation matrix"""

def paper_citation_matrix():
    with open("datasets_inUse/paper-citation-network-nonself.txt",'r') as file:
        matrix=np.zeros((nop,nop))
        for i in tqdm(file.readlines()):
            l=i.split()
            #print(papers[l[0]].pid," " , papers[l[2]].pid," -------------------")
            matrix[papers[l[0]].pid,papers[l[2]].pid]=1
    return matrix






matrix=paper_citation_matrix()
print(matrix.shape)
data=pd.DataFrame(matrix)
print(data.shape)

def calculate(trainData,testingData,distanceMeasure, kernel, n_clusters):   
        km = Kernel_K_Means(n_clusters, kernel, max_iter=100, random_state=0, verbose=1)
        clusterTrain = km.fit(data)
        TrainingClusters=clusterTrain.labels_
        clusteringTest = km.fit_predict(testingData)
        return TrainingClusters ,clusteringTest

#Making Testing Data
POI_ID = "P12-1041"
POI_INDEX = papers[POI_ID].pid

testingData = data.iloc[POI_INDEX]
testingData.drop(POI_INDEX, inplace=True)

#Making Training Data
data.drop(POI_INDEX, axis=0, inplace=False)
data.drop(POI_INDEX, axis=1, inplace=True)

kernelList = ['linear','rbf','polynomial','laplacian','sigmoid','cosine']

for kernel in kernelList : 
  AllotedClustersTraining,AllotedCluster = calculate(data,testingData,distanceMeasure='euclidean', kernel=kernel, n_clusters=10)   
  clusterArray = []
  for i in range(len(AllotedClustersTraining)):
      if(AllotedClustersTraining[i]==AllotedCluster):
          clusterArray.append(i)


  distanceMeasure = 'euclidean'
  distanceArray = {}
  for i in range(len(clusterArray)):
      trainingclusterCitations = trainingData.iloc[clusterArray[i]].values.reshape(1,-1)
      d = distance.cdist(trainingclusterCitations, testingData, distanceMeasure)
      distanceArray[clusterArray[i]] = d[0][0]
      
  dict(sorted(distanceArray.items(), key=lambda item: item[1]))

  #Finding Recommendations 
  print("Recommendations using Kernel : ", kernel)
  print("Index of paper of Interest- ", POI_INDEX)
  print("Papers Recommended for Paper ID- ", POI_ID)
  print("Title- " , papers[POI_ID].title)
  topKPapers = 5
  for i in range(topKPapers):
      pid = list(distanceArray.keys())[i]
      for j in papers:
          if(papers[j].pid==pid):
              print(i+1, ". ", papers[j].title , " " , j)
