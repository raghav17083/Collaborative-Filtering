There are only two previous papers we are aware of that induce labeled bracketing and evaluate on corpora annotated with a similar representation (Haghighi and Klein, 2006; Borensztajn and Zuidema, 2007). 
The BMM model used here (Borensztajn and Zuidema, 2007) combines features of (Petasis et al., 2004) and Stolckes algorithm, applying the minimum description length (MDL) principle. 
These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. 
We then induce initial labels using a Bayesian Model Merging (BMM) labeling algorithm (Borensztajn and Zuidema, 2007), which aims at minimizing the description length of the input data and the induced grammar. 
To do that we modify the Bayesian Model Merging (BMM) algorithm of (Borensztajn and Zuidema, 2007), which induces context-free grammars (bracketing and labeling) from POS tags, combining features of the models of (Stolcke and Omohundro, 1994) and (Petasis et al., 2004). 
