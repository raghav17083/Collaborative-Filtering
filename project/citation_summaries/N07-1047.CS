D08-1113:1	303:310	We would like to use features that look at wide context on the input side, which is inexpensive (Jiampojamarn et al., 2007).
---------------------------------------------------
P08-1065:2	224:264	To explore this, we tested our model in conjunction with a recent L2P system that has been shown to predict phonemes with state-of-the-art word accuracy (Jiampojamarn et al., 2007).
---------------------------------------------------
P09-1014:3	219:284	Like other recent L2P systems (Bisani and Ney, 2002; Marchand and Damper, 2007; Jiampojamarn et al., 2007), this approach does not generate stress, nor does it consider stress when it generates phonemes.
---------------------------------------------------
N09-3016:4	49:150	The recent work of Jiampojamarn et al (2007) combinesbothoftheaboveapproachesinaveryinteresting manner.
---------------------------------------------------
N09-3016:5	87:150	Figure 1 shows the alignments induced by GIZA++ for the example words which are mentioned by Jiampojamarn et al (2007).
---------------------------------------------------
N09-3016:6	35:150	But recent work (Bisani and Ney, 2002; Jiampojamarn et al., 2007) shows that multiple letter-to-phoneme alignments perform better than single letter to phoneme alignments.
---------------------------------------------------
N09-3016:7	124:150	1-1Align,M-Malign,HMM:one-one alignments, many-many alignments, HMM with local prediction (Jiampojamarn et al., 2007).
---------------------------------------------------
N09-3016:8	17:150	Recent work uses many-to-many correspondences (Jiampojamarn et al., 2007) and reports signicantly higher accuracy for Dutch, German and French.
---------------------------------------------------
P08-1103:9	176:209	2Perfect with respect to our many-to-many alignment (Jiampojamarn et al., 2007), but not necessarily in any linguistic sense.
---------------------------------------------------
P08-1103:10	186:209	With the exception of the system described in (Jiampojamarn et al., 2007), which we re-ran on our current test sets, the results of other systems are taken from the original papers.
---------------------------------------------------
P08-1103:11	192:209	M-M HMM: Many-to-Many HMM system (Jiampojamarn et al., 2007).
---------------------------------------------------
P08-1103:12	94:209	In the pipeline approach (Figure 1b), the input word is segmented into letter substrings by an instance-based classifier (Aha et al., 1991), which learns a letter segmentation model from many-tomany alignments (Jiampojamarn et al., 2007).
---------------------------------------------------
P08-1103:13	40:209	The second hybrid approach (Jiampojamarn et al., 2007) also extends instance-based classification.
---------------------------------------------------
P08-1103:14	28:209	Originally, L2P systems assumed one-to-one alignment (Black et al., 1998; Damper et al., 2005), but recently many-to-many alignment has been shown to perform better (Bisani and Ney, 2002; Jiampojamarn et al., 2007).
---------------------------------------------------
D09-1111:15	92:259	Previously, this has been done using an EM-learned edit distance (Ristad and Yianilos, 1998), or generalizations thereof (Brill and Moore, 2000; Jiampojamarn et al., 2007).
---------------------------------------------------
