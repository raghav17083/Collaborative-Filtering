(Reichart et al., 2008) introduces multi-task active learning where unlabeled data require annotations for multiple tasks, e.g. they consider namedentities and parse trees, and showed that multiple tasks helps selection compared to individual tasks. 
This setting is similar to the multi-task AL scenario (Reichart et al., 2008). 
is the ranking of a sentence in the list for the dth translation task (Reichart et al., 2008). 
Starting from a random initial value for ks, we improve one dimension at a time and traverse the discrete grid 2To see how different rankings can be combined, see (Reichart et al., 2008) which proposes this for multi-task AL. 3Here the retrained SMT model is the one learned by adding a particular sentence from dev1 into L. placed on the values of the weight vector. 
Examples include base noun phrase chunking (Ngai, 2000), named entity recognition (Tomanek et al., 2007) and multitask annotation (Reichart et al., 2008). 
