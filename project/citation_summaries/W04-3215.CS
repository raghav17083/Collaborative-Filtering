Even robust parsers using linguistically sophisticated formalisms, such as TAG (Chiang, 2000), CCG (Clark and Curran, 2004b; Hockenmaier, 2003), HPSG (Miyao et al. , 2004) and LFG (Riezler et al. , 2002; Cahill et al. , 2004), often use training data derived from the Penn Treebank. 
Recently more techniques for answer extraction, answer selection, and answer validation have been proposed (Lita et al. , 2004; Soricut and Brill, 2004; Clark et al. , 2004). 
Clark and Curran (2004b) describes the training procedure for the dependency model, which uses a discriminativeestimationmethodbymaximisingthe conditional likelihood of the model given the data (Riezler et al. , 2002). 
1 Motivation Question Answering has emerged as a key area in natural language processing (NLP) to apply question parsing, information extraction, summarization, and language generation techniques (Clark et al. , 2004; Fleischman et al. , 2003; Echihabi et al. , 2003; Yang et al. , 2003; Hermjakob et al. , 2002; Dumais et al. , 2002). 
Our partial training regime only requires sentences to be annotated with lexical categories, rather than full parse trees; therefore the data can be produced much more quickly for a new domain or language (Clark et al. , 2004). 
