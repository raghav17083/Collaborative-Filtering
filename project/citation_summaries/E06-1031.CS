P07-1111:1	29:176	In addition to the well-known word error rate (WER), more sophisticated modifications have been proposed (Tillmann et al. , 1997; Snover et al. , 2006; Leusch et al. , 2006).
---------------------------------------------------
W06-3112:2	31:135	Others try to accommodate both syntactic and lexical differences between the candidate translation and the reference, like CDER (Leusch et al. , 2006), which employs a version of edit distance for word substitution and reordering; METEOR (Banerjee and Lavie, 2005), which uses stemming and WordNet synonymy; and a linear regression model developed by (Russo-Lassner et al. , 2005), which makes use of stemming, WordNet synonymy, verb class synonymy, matching noun phrase heads, and proper name matching.
---------------------------------------------------
P08-3005:3	9:160	Although the automatic evaluation metrics have succeeded in the system level, there are still on-going investigations to get reference translation better (Russo-Lassner et al., 2005) or to deal with sub-document level evaluation (Kulesza et al., 2004; Leusch et al, 2006).
---------------------------------------------------
W07-0411:4	57:166	Others try to accommodate both syntactic and lexical differences between the candidate translation and the reference, like CDER (Leusch et al. , 2006), which employs a version of edit distance for word substitution and reordering; or METEOR (Banerjee and Lavie, 2005), which uses stemming and WordNet synonymy.
---------------------------------------------------
D07-1007:5	174:218	In addition to the widely used BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002) scores, we also evaluate translation quality with the recently proposed Meteor (Banerjee and Lavie, 2005) and four edit-distance style metrics, Word Error Rate (WER), Positionindependent word Error Rate (PER) (Tillmann et al. , 1997), CDER, which allows block reordering (Leusch et al. , 2006), and Translation Edit Rate (TER) (Snover et al. , 2006).
---------------------------------------------------
W07-0707:6	29:251	The CDER measure (Leusch et al. , 2006) is based on edit distance, such as the well-known WER, but allows reordering of blocks.
---------------------------------------------------
W08-0312:7	11:85	Meteor , as well as several other proposed metrics such as GTM (Melamed et al., 2003), TER (Snover et al., 2006) and CDER (Leusch et al., 2006) aim to address some of these weaknesses.
---------------------------------------------------
W07-0714:8	52:140	Others try to accommodate both syntactic and lexical differences between the candidate translation and the reference, like CDER (Leusch et al. , 2006), which employs a version of edit distance for word substitution and reordering; or METEOR (Banerjee and Lavie, 2005), which uses stemming and WordNet synonymy.
---------------------------------------------------
P09-1106:9	183:202	Following (Leusch et al., 2006), we modified the TER script to allow fuzzy matching: change the substitution cost from 1 for any word pair to 946  (,)1 (,) sub ji ji COST e e S e e=              (5) which (,) j i Se e  is the similarity score based on the length of longest matched prefix (LMP) computed as in Equation (4).
---------------------------------------------------
W07-0734:10	13:94	Meteor, as well as several other proposed metrics such as GTM (Melamed et al. , 2003), TER (Snover et al. , 2006) and CDER (Leusch et al. , 2006) aim to address some of these weaknesses.
---------------------------------------------------
