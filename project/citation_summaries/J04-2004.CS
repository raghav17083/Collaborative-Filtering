SFSTs model joint probability distributions; therefore, Equation (1) has to be rewritten as  t= argmax t Pr(s,t)(4) This is the approach followed in GIATI (Casacuberta et al. 2004a; Casacuberta and Vidal 2004), but other models for the joint probability can be adopted. 
Given a nite sample of string pairs, the inference of SFSTs using the GIATI technique is performed as follows (Casacuberta and Vidal 2004; Casacuberta, Vidal, and Pico 2005): i) Building training strings: Each training pair is transformed into a single string from an extended alphabet to obtain a new sample of strings. 
The translation system described in this article implements a translation model that has been derived from the finite-state perspectivemore specifically, from the work of Casacuberta (2001) and Casacuberta and Vidal (2004). 
where:  is a finite set of input symbols (source vocabulary); ???m are m finite sets of output symbols (target vocabularies); Q is a finite set of states; q0 ?Q is the initial state; R?Q?1?mQ is a set of transitions such as (q,w, ?p1,, ?pm,qprime), which is a transition from the state q to the state qprime, with the source symbol w and producing the substrings (?p1,, ?pm); P : R??[0,1] is the transition probability distribution; F : Q??[0,1] is the final state probability distribution; The probability distributions satisfy the stochastic constraint: ?q?Q (1) F(q)+ summationtext w,?p1,,?pm,qprime P(q,w, ?p1,, ?pm,qprime) = 1 2.2 Training the multilingual translation model Both topology and parameters of an SFST can be learned fully automatically from bilingual examples making use of underlying alignment models (Casacuberta and Vidal, 2004). 
In a nutshell, the translation model is implemented as a stochastic finite-state transducer trained using a n-gram model of (source,target) pairs (Casacuberta and Vidal, 2004). 
