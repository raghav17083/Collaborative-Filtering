Additionally, in (Moschitti et al., 2006; Moschitti et al., 2008) a tree kernel was applied to semantic trees similar to the one introduced in the next section to re-rank Semantic Role Labeling annotations. 
Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). 
This choice is justified by previous studies (Moschitti et al. , 2006b) showing that the accuracy of classification is higher for lower nodes;  if only two nodes are involved, i. e. they dominate each other, then keep the one with the highest classification score. 
Such counts are used in our re-ranking function as follows: let ei be the pair angbracketleftbigs1i,s2iangbracketrightbig we evaluate the kernel: KR(e1,e2) = SK(s11,s12) + SK(s21,s22) (3)  SK(s11,s22)SK(s21,s12) This schema, consisting in summing four different kernels, has been already applied in (Collins and Duffy, 2002) for syntactic parsing re-ranking, where the basic kernel was a tree kernel instead of SK and in (Moschitti et al., 2006), where, to rerank Semantic Role Labeling annotations, a tree kernel was used on a semantic tree similar to the one introduced in the next section. 
Concerning the use of kernels for NLP, interesting models and results are described, for example, in (Collins and Duffy, 2002), (Moschitti et al., 2008), (Kudo and Matsumoto, 2003), (Cumby and Roth, 2003), (Shen et al., 2003), (Cancedda et al., 2003), (Culotta and Sorensen, 2004), (Daume III and Marcu, 2004), (Kazama and Torisawa, 2005), (Kudo et al., 2005), (Titov and Henderson, 2006), (Moschitti et al., 2006), (Moschitti and Bejan, 2004) or (Toutanova et al., 2004). 
