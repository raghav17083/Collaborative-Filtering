D08-1056:1	56:319	(Snow et al., 2006; Nakov & Hearst, 2008).
---------------------------------------------------
D08-1056:2	307:319	(2006) and Nakov and Hearst (2008), among others, look at using a large amount of unlabeled data to classify relations between words.
---------------------------------------------------
N09-1059:3	25:202	Nakov and Hearst (2008) solved relational similarity problems using the Web as a corpus.
---------------------------------------------------
N09-1059:4	34:202	(Nakov and Hearst, 2005; Gledson and Keane, 2008)).
---------------------------------------------------
W09-2415:5	145:179	The patterns will be manually constructed following the approach of Hearst (1992) and Nakov and Hearst (2008).6 The example collection for each relation R will be passed to two independent annotators.
---------------------------------------------------
W09-2415:6	48:179	As a first step, SemEval2007 Task 4 offered many useful insights into the performance of different approaches to semantic relation classification; it has also motivated followup research (Davidov and Rappoport, 2008; KatrenkoandAdriaans, 2008; NakovandHearst, 2008; O Seaghdha and Copestake, 2008).
---------------------------------------------------
W09-2415:7	29:179	They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set.
---------------------------------------------------
W09-2416:8	66:115	The SemEval-2010 task we present here builds on thework ofNakov (Nakovand Hearst, 2006; Nakov, 2007; Nakov, 2008b), where NCs are paraphrased by combinations of verbs and prepositions.
---------------------------------------------------
W09-2416:9	72:115	Paraphrasesofthiskind have been shown to be useful in applications such as machine translation (Nakov, 2008a) and as an intermediate step in inventory-based classification of abstract relations (Kim and Baldwin, 2006; Nakov and Hearst, 2008).
---------------------------------------------------
W09-2416:10	100:115	Pearsons correlation coefficient is a standard measure of the correlation strength between two distributions; it can be calculated as follows:  = E(XY ) E(X)E(Y )radicalbigE(X2)  [E(X)]2radicalbigE(Y 2)  [E(Y )]2 (1) where X = (x1,,xn) and Y = (y1,,yn) are vectors of numerical scores for each paraphrase provided by the humans and the competing systems, respectively, n is the number of paraphrases to score, and E(X) is the expectation of X. Cosine correlation coefficient is another popular alternative and was used by Nakov and Hearst (2008); it can be seen as an uncentered version of Pearsons correlation coefficient:  = X.YbardblXbardblbardblYbardbl (2) Spearmans rank correlation coefficient is suitable for comparing rankings of sets of items; it is a special case of Pearsons correlation, derived by considering rank indices (1,2,) as item scores . It is defined as follows:  = n summationtextx iyi  ( summationtextx i)( summationtexty i)radicalBig nsummationtextx2i  (summationtextxi)2 radicalBig nsummationtexty2i  (summationtextyi)2 (3) One problem with using Spearmans rank coefficient for the current task is the assumption that swapping any two ranks has the same effect.
---------------------------------------------------
