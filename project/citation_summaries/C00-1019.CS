Other similar approaches include those of Cicekli and G uvenir (1996), McTait and Trujillo (1999), Carl (1999), and Brown (2000), inter alia. 
Statistical Machine Translation (SMT): SMT learns models for translation from corpora and dictionaries and searches for the best translation according to the models in run-time (Brown et al. , 1990; Knight, 1997; Ney et al. , 2000). 
Prior work has shown that EBMT requires large amounts of data (in the order of two to three million words) (Brown, 2000) of pre-translated text, to function reasonably well. 
Given that examples such as <DET> a : un are likely to exist in the word-level lexicon, they may be inserted at the point indicated by the marker tag to form the correct translation un bon homme.We thus cluster on marker words to improve the coverage of our system (see Section 5 for results that show exactly how clustering on marker words helps); others (notably Brown [2000, 2003]) use clustering techniques to determine equivalence classes of individual words that can occur in the same context, and in so doing derive translation templates from individual translation examples. 
In this paper, we compare our algorithm against the incremental GAC algorithm(Brown, 2000). 
