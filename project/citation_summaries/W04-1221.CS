Also of interest is the system presented by Settles (2004) which used CRFs with rich feature sets and suggested that one could use features from syntactic parsing with this model given their flexibility. 
4,500, 5 kg NETE Terms Maximum Entropy, Archeology Table 1: The named entity tagset used for the shared task  Affixes like Hyderabad, Rampur, Mehdipatnam, Lingampally  Gazetteer features: class in the gazetteer  Left and right context  Token length, e.g. the number of letters in a word  Previous history in the document or the corpus  Classes of preceding NEs The machine learning techniques tried for NER include the following:  Hidden Markov Models or HMM (Zhou and Su, 2001)  Decision Trees (Isozaki, 2001)  Maximum Entropy (Borthwick et al., 1998)  Support Vector Machines or SVM (Takeuchi and Collier, 2002)  Conditional Random Fields or CRF (Settles, 2004) Different ways of classifying named entities have been used, i.e., there are more than one tagsets for NER. 
After an initialization phase needed by AL to take off (which can considerably be accelerated when one carefully selects the sentences of the first AL round, see Section 4.2), AL selects, by and large, only sentences which contain at least one entity mention of the type of inter10The named enatity tagger used throughout in this section is based on Conditional Random Fields and similar to the one presented by (Settles, 2004). 
Our performance of the single-phase CRF with maximum likelihood training is 69.44%, which agrees with (Settles, 2004) who also uses similar settings. 
Previous studies have shown that automatic named entity recognition can be performed with a reasonable level of accuracy by using various machine learning models such as support vector machines (SVMs) or conditional random fields (CRFs) (Tjong Kim Sang and De Meulder, 2003; Settles, 2004; Okanohara et al., 2006). 
