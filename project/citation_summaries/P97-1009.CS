4.6 Lins Measure Lin (1998a) proposed a measure of lexical distributional similarity based on his information-theoretic similarity theorem (Lin 1997, 1998b): The similarity between A and B is measured by the ratio between the amount of information needed to state the commonality of A and B and the information needed to fully describe what A and B are. 
Lin (1997) defines the local context of a target word by the collection of syntactic dependencies in which the word takes part. 
Related to this issue, we note that the head rules, which were nearly identical to those used in (Collins, 1997), have not been tuned at all to this task. 
In previous work (Weeds and Weir 2003b), we used the WordNet-based similarity measure first proposed in Lin (1997) and used in Lin (1998a): wn sim lin (w 1, w 2 ) = max c 1 S(w 1 )c 2 S(w 2 ) parenleftbigg max csup(c 1 )sup(c 2 ) 2logP(c) log (P(c 1 )) + log (P(c 2 )) parenrightbigg (49) where S(w) is the set of senses of the word w in WordNet, sup(c) is the set of possibly indirect super-classes of concept c in WordNet, and P(c) is the probability that a randomly selected word refers to an instance of concept c (estimated over some corpus such as SemCor [Miller et al. 1994]). 
2.1 Selectors The term selector comes from (Lin, 1997), and refers to a word which can take the place of another given word within the same local context. 
