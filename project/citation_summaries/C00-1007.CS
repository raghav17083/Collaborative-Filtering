By and large, two statistical models are used in the rankers to choose output strings:  N-gram language models over different units, such as word-level bigram/trigram models (Bangalore and Rambow, 2000; Langkilde, 2000), or factored language models integrated with syntactic tags (White et al., 2007). 
For examples of related statistical sentence generators see Langkilde and Knight [1998] and Bangalore and Rambow [2000]. 
Other work focuses on surface realization | choosing among difierent lexical and syntactic options supplied by the lexical chooser and sentence planner | rather than on creating the mapping dictionary; although such work also uses lattices as input to the stochastic realizer, the lattices themselves are constructed by traditional knowledge-based means (Langkilde and Knight, 1998; Bangalore and Rambow, 2000). 
One is n-gram model over different units, such as word-level bigram/trigram models (Bangalore and Rambow, 2000; Langkilde, 2000), or factored language models integrated with syntactic tags (White et al. 2007). 
6 Related Work 6.1 Statistical Surface Realisers The work in this paper is similar to research in statistical surface realisation (for example, Langkilde and Knight (1998); Bangalore and Rambow (2000); Filippova and Strube (2008)). 
