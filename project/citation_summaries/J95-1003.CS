Previous work on multimodal reference resolution includes the use of a focus space model (Neal et al. , 1998), the centering framework (Zancanaro et al. , 1997), context factors (Huls et al. , 1995), and rules (Kehler 2000). 
Both of these steps, identifying antecedents and parsing sentences into clauses, can be completed, in theory, by automatic, computational methods (Huls, Bos, and Claassen 1995; Nakaiwa and Shirai 1996; Paul and Sumita 2001; Yamura-Takei et al. 2002), but the success rate of these approaches is not high enough to rely on them for completely accurate analyses of this type of corpus at this time. 
Following prior work that demonstrated the utility of a visual decay function (Byron et al. , 2005b; Huls et al. , 1995), we implemented a three second threshold on the lifespan of a visual entity. 
To resolve multimodal references, many approaches have been developed, from the use of a focus space model (Neal et al. , 1998), a centering framework (Zancanaro et al, 1997), contextual factors (Huls et al. , 1995); to recent approaches using unification (Johnston, 1998), finite state machines (Johnston and Bangalore 2000), and contextbased rules (Kehler 2000). 
Local semantic constraints can be added to this algorithm, as in (Huls et al. , 1995). 
