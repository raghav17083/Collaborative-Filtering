Many previous approaches have used a logical form representation of the text and hypothesis sentences, focusing on deriving a proof by which one can infer the hypothesis logical form from the text logical form (Bayer et al. , 2005; Bos and Markert, 2005; Raina et al. , 2005; Tatu and Moldovan, 2005). 
The RTE problem as presented in the PASCAL RTE dataset is particularly attractive in that it is a reasonably simple task for human annotators with high inter-annotator agreement (95.1% in one independent labeling (Bos and Markert, 2005)), but an extremely challenging task for automated systems. 
We show comparable results from recent systems based on lexical similarity (Jijkoun and de Rijke, 2005), graph alignment (Haghighi et al. , 2005), weighted abduction (Raina et al. , 2005), and a mixed system including theorem proving (Bos and Markert, 2005). 
Finally, a few efforts (Akhmatova, 2005; Fowler et al. , 2005; Bos and Markert, 2005) have tried to 42 translate sentences into formulas of first-order logic, in order to test logical entailment with a theorem prover. 
For example, two high-accuracy systems are those described in (Tatu and Moldovan, 2005), achieving 60.4% accuracy with no task-specific information, and (Bos and Markert, 2005), which achieves 61.2% task-dependent accuracy, i.e. when able to use the specific task labels as input. 
