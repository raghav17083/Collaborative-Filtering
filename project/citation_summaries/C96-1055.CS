Supervised Learning of Lexical Semantic Verb Classes Using Frequency Distributions Suzanne Stevenson Rutgers Umverslty suzannecs rutgers edu Paola Merlo Umverslty of Geneva merlolettres unlge ch Natalia Kariaeva Rutgers Umverslty karlaeva@rcl rutgers edu Kamin Whitehouse Rutgers Umverslty kamlnwrcl rutgers edu Abstract Vve zeport a number of computatmnal experiments m supervised learning whose goal Is to automatmally classify a set of verbs into lexmal semanUc classes, based on frequency dlstnbutmn approxlmatmns of grammatical features extracted from a very large annotated corpus DlstnbuUons of five syntactic features that approximate tranmUvlty alternatmns and thematic role assignments are sufficient to reduce error rate by 56% over chance We conclude that corpus data is a usable repository of verb class mformatmn, and that corpusdriven extraction of grammaUcal features Is a promising methodology for automatm lexmal acqum,Uon 1 Introduction Recent years have witnessed a shift in grammar development methodology, from crafting large grammars, to annotation of corpora Correspondingly, there has been a change from developing rule-based parsers to developing statmUcal methods for reducing grammatmal knowledge from annotated corpus data The shift has mostly occurred because buildmg w~de-coverage grammars is ume-consummg, error prone, and difficult The same can be said for crafting the rich lexlcal representatmns that are a central component of hngmstlc knowledge, and research m automaUc lexmal acquisition has sought to address this ((Doff and Jones, 1996, Dorr, 1997), among others) Yet there have been few attempts to learn fine-grained lexical classifications from the statlsUcal analysis of dlstnbutmnal data, analogously to the induction of syntacUc knowledge (though see, e g, (Brent, 1993, Klavans and Chodorow, 1992, Resmk, 1992)) In this paper, we propose such a~ approach for the automaUc classfficauon of ~erbs into lexlcal semantic classes l We can express the Issues raised by this apploach as follows 1 Whmh hngulstlc dlstmcUons among \[exlcsl classes can we expect to find m a corpus ~ 2 How easily can we extract the frequency distributions that approximate the relevant hngmstlc properttes? 
Dorr and Jones, 1996). 
For example, the English verb classification by Levin (1993) has been used in NLP applications such as word sense disambiguation (Dorr and Jones 1996), machine translation (Dorr 1997), document classification (Klavans and Kan 1998), and subcategorization acquisition (Korhonen 2002). 
Other work has used Levins list of verbs (in conjunction with related lexical resources) for the creation of dictionaries that exploit the systematic correspondence between syntax and meaning (Dorr, 1997; Dang et al. , 1997; Dorr and Jones, 1996). 
3 Which frequency dlstnbuUons work best to distinguish the verb classes ~ In exploring these quesUons, we focus on verb classlficaUon for several reasons Verbs are very important sources of knowledge in many language engineering tasks, and the relationships among verbs appear to play a major role m the orgamzatmn and use of this knowledge Knowledge about verb classes is crucml for lex,cal acqmsltton m support of language generation and machine translatmn (Dolt, 1997) and document cl~sfficatmn (Klavans and Kan, 1998), yet manual classfficauon of large numbers of verbs is a difficult and resource intensive task (Levm, 1993 Miller et al, 1990, Dang et al, 1998) To address these issues, we suggest that one can tram an automatic classffier for verbs on the basts of staUstmal approxlmaUons to verb dlatheses We use dlatheses--alternatmns m the expression of the arguments of the verb--following Levm and Dorr, for two reasons Fnst, verb dlatheses are syntacuc cues 1 We are aware that a dlstnbutmnal approach rests on one strong assumptmn regarding the nature of the representatmns under study semantic notmns and syntacuc notmns are correlated, at least m part This assurapuon is under debate (Bnscoe and Copestake, 1995, Levm, 1993, Dorr and Jones, 1996, Dorr, 1997), but we adopt ~t here without further dlscussmn 15 '  to semantic classes, hence they can be more easily captured by corpus-based techniques Second, using verb d~atheses reduces no,se There ~s a certain consensus (Bnscoe and Copestake, 1995, Pustejovsky, 1995, Palmer, 1999) that verb dmtheses are regular sense extensmns Hence focussing on thin type of classfficatmn allows one to abstract from the problem of word sense dmamb,guatmn and treat remdual d~fferences m word senses as no~se m the classfficatmn task We present an m-depth case study, m which we apply machine learning techmques to automaUcally classify a set of verbs based on d~stnbutmns of grammaucal indicators of dmtheses, extracted from a very large corpus We look at three very mterestmg classes of verbs unergaUves, unaccusauves, and obJect-drop verbs (Levm, 1993) These are Interestmg classes because they all parUcapate m the trans~uvlty alternatmn, and they are minimal parrs that as, a small number of well-defined dmtmctmns d~fferentmte their trans,tlve/mtranmUve behavmr Thus, we expect the differences m their dmtnbuttons to be small, entailing a fine-grained dlscr,mmaUon task that prowdes a challenging testbed for automatic classfficatmn The specffic theoretical questmn we mvesUgate ~s whether the factors underlying the verb class dmtmctmns are reflected m the statmttcal dmtnbutmns of lex~cal features related to dmtheses presented by the md,v~dual verbs m the corpus In doing th~s, we address the questmns above by determining what are the lexmal features that could d~stmgmsh the behavtor of the classes of verbs w~th respect to the relevant dmtheses, ~hmh of those features can be gleaned from the corpus, and which of those, once the staUstmal dmtnbutmns are available, can be used successfully by an automatic classifier In m~ttal work (Stevenson and Merlo, 1999), ~e found that hngmstlcally motivated features that d~stmgmsh the verb classes can be extracted from an annotated, and m one case parsed, corpus These features are sufficient to almost halve the error rate compared to chance (45% reductmn) m automaUc verb classtficaUon, suggesting that d~stnbuUonal data prowdes knowledge useful to the class~ficaUon of verbs The focus of our original stud~ was tho demonstration m prmctple of l~a.nmg verb classes from frequency d~stnbutmns ofsyntactm features, and an analysm of the relaUve contrtbutmn of the various features to learmng Th~s paper turns to the nnportant next steps of rephcatmg our findrags using other training methods and learning algorithms, and analyzing the performance on each of tbe three classes of verbs This more detailed analys~s of accuracy within each class m turn leads to the development of a new dlstrtbutmnal feature mtended to improve dlscnmmabthty among t~o of the classes The addltmn of the ne~ feature successfully reduces the error rate of out mltml results m classlficatmn by 19%, for a 56% overall reductmn m error rate compared to chance 2 Determining the Features In this sectmn, we present mouvatmn for the mttml features that we mvesUgated m terms of their role m learmng the verb classes We first present the hngmstlcally den~ed features then turn to e~tdence from experimental psychohngutstlcs to e\tend the set of potentially relevant features 2.1 Features of the Velb Classes The three verb classes under mvesugatmn unergaUves, unaccusaUves, and object-drop -differ m the properties of their translttve/mtranslhve a\[ternaUons, which are exemphfied below UnergaUve (la) The horse raced past the barn (lb) The jockey raced the horse past the barn Wnaccusatave (2a) The butter melted m the pan (2b) The cook melted the butter m the pan ObJect-drop (3a) The boy washed the hall (3b) The boy washed The sentences m (1) use an unergatwe vvelb. 
