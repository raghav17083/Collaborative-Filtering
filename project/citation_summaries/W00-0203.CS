We followed the three-point grading scheme previously developed for the C-STAR consortium, as described in (Levin et al. , 2000). 
Experiments at the end of C-star II showed that cross-site evaluations were comparable to intra-site evaluations (analyzer and generator written at the same site) (Levin et al. , 2000b). 
Stevenson and Gaizauskas (2000) use TiMBL (Daelemans et al. , 2000) to identify sentence boundaries in speech recognizer output, and Gotoh and Renals (2000) use a statistical approach to identify sentence boundaries in automatic speech recognition transcripts of broadcast speech. 
Translations were compared to human transcriptions and graded as described in (Levin et al. , 2000). 
The C-star II database tagged with C-star II interlingua had a notag rate of 7.3% (Levin et al. , 2000a). 
