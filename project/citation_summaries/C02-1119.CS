This framework is useful for question classification because the works of (Li and Roth, 2002; Suzuki et al. , 2002a) showed that richer information, such as structural and semantical information inside a given question, improves the question classification performance over using the information of just simple key terms. 
In recent years, many supervised machine learning techniques for answer selection in open-domain question answering have been investigated in some pioneering studies [Ittycheriah et al. 2001; Ng et al. 2001; Suzuki et al. 2002; Sasaki, et al. 2005; and Echihabi et al. 2003]. 
Moreover, the previous work of (Suzuki et al. , 2002a) showed that the sequential patterns constructed by different levels of attributes, such as words, part-ofspeech (POS) and semantical information, improve the performance of question classification. 
current models of this type are based on supervised approaches [Ittycheriah et al. 2001; Ng et al. 2001; Suzuki et al. 2002; and Sasaki et al. 2005] that are heavily dependent on hand-tagged questionanswer training pairs, which not readily available. 
Recently, some pioneering studies have investigated approaches to automatically construct QA components from scratch by applying machine learning techniques to training data (Ittycheriah et al. , 2001a)(Ittycheriah et al. , 2001b)(Ng et al. , 2001) (Pasca and Harabagiu)(Suzuki et al. , 2002)(Suzuki 215 Table 1: Number of Questions in Question Types of CRL QA Data # of Questions # of Question Types Example 1-9 74 AWARD, CRIME, OFFENSE 10-50 32 PERCENT, N PRODUCT, YEAR PERIOD 51-100 6 COUNTRY, COMPANY, GROUP 100-300 3 PERSON, DATE, MONEY Total 115 et al. , 2003) (Zukerman and Horvitz, 2001)(Sasaki et al. , 2004). 
