P06-1110:1	190:239	In future work, we plan to try linguistically more sophisticated features (Charniak & Johnson, 2005) as well as sub-tree features (Bod, 2003; Kudo et al. , 2005).
---------------------------------------------------
E09-1066:2	21:200	(Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Shen et al., 2003; Moschitti and Bejan, 2004; Culotta and Sorensen, 2004; Kudo et al., 2005; Toutanova et al., 2004; Kazama and Torisawa, 2005; Zhang et al., 2006; Moschitti et al., 2006).
---------------------------------------------------
W06-3603:3	146:223	Charniak and Johnson (2005) use linguistically more sophisticated features, and Bod (2003) and Kudo et al.
---------------------------------------------------
W06-3607:4	7:186	Various supervised learning algorithms have been adapted to the task of reranking for NLP systems, such as MaxEnt-Rank (Charniak and Johnson, 2005; Ji and Grishman, 2005), SVMRank (Shen and Joshi, 2003), Voted Perceptron (Collins, 2002; Collins and Duffy, 2002; Shen and Joshi, 2004), Kernel Based Methods (Henderson and Titov, 2005), and RankBoost (Collins, 2002; Collins and Koo, 2003; Kudo et al. , 2005).
---------------------------------------------------
D09-1012:5	9:201	(Collins and Duffy, 2002), (Kudo and Matsumoto, 2003), (Cumby and Roth, 2003), (Cancedda et al., 2003), (Culotta and Sorensen, 2004), (Toutanova et al., 2004), (Kazama and Torisawa, 2005), (Shen et al., 2003), (Gliozzo et al., 2005), (Kudo et al., 2005), (Moschitti et al., 2008), (Diab et al., 2008).
---------------------------------------------------
P08-2010:6	85:99	Our BoostedMERT should not be confused with other boosting algorithms such as (Collins and Koo, 2005; Kudo et al., 2005).
---------------------------------------------------
W05-1514:7	194:207	Since many researchers have reported that information on partial parse trees plays an important role for achieving high performance (Bod, 1992; Collins and Duffy, 2002; Kudo et al. , 2005), we expect that additional features will improve the performance of chunk parsing.
---------------------------------------------------
D09-1112:8	37:213	(Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby 1Contract n. 33549 and Roth, 2003; Cancedda et al., 2003; Culotta and Sorensen, 2004; Toutanova et al., 2004; Kudo et al., 2005; Moschitti, 2006a; Moschitti et al., 2007; Moschitti, 2008; Moschitti et al., 2008; Moschitti and Quarteroni, 2008).
---------------------------------------------------
W08-2103:9	80:220	We also use the following pruning techniques (Morishita, 2002; Kudo et al., 2005).
---------------------------------------------------
W08-2103:10	15:220	Furthermore, classifiers based on boostingbased learners have shown fast classification speed (Kudo et al., 2005).
---------------------------------------------------
W08-2103:11	188:220	Networks (Toutanova et al., 2003) 97.24 SVM (Gimenez and M`arquez, 2003) 97.05 ME based a bidirectional inference (Tsuruoka and Tsujii, 2005) 97.15 Guided learning for bidirectional sequence classification (Shen et al., 2007) 97.33 AdaBoost.SDF with candidate features (=2,=1,=100, W-dist) 97.32 AdaBoost.SDF with candidate features (=2,=10,=10, F-dist) 97.32 SVM with candidate features (C=0.1, d=2) 97.32 Text Chunking F=1 Regularized Winnow + full parser output (Zhang et al., 2001) 94.17 SVM-voting (Kudo and Matsumoto, 2001) 93.91 ASO + unlabeled data (Ando and Zhang, 2005) 94.39 CRF+Reranking(Kudo et al., 2005) 94.12 ME based a bidirectional inference (Tsuruoka and Tsujii, 2005) 93.70 LaSo (Approximate Large Margin Update) (Daume III and Marcu, 2005) 94.4 HySOL (Suzuki et al., 2007) 94.36 AdaBoost.SDF with candidate featuers (=2,=1,=, W-dist) 94.32 AdaBoost.SDF with candidate featuers (=2,=10,=10,W-dist) 94.30 SVM with candidate features (C=1, d=2) 94.31 One of the reasons that boosting-based classifiers realize faster classification speed is sparseness of rules.
---------------------------------------------------
W08-2103:12	195:220	Most of these previous works manually selected combination of features except for SVM with polynomial kernel and (Kudo and Matsumoto, 2001) a boosting-based re-ranking (Kudo et al., 2005).
---------------------------------------------------
W08-2103:13	11:220	These include text categorization (Schapire and Singer, 2000), Natural Language Parsing (Collins and Koo, 2005), English syntactic chunking (Kudo et al., 2005) and so on.
---------------------------------------------------
W08-2103:14	198:220	Kudo et al. proposed to perform several pseudo iterations for converging fast (Kudo et al., 2005) with features in the cache that maintains the features explored in the previous iterations.
---------------------------------------------------
W09-1106:15	99:202	Concerning the use of kernels for NLP, interesting models and results are described, for example, in (Collins and Duffy, 2002), (Moschitti et al., 2008), (Kudo and Matsumoto, 2003), (Cumby and Roth, 2003), (Shen et al., 2003), (Cancedda et al., 2003), (Culotta and Sorensen, 2004), (Daume III and Marcu, 2004), (Kazama and Torisawa, 2005), (Kudo et al., 2005), (Titov and Henderson, 2006), (Moschitti et al., 2006), (Moschitti and Bejan, 2004) or (Toutanova et al., 2004).
---------------------------------------------------
