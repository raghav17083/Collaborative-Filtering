Indeed, using tree kernel methods to mine structured knowledge has shown success in some NLP applications like parsing (Collins and Duffy, 2001), semantic role labeling (Moschitti, 2004; Zhang et al., 2007b), relation extraction (Zhang et al., 2006), pronoun resolution (Yang et al., 2006) and question classification (Zhang and Lee, 2003). 
Here, we explore four parse tree structures in NP anaphoricity determination: the common tree (CT), the shortest path-enclosed tree (SPT), the minimum tree (MT) and the dynamically extended tree (DET), motivated by Yang et al (2006) and Zhou et al (2008). 
Indeed, they have already been used in NLP to encode the type of structural information that plays a role in binding constraints (Yang et al. 2006); however, the methods used in this previous work do not make it possible to exploit the full power of kernel functions. 
2 Related Work Related work on exploring syntactic structured information in pronoun resolution can be typically classified into three categories: parse tree-based search algorithms (Hobbs 1978), feature-based (Lappin and Leass 1994; Bergsma and Lin 2006) and tree kernel-based methods (Yang et al 2006). 
Among previous tree kernels, the convolution tree kernel represents the state-of-the-art and have been successfully applied by Collins and Duffy (2002) on parsing, Moschitti (2004) on semantic role labeling, Zhang et al (2006) on semantic relation extraction  and Yang et al (2006) on pronoun resolution. 
