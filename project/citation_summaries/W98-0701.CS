A method that disambiguates unrestricted nouns, verbs, adverbs and adjectives in texts is presented in (Stetina et al. , 1998); it attempts to exploit sentential and discourse contexts and is based on the idea of semantic distance between words, and lexical relations. 
While it is tempting to compare these results to those of (Stetina et al. , 1998), who reported 79.4% overall accuracy on a different, larger test set using their non-discourse model, we note that that was more of an upperbound study, examining how well a WSD algorithm could perform if it had access to goldstandard-perfect parse trees33 By way of further comparison, that algorithm has a feature space similar to the synset-prediction compo1nit is not clear how or why the results of (Stetina et al. , 1998) exceeded the reported inter-annotator agreement of the entire corpus. 
Most recently, in (Stetina et al. , 1998), the authors made use of head-driven bilexical dependencies with syntactic relations to attack the problem of generalized word-sense disambiguation, precisely one of the two problems we are dealing with here. 
To our knowledge, there is only one other method, recently reported, that disambiguates unrestricted words in texts (Stetina et al. , 1998). 
Bolstered by the success of (Stetina and Nagao, 1997), (Lin, 1997) and especially (Stetina et al. , 1998), we believe there is great promise the incorporation of word-sense into a probabilistic parsing model. 
