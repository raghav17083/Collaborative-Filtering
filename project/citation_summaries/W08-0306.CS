Finally, the root node of the tree must be aligned to the full 1Previous approaches to bilingual grammar induction have used variational inference to optimise a bound on the data log-likelihood (Zhang et al., 2008; Blunsom et al., 2009b). 
Others have introduced alternative discriminative training methods (Tillmann and Zhang, 2006; Liang et al., 2006; Turian et al., 2007; Blunsom et al., 2008; Macherey et al., 2008), in which a recurring challenge is scalability: to train many features, we need many train218 ing examples, and to train discriminatively, we need to search through all possible translations of each training example. 
Word alignment is also a required first step in other algorithms such as for learning sub-sentential phrase pairs (Lavie et al., 2008) or the generation of parallel treebanks (Zhechev and Way, 2002). 
In this work we draw on recent advances in Bayesian modelling of grammar induction (Johnson et al., 2007; Cohn et al., 2009) to propose a non-parametric model of synchronous tree substitution grammar (STSG), continuing a recent trend in SMT to seek principled probabilistic formulations for heuristic translation models (Zhang et al., 2008; DeNero et al., 2008; Blunsom et al., 2009b; Blunsom et al., 2009a). 
3.3 MIRA training We incorporate all our new features into a linear model (Och and Ney, 2002) and train them using MIRA (Crammer et al., 2006), following previous work (Watanabe et al., 2007; Chiang et al., 2008). 
