Additionally, many discriminative models use a generative model as a base model and add discriminative features with reranking (Collins, 2000; Charniak and Johnson, 2005; Roark et al. , 2004), or train discriminatively a small set of weights for features which are generatively estimated probabilities (Raina et al. , 2004; Och and Ney, 2002). 
The optimal string under our new model is defined as w = arg max w ( log Pl(w) + , (a, w)+ log Pa(a|w)) (2) where the arg max is taken over all strings in the 1000-best list, and where   Rd is a parameter vector specifying the weight for each feature in  (note that we define x, y to be the inner, or dot 1Note that (Roark et al. , 2004a; Roark et al. , 2004b) give results for an n-gram approach on this data which makes use of both lattices and 1000-best lists. 
(2004a; 2004b), and the extensions to that work in Roark et al. 
Lexical language model features have been exploited successfully in discriminative language modeling to improve speech recognition performance (Roark et al. , 2004). 
As one example, the language modeling features might take into account n-grams, for example through definitions such as 2(a,w) = Count of the the in w Previous work (Roark et al. , 2004a; Roark et al. , 2004b) considered features of this type. 
