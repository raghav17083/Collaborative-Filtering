One of the well known dialogue analysis schemes, 6 used in the Edinburgh Maptask, is described in (Carletta, Isard et al. 1997) (Carletta, Isard et al. 1996) How does MAP compare to DMT? 
5.3 Agreement between Subjects As indicated in Table 9, the unanimous agreement of just 16.6% and 19.5% in the adhoc and categorization tasks respectively is low: the agreement data has Kappa (Carletta et al. 1997) of .38 for adhoc and .29 for categorization 4. 
This position was taken by other computational linguists as well (Carletta et al. , 1997, p. 25). 
In content analysis, they require a kappa value over 0.67 for deriving a tentative conclusion, but in a guideline of medical science, a kappa value 0.41 < n < 0.60 are judged to be moderate (Carletta et al., 1997a; Landis and Koch, 1977; Krippendorff, 1980). 
4 To link dialogue acts to utterances, three problems 5 must be addressed at the same time: AF Dialogue act classification scheme and its reliability in coding corpus, (Carletta et al. , 1997; Allen and Core, 1997; Traum, 1999); AF Choice of features/cues that can support automatic dialogue act identification, including lexical, syntactic, prosodic, collocational, and discourse cues; AF A model that correlates dialogue acts with those features. 
