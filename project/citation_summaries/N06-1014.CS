The alignment is done by the Berkeley word aligner (Liang et al., 2006) and then we symmetrized the word alignment using the grow-diag heuristic. 
Their best result, however, is obtained from a model that includes both a feature recording intersected IBM Model 4 predictions, plus a feature whose values are the alignment probabilities obtained from a pair of HMM alignment models trained in both directions in such a way that they agree on the alignment probabilities (Liang et al. , 2006). 
weight Model 1 Score 0.1416 POS 0.0540 Log-likelihood Ratio 0.0856 relative distortion 0.0606 DA-1 0.0227 DLA-2 0.0927 tgt-1-PRD 0.0961 tgt-2-AMOD 0.0621 Table 5: Weights of some informative features 5.2 Machine Translation Research has shown that an increase in AER does not necessarily imply an improvement in translation quality (Liang et al., 2006) and vice-versa (Vilar et al., 2006). 
The alignment is done by the Berkeley word aligner (Liang et al., 2006) and then we symmetrized the word alignment using the grow-diag heuristic. 
(Lacoste-Julien et al. , 2006) created a discriminative model able to model 1-to-1, 1-to2 and 2-to-1 alignments for which the best results were obtained using features based on symmetric HMMs trained to agree, (Liang et al. , 2006), and intersected Model 4. 
