D09-1084:1	72:275	Chen et al., (2006) propose a web-based doublechecking model to compute the semantic similarity between words.
---------------------------------------------------
D09-1084:2	238:275	6 Experiments Table 1 compares the proposed method against Miller-Charles ratings (MC), and previously proposed web-based semantic similarity measures: Jaccard, Dice, Overlap, PMI (Bollegala et al., 2007), Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007), Sahami and Heilman (SH) (2006), co-occurrence double checking model (CODC) (Chen et al., 2006), and support vector machine-based (SVM) approach (Bollegala et al., 2007).
---------------------------------------------------
N09-1003:3	8:215	The techniques used to solve this problem can be roughly classified into two main categories: those relying on pre-existing knowledge resources (thesauri, semantic networks, taxonomies or encyclopedias) (Alvarez and Lim, 2007; Yang and Powers, 2005; Hughes and Ramage, 2007) and those inducing distributional properties of words from corpora (Sahami and Heilman, 2006; Chen et al., 2006; Bollegala et al., 2007).
---------------------------------------------------
N09-1003:4	177:215	We did Method Source Spearman (MC) Pearson (MC) (Sahami et al., 2006) Web snippets 0.62 [0.32, 0.81] 0.58 [0.26, 0.78] (Chen et al., 2006) Web snippets 0.69 [0.42, 0.84] 0.69 [0.42, 0.85] (Wu and Palmer, 1994) WordNet 0.78 [0.59, 0.90] 0.78 [0.57, 0.89] (Leacock et al., 1998) WordNet 0.79 [0.59, 0.90] 0.82 [0.64, 0.91] (Resnik, 1995) WordNet 0.81 [0.62, 0.91] 0.80 [0.60, 0.90] (Lin, 1998a) WordNet 0.82 [0.65, 0.91] 0.83 [0.67, 0.92] (Bollegala et al., 2007) Web snippets 0.82 [0.64, 0.91] 0.83 [0.67, 0.92] (Jiang and Conrath, 1997) WordNet 0.83 [0.67, 0.92] 0.85 [0.69, 0.93] (Jarmasz, 2003) Rogets 0.87 [0.73, 0.94] 0.87 [0.74, 0.94] (Patwardhan et al., 2006) WordNet n/a 0.91 (Alvarez and Lim, 2007) WordNet n/a 0.91 (Yang and Powers, 2005) WordNet 0.87 [0.73, 0.91] 0.92 [0.84, 0.96] (Hughes et al., 2007) WordNet 0.90 n/a Personalized PageRank WordNet 0.89 [0.77, 0.94] n/a Bag of words Web corpus 0.85 [0.70, 0.93] 0.84 [0.69, 0.93] Context window Web corpus 0.88 [0.76, 0.95] 0.89 [0.77, 0.95] Syntactic contexts Web corpus 0.76 [0.54, 0.88] 0.74 [0.51, 0.87] SVM Web, WN 0.92 [0.84, 0.96] 0.93 [0.85, 0.97] Table 7: Comparison with previous approaches for MC.
---------------------------------------------------
N07-1043:5	54:292	Chen et al. , (2006) propose a web-based double341 checking model to compute semantic similarity between words.
---------------------------------------------------
N07-1043:6	157:292	Since most named entities are not covered by WordNet, similarity measures based on WordNet alone cannot be Table 5: Performance of named entity clustering Method Precision Recall F Measure WebJaccard 0.5926 0.712 0.6147 WebOverlap 0.5976 0.68 0.5965 WebDice 0.5895 0.716 0.6179 WebPMI 0.2649 0.428 0.2916 Sahami (2006) 0.6384 0.668 0.6426 Chen (2006) 0.4763 0.624 0.4984 Proposed 0.7958 0.804 0.7897 used in such tasks.
---------------------------------------------------
N07-1043:7	136:292	Our implementation of Co-occurrence Double Checking (CODC) measure (Chen et al. , 2006) reports the second best correlation of 0.6936.
---------------------------------------------------
