W06-2204:1	201:347	Specifically, probabilistic finite-state methods such hidden Markov models and conditional random fields have been shown to be competitive with more traditional pattern-based approaches to information extraction (Fuchun and McCallum, 2004), and these methods can exploit the Expectation Maximization algorithm to learn from a mixture of labelled and unlabelled data (Lafferty et al. , 2004).
---------------------------------------------------
I08-1044:2	37:215	CRFs have been successfully applied to a number of real-world tasks, including NP chunking (Sha and Pereira, 2003), Chinese word segmentation (Peng et al., 2004), information extraction (Pinto et al., 2003; Peng and McCallum, 2004), named entity identification (McCallum and Li, 2003; Settles, 2004), and many others.
---------------------------------------------------
N06-1054:3	13:249	 In bibliography entries (Peng and McCallum, 2004), a given field (author, title, etc).
---------------------------------------------------
D07-1088:4	64:252	Recent work includes improved model variants (e.g. , Jiao et al. , 2006; Okanohara et al. , 2006) and applications such as web data extraction (Pinto et al. , 2003), scientific citation extraction (Peng and McCallum, 2004), and word alignment (Blunsom and Cohn, 2006).
---------------------------------------------------
D07-1088:5	38:252	This paper mainly focuses on the VP problem, since linguistic features for the HP problem is the general IE topic of much past research (e.g. , Peng and McCallum, 2004).
---------------------------------------------------
D07-1088:6	62:252	Recently an increasing number of research efforts on text mining and IE have used CRF models (e.g. , Peng and McCallum, 2004).
---------------------------------------------------
P06-3006:7	113:138	A detailed description of CRFs can be found in (Lafferty et al, 2001; Sha and Pereira, 2003; Malouf, 2002; Peng and McCallum, 2004).
---------------------------------------------------
P06-1061:8	24:172	Examples of these models include maximum entropy Markov models (McCallum et al. , 2000), Bayesian information extraction network (Peshkin and Pfeffer, 2003), and conditional random fields (McCallum, 2003) (Peng and McCallum, 2004).
---------------------------------------------------
C04-1081:9	64:178	See Peng and McCallum (2004) for more details and further experiments.
---------------------------------------------------
P05-1046:10	179:198	More recently, Peng and McCallum (2004) applied supervised learning of Conditional Random Field (CRF) sequence models to the problem of parsing the head377 ers of research papers.
---------------------------------------------------
W06-0505:11	54:181	Furthermore, CRFs have been used successfully in information extraction (Peng and McCallum, 2004), named entity recognition (Li and McCallum, 2003; McCallum and Li, 2003) and sentence parsing (Sha and Pereira, 2003).
---------------------------------------------------
D09-1014:12	14:258	Statistical machine learning methods such as hidden Markov models (HMMs) (Rabiner, 1989; Seymore et al., 1999; Freitag and McCallum, 1999) and conditional random fields (CRFs) (Lafferty et al., 2001; Peng and McCallum, 2004; Sarawagi and Cohen, 2005) have become popular approaches to address the text extraction problem.
---------------------------------------------------
D08-1112:13	145:169	CORA (Peng and McCallum, 2004) consists of two collections: a set of research paper headers annotated for entities such as title, author, and institution; and a collection of references annotated with BibTeX fields such as journal, year, and publisher.
---------------------------------------------------
I08-2124:14	24:185	Reported work includes improved model variants (e.g., Jiao et al., 2006) and applications such as web data extraction (Pinto et al., 2003), scientific citation extraction (Peng and McCallum, 2004), word alignment (Blunsom and Cohn, 2006), and discourselevel chunking (Feng et al., 2007).
---------------------------------------------------
P05-1062:15	170:193	For example, Peng and McCallum (2004) applied Conditional Random Fields to extract information, which draws together the advantages of both HMM and SVM.
---------------------------------------------------
W07-0206:16	158:201	(1999), Peng and McCallum (2004), McCallum et al.
---------------------------------------------------
P05-1003:17	8:159	1 Introduction In recent years, conditional random fields (CRFs) (Lafferty et al. , 2001) have shown success on a number of natural language processing (NLP) tasks, including shallow parsing (Sha and Pereira, 2003), named entity recognition (McCallum and Li, 2003) and information extraction from research papers (Peng and McCallum, 2004).
---------------------------------------------------
C08-1039:18	91:179	In our experiments we use the bibliographic citation dataset described in (Peng and McCallum, 2004) (see Fig.
---------------------------------------------------
C08-1039:19	172:179	(Peng and McCallum, 2004) used only labeled data to train conditional random fields and HMMs with second order state transitions where they allow observation in each position to depend on the current state as well as observation of the previous position.
---------------------------------------------------
W06-2918:20	8:203	1 Introduction In recent years discriminative probabilistic models have been successfully applied to a number of information extraction tasks in natural language processing (NLP), such as named entity recognition (NER) (McCallum and Li, 2003), noun phrase chunking (Sha and Pereira, 2003) and information extraction from research papers (Peng and McCallum, 2004).
---------------------------------------------------
