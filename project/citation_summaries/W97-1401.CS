P98-1102:1	179:192	Empirical investigation (Oviatt 1996, Oviatt et al 1997) has shown that multimodal utterances rarely contain more than two or three elements.
---------------------------------------------------
P98-1102:2	12:192	Our multimodal interface technology is implemented in QuickSet (Cohen et al 1997), a working system which supports dynamic interaction with maps and other complex visual displays.
---------------------------------------------------
P98-1102:3	2:192	Johnston et al (1997) model this integration using a unification operation over typed feature structures.
---------------------------------------------------
P98-1102:4	101:192	The basic multimodal integration strategy of Johnston et al 1997 is now just one rule among many (Figure 7).
---------------------------------------------------
P98-1102:5	26:192	In the approach to multimodal integration proposed by Johnston et al 1997, integration of spoken and gestural input is driven by a unification operation over typed feature structures (Carpenter 1992) representing the semantic contributions of the different modes.
---------------------------------------------------
P98-1102:6	163:192	The system has undergone a form of pro-active evaluation in that its design is informed by detailed predictive modeling of how users interact multimodally, and incorporates the results of empirical studies of multimodal interaction (Oviatt 1996, Oviatt et al 1997).
---------------------------------------------------
P98-1102:7	39:192	The approach of Johnston et al 1997 also faces fundamental architectural problems.
---------------------------------------------------
P98-1102:8	114:192	This temporal constraint is based on empirical investigation of multimodal interaction (Oviatt et al 1997).
---------------------------------------------------
P98-1102:9	43:192	2 Parsing in Multidimensional Space The integrator in Johnston et al 1997 does in essence parse input, but the resulting structures can only be unary or binary trees one level deep; unimodal spoken or gestural commands and multimodal combinations consisting of a single spoken element and a single gesture.
---------------------------------------------------
P98-1102:10	158:192	It has been implemented and deployed as part of QuickSet (Cohen et al 1997) and operates in real time.
---------------------------------------------------
N04-4012:11	16:105	Users display a preference for the touchscreen in map-based positioning acts and object selection (Oviatt et al. , 1997).
---------------------------------------------------
N04-4012:12	73:105	Like humans (McNeill, 1992; Oviatt et al. , 1997), our system aims to be coherent and consistent across all modes.
---------------------------------------------------
