While this is less of a problem when evaluating on manual transcriptions, the experience reported in (Huang et al. , 2001) suggests that the relatively high error rate of speech recognizers may negatively affect performance of caller name extraction on automatically generated transcripts. 
The results are summarized in Table 5, which also repeats the best results from (Huang et al. , 2001), using the same terminology as earlier: rows HZP strict and HZP containment refer to the best model from (Huang et al. , 2001)  corresponding to row HZP log-linear in Table 4  when evaluated using the strict criterion and containment, respectively; and row JA containment refers to our own best model  corresponding to row JA extract + classify in Table 4. 
This is corroborated by the fact that we were able to obtain performance much closer to that of the best, finely tuned log-linear model from (Huang et al. , 2001) by using a generic named entity tagger that was not adapted in any way to the particular task at hand. 
Rows HZP strict and HZP containment repeat the figures for the best model from (Huang et al. , 2001) when evaluated on automatic transcriptions. 
This places less of a burden on the grammar developers than having to write an accurate set of rules like the baseline of (Huang et al. , 2001). 
