Developing a full coreference system, however, is a considerable engineering effort, which is why a large body of research concerned with feature engineering or learning methods (e.g. Culotta et al. 2007; Denis and Baldridge 2007) uses a simpler but non-realistic setting, using pre-identified mentions, and the use of coreference information in summarization or question answering techniques is not as widespread as it could be. 
Both of these systems were supervised systems discriminatively trained to maximize b3 and used features from many different structured resources including WordNet, as well as domain-specific features (Culotta et al., 2007). 
A solution seen in previous work (Luo et al., 2004; Culotta et al., 2007) is to design a set of first-order features summarizing the information of the mentions in an entity, for example, whether the entity has any mention that is a name alias of the active mention? or whether most of the mentions in the entity have the same head word as the active mention? These features, nevertheless, are designed in an ad-hoc manner and lack the capability of describing each individual mention in an entity. 
In our study, we also tested the Most-X strategy for the first-order features as in (Culotta et al., 2007), but got similar results without much difference (0.5% F-measure) in perfor4http://www.rulequest.com/see5-info.html mance. 
As these varied factors have given rise to a multitude of weak features, recent work has focused on how best to learn to combine them using models over reference structures (Culotta et al., 2007; Denis and Baldridge, 2007; Klenner and Ailloud, 2007). 
