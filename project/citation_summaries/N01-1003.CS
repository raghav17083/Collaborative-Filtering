The best result is obtained by using HH to train both the TM and the LM; this result (0.41) is comparable to the result obtained by using matched PTB training and test data (0.43) that is used in (Bangalore et al. , 2001). 
In order to label the HH corpus of 1062 utterances, we started with 10 dialogues (305 utterances) labelled with the CSTAR dialogue act tagging scheme (Finke et al. , 1998; Doran et al. , 2001). 
In (Walker et al. , 2001), we evaluate the performance of the learning component of SPOT, and show that SPOT learns to select sentence plans that are highly rated by the two human judges. 
Two kinds of TAG grammar are used in (Bangalore et al. , 2001). 
(Bangalore et al. , 2001) experimentally determine how the quality and quantity of the resources used in training FERGUS a ect the output quality of the generator. 
