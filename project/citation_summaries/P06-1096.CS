Alignment is often used in training both generative and discriminative models (Brown et al., 1993; Blunsom et al., 2008; Liang et al., 2006). 
In this method, each training sentence is decoded and weights are updated at every iteration (Liang et al. , 2006). 
Tillmann and Zhang (2006), Liang et al. 
Forced decoding arises in online discriminative training, where model updates are made toward the most likely derivation of a gold translation (Liang et al., 2006). 
This makes it suitable for discriminative SMT training, which is still a challenge for large parameter sets (Tillmann and Zhang, 2006; Liang et al. , 2006). 
