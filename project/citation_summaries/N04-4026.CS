In view of content-independency of the distortion and flat reordering models, several researchers (Och et al. , 2004; Tillmann, 2004; Kumar et al. , 2005; Koehn et al. , 2005) proposed a more powerful model called lexicalized reordering model that is phrase dependent. 
However, their decoder is outperformed by phrase-based decoders such as (Koehn, 2004), (Och et al. , 1999), and (Tillmann and Ney, 2003). 
A DP-based beam search procedure identical to the one used in (Tillmann, 2004) is used to maximize over all oriented block segmentations a14 a9a88a16a18 a19 a10 a16a18 a21 . During decoding orientation bigrams a14 a9 a11 a19 a78 a19a43a9a107a21 with left orientation are only generated if a74a157a158 a14 a9a107a21a166a165 a152 for the successor block a9 . 3 Localized Block Model and Discriminative Training In this section, we describe the components used to compute the block bigram probability a27 a14 a9 a24 a19 a10 a24a17a29 a9 a24a31a30 a18 a19 a10 a24a31a30 a18 a21 in Eq. 
IBM constraints (Berger et al., 1996), the lexical word reordering model (Tillmann, 2004), and inversion transduction grammar (ITG) constraints (Wu, 1995; Wu, 1997) belong to this type of approach. 
Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn  et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008). 
