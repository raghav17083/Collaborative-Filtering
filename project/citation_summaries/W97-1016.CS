The results are compared with a maximum-entropy method (Ratnaparkhi et al. , 1994), transformation-based learning (TBL, Brill and Resnik (1994)), an instantiation of the backoff estimation (Collins and Brooks, 1995) and a memory-based method (Zavrel et al. , 1997). 
The TiMBL algorithm has already been used for various NLP tasks including part-of-speech tagging and PP-attachment (Daelemans et al. 1996; Zavrel, Daelemans, and Veenstra 1997). 
PP-Attachment Accuracies of Previous Work method accuracy our method SVM 87.25% supervised Ratnaphakhi et al., 1994 ME 81.6% Brill and Resnik, 1994 TBL 81.9% Collins and Brooks, 1995 back-o 84.5% Zavrel et al., 1997 NN 84.4% Stetina and Nagao, 1997 DT 88.1% Abney et al., 1999 boosting 84.6% Vanschoenwinkel and Manderick, 2003 SVM 84.8% Zhao and Lin, 2004 NN 86.5% unsupervised Ratnaparkhi, 1998 81.9% Pantel and Lin, 2000 84.3% ME: Maximum Entropy, TBL: Transformation-Based Learning, DT: Decision Tree, NN: Nearest Neighbor configurations (McNemars test; p<0.05). 
based methods (Zavrel et al. , 1997), linear classifiers (Roth, 1998; Roth, 1999) and transformationbased learning (Brill, 1995). 
Previous applications of 5Memory-based learning has recently been applied to a variety of NLP classification tasks, including part-of-speech tagging, noun phrase chunking, grapheme-phoneme conversion, word sense disambiguation, and PP attachment (see (Daelemans et al. , 1999; Veenstra et al. , 2000; Zavrel et al. , 1997) for details). 
