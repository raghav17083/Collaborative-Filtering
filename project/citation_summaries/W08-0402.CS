Li and Khudanpur (2008) report significant improvements in translation speed by taking unseen ngrams into account within cube pruning to minimize language model requests. 
The toolkit has been used to translate roughly a million sentences in a parallel corpus for largescale discriminative training experiments (Li and Khudanpur, 2008a). 
Li and Khudanpur (2008) report significant improvements in translation speed by taking unseen n-grams into account within cube pruning to minimize language model requests. 
Additionally, parallel and distributed computing techniques are exploited to make it scalable (Li and Khudanpur, 2008b). 
It is written in Java and implements all the essential algorithms described in Chiang (2007) and Li and Khudanpur (2008b): chart-parsing, n-gram language model integration, beamand cube-pruning, and k-best extraction. 
