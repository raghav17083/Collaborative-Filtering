c 2009 ACL and AFNLP A Comparison of Model Free versus Model Intensive Approaches to Sentence Compression Tadashi Nomoto National Institute of Japanese Literature 10-3 Midori Tachikawa Tokyo 190-0014 Japan nomoto@acm.org Abstract This work introduces a model free approach to sentence compression, which grew out of ideas from Nomoto (2008), and examines how it compares to a state-of-art model intensive approach known as Tree-to-Tree Transducer, or T3 (Cohn and Lapata, 2008). 
Different from prior research, Cohn and Lapata (2008) achieved sentence compression using a combination of several operations including word deletion, substitution, insertion, and reordering based on a statistical model, which is similar to our paraphrase generation process. 
7 T3 CohnandLapata(2008; 2009)arearecentattempt to bring a machine learning framework known as Structured SVM to bear on sentence compression and could be considered to be among the current state-of-art approaches. 
Another future direction is to extend our ILP formulations to more sophisticated models that go beyond word deletion, like the ones proposed by Cohn and Lapata (2008). 
Abstractive techniques in text summarization include sentence compression (Cohn and Lapata, 2008), headline generation (Soricut and Marcu, 2007), and canned-based generation (Oakes and Paice, 2001). 
