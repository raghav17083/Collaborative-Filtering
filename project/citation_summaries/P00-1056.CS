The standard evaluation metric within word alignment is the Alignment Error Rate (AER) (Och and Ney, 2000), which requires gold alignments that are marked as sure or probable. 
We make word alignments through the learning of IBM models by using the GIZA++ toolkit(Och and Ney, 2000): we learn the translation model toward IBM model 4, initiating translation iterations from IBM model 1 with intermediate HMM model iterations. 
4.2 Baseline System Training Using the toolkit Moses (Koehn et al., 2007), we built a phrase-based baseline system by following 429 the standard procedure: running GIZA++ (Och and Ney, 2000) in both directions, applying refinement rules to obtain a many-to-many word alignment, and then extracting and scoring phrases using heuristics (Och and Ney, 2004). 
For scoring the viterbi alignments of each system against goldstandard annotated alignments, we use the alignment error rate (AER) of Och and Ney (2000), which measures agreement at the level of pairs of words: AER = 1 jA \ GPj + jA \ GSjjAj + jG Sj where A is the set of word pairs aligned by the automatic system, GS is the set marked in the gold standard as sure, and GP is the set marked as possible (including the sure pairs). 
The language model is trained using the CMU-Cambridge toolkit and the translation model using the GIZA++ toolkit (Och and Ney, 2000). 
