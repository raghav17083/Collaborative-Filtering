,e verbs ts also causative (2b) The sentence~ m (3) use an object-dtop verb washed, the~e ','elt:,~ haxe a non-causaU~e tran'~ltl~,e/intransltl~,,e al\[elnltton in ~ hlch the object is sm~pl~ opttonal Both unergauves and unaccusatl~es \[la~e a causattve trans~u~e form, but differ m the semanuc roles that they assign to the paructpants m the e~ent described In an mtranstUve unetgaUve, the ',ubject ts an 4.gent Ithe doer of the e~ent), and m an Intransitive unaccusaUve, the subject ts a Theme (~omething affected by the e~ent) The role assignments to the corresponding semanuc arguments of the ttans~u~e forms--I e, the dnect objects--a~e the ~ame 16 with the addition of a Causal Agent (the causer of the event) as subject in both cases Object-drop verbs simply assign Agent to the subject and Theme to the optional object We expect the differing semantic role assignments of the verb classes to be reflected m their syntactic behavior, and consequently in the distributional data we collect from a corpus The three classes can be characterized by their occurrence in two alternations the transittve/mtrans~tive alternation and the causative alternation Unergatives are distinguished from the other classes m being rare in the transitive form (see (Stevenson and Merlo, 1997) for an explanation of this fact) Both unergatives and unaccusatives are dlstmgmshed from obJect-drop m being causative in their transitive form, and sundarly we expect this to be reflected in amount of detectable causative use Furthermore, since the caus&tlve is a transitive use, and the transitive use of unergatlves is expected to be rare, causativity should primarily distinguish unaccusatlves from objectdrops In conclusion, we expect the defining features of the verb classes--the intransitive/transitive and causative ~lternatlons--to lead to distributional differences m the observed usages of the verbs in these alternations 2 2 Psychollngmst~cally Relevant Features The verbs under study not only differ in their thematic properties, they also differ in their processmg properties Because these verbs can occur both in a trans~tive and an intransitive form, they have been particularly studied in the context of the mare verb/reduced relative (MV/I:tR) ambiguity illustrated below (Bever, 1970) The horse raced past the barn fell The verb ~aced can be interpreted as either a past tense main verb, or as a past participle w~thm a reduced relative clause (l e, the horse \[that was\] raced past the barn) Because fell is the main verb, the leduced relative lnterpretatmn of raced is required for a coherent analysis of the complete sentence But the main verb interpretation of raced is so strongly preferred that people experience great difficulty at the verb fell, unable to integrate it with the interpretation that has been developed to that point However, the reduced relative interpretation is not difficult for all verbs, as in the follo~mg example The boy washed in the tub was angry The difference in ease of interpreting the lesolutions of this ambiguity has been shown to be sensitive to both frequency differentials (MacDonald 1994, Trueswell, 1996) and to verb class d~stmctmns (Stevenson and Merlo, 1997, Flhp et al, 1999) Consider the features that d~stmguish the t~o resolutions of the M\,/RR ambiguity MV The horse raced past the barn quickly RR The horse raced past the barn fell In the main verb resolution, the ambiguous ~erb raced is used in its intransitive form, while in the reduced relative, it is used in its transitive, causative form These features correspond directly to the defining alternations of the three verb classes under study (intransitive/transitive, causative) ~,ddltionally, we see that other related features to these usages serve to distinguish the two resolutions of the ambiguity The mare verb form Is active and a mare verb part-of-speech (labeled as VBD by automatic POS taggers), by contrast, the reduced relative foim is passive and a past partic~ple (tagged as \ BN) Since these features (active/passive and VBD/VBN) are related to the intransitive/transitive alteination, we expect them to also exhibit d~stributloaal differences among the verb classes Specifically, ~e expect the unergatives to yield a higher proportion of act~ e and "vBD usage, since, as noted above, the transitive use of unergatwes is rare 3 Frequency Distributions of the Features We assume that currently available large cotpoLa are a reasonable approximation to language (Pullum, 1996) Using a combined corpus of 65-mllhon words, we measured the relative frequenc) distributions of the four linguistic features (VBD/~ BN active/passive, Intransitive/transitive, causative/noncausative) over a sample of verbs from the three lextcal semantic classes 3 1 Materials ~e chose a set of 20 verbs from each class based pllmaidy on the classfficatlon of verbs m (Le~ m 1993) (see Appendl~ ~) The uneigatlves ale maanei oI motion verbs The unaccusatl~es ale ~erbs of~haage of state The object-drop verbs are unspecified object alternation verbs The ~e~bs ~ere sele~Led flora Lenin's classes based on their absolute fiequenc} Ful thermore, they do not generally sho~ ma~l~ e depaitures from the intended verb sense m the cotpu~ (Though note that there are only 19 unaccu~atlxes because,zpped, ~hlch ~as initially counted m the unaccusatives, was then excluded from the aaal~sis as It occurred mostly in a different usage m the corpus, as a velb plus paltlcle ) Most of the vetb~ can occur m the transitive and in the passive Each ~erb presents the ~ame folm m the simple pa~t and m the past palticlple In order to smlphf~ the ~ouat17 mg procedure, we made the assumptron that counts on this single verb form would approximate the distribution of the features across all forms of the verb Most counts were performed on the tagged versron of the Brown Corpus and on the portion of the Wall Street Journal distmbuted by the ACL/DCI (years 1987, 1988, 1989), a combined corpus m excess of 65 mdhon words, with the exceptmn of causatrvlty which was counted only for the 1988 year of the WSJ, a corpus of 29 million words 3 2 Method We counted the occurrences of each verb token in a transrtlve or mt~ansltr~e use (INTR), m an active or passive use (ACT), rn a past pamcrple or smaple past use (VBD), and in a causative or non-causative use (CAUS) More precrsely, features were counted as follows INTR a verb occurrence was counted as transrtlve if rmmediately followed by a nominal group, else rt was counted as mtransitrve ACT mare verbs (tagged VBD) were counted as actrve, participles (tagged V BN) counted as actrve ff the closest preceding auxiliary was have, as passive ff the closest preceding auxiliary was be VBD occurrences tagged VBD were simple past, VBN were past participle (Each of the above three counts was normalized over all occurrences of the verb, yielding a single relative frequency measure for each verb for that feature ) CAUS The causative feature was approximated by the followmg steps Frrst, for each verb, all cooccurrmg subjects and objects were extracted from a parsed corpus (Colhns, 1997) Then the proportmn of overlap between the two multrsets of nouns was calculated, meant to capture the causative alternation, ~here the subject of the mtransrtrve can occur as the object of the trans~trve Vve define overlap as the largest multiset of elements belongmg to both the subjects and the object multisets, eg {a,a,a,b}(3 {a} = {a,a,a} The proportron is the ratio between the o~erlap and the sum of the subject and object multrsets (For example, for the rumple sets above, the ratio would be 3/5 or 60 ) All ra~ and normahzed corpus data ale a~adable from the authors, and more detarl concerning data collectron can be found m (Stevenson and Merto, 1999) 4 Experiments in Verb Classification The frequency drstnbutrons of the verb alternatmn features yield a vector for each verb that represents the relative frequency values for the verb on each drmensron, the set of 59 vectors constrtute the data for our machine learmng experiments Template \[verb, VBD, ACT, INTR, CADS, class\] Example \[opened, 79, 91, 31, 16, unacc\] Our goal was to determine whether automatm classfficatlon techniques could determine the class of a verb from the distributional propertms represented m this vector In related work (Stevenson and Merlo, 1999) ~e describe initial unsupervised and supervised lealnmg experiments on this data, and discuss the contllbutlon of the four different features (the frequenc.~ distributions) to accurac~ m verb classfficatlon In thzs paper, we extend the work in several ~ays Fu~t, ~e report further analysis of rephcauons of our mmal supervised learning results Next, we demonstrate srmdar performance using different training methods and learning algorithms, mdmatmg that the performance rs Independent of the particular learning approach Furthermore, these addrtronal e~penments allow us to evaluate the performance separately on each of the three verb classes Finally, based on tins evaluation, we suggest a new feature to better drstmgmsh the thematic propertms of the classes, and present experimental results showing that its use rmproves our original accuracy rate 4.1 Initml Experiments Imtial experiments were carried out using a decrsron tree induction algorithm, the C5 0 system avadable from http//www rulequest corn/ (Qumlan, 1992), to automatmally create a classfficatron program flora a training set of verb vectois with known classfficatron 2 In our earhei experiments ~e ran \[0-fold cross-vahdatrons repeated 10 times hele ~e repeat the ctoss-vahdatrons 50 tmles, and the numbeis tepolted are averages over all the tuns 3 Table 1 shows the results of our experiments on the four features we counted m the corpora (x BD ACT, INTR, CAUS), as well as all three-feature subsets of those four The basehne (chance) performance m th~s task rs 33 8%, since thele are 59 ~ectors and ~The s~stem generates both declsmn trees aml rule sets for use m classfficatmn Since the d~fferencc m petformance between the t~o zs ne~er s~gmficant ~xe repoKt here Jab the results using the extracted rules The rules provide a confidence level foz each classfficatmn ~ hmh Is unavailable with the decmon tree data structure 3A 10-fold cross-vahdatmn means that the s~stem randomly d~vldes the data into 10 parts, and runs 10 t~mes on a different 90%-tralmng-data/10%-test_data spht, ymldmg an average accuracy and standard enor Th~s procedure is then repeated for 50 different random dlvlsmns of the_ data and accurac3 and standard eIror are agam averaged across the 50 runs 18 Features Acc% SE% VBD ACT INTR CAUS 63 7 0 6 VBD INTR CAUS 62 7 0 6 ACT INTR CAUS 59 9 0 5 VBD ACT CAUS 56 8 0 5 VBD ACT INTR 54 5 0 5 f, Table 1 Percentage Accuracy (Acc%) and Standard Error (SE%) of C5 0 (33 8% baselrne) 3 possible classes (That is, assigning one of the two most common classes--of 20 verbs each--to all cases would ymld 20 out of 59 correct, or 33 8% ) As seen m the table, classrficatmn based on the four features performs at 63 7%, or 30% over chance The true mean of the sample cross-vahdatlons lies wd, hm plus or remus two standard errors of the reported mean (dr=49, t=2 01, p< 05) In all cases, the range is plus or mmus I0 or 12, yreldmg a very natrow predrcted accuracy range Furthermore, we performed t-tests comparing the results of the 50 crossvahdatmns for each of the different feature subsets All pairs were srgmficantly different (p< 05) except for the results using all four features (first row m the table) and those excluding ACT (second row m the table) We conclude that all features except ACT contribute posrtlvely to classrficatmn performance, and that ACT does not degrade performance In our rephcatrons, then, we focus on all four features 4 2 Rephcatmn with Different Training and Learning Methods There are conceptual and practical reasons for investigating the performance of other training approaches and learning algorithms applied to our verb distribution data Conceptually, it is desrrable to know whether a particular learning algorithm or training techmque affects the level of performance Practically, drfferent methods enable us to evaluate more easily the performance of the classification method within each verb class (When we run repeated cross-validations with t keg.C5 0system, we don't have access to the accuracy rage for each class, the system only outputs an overall mean error rate ) To preview, we find that the different training and learning methods we tried all, gave similar performance to our original results, and m addltron allowed us to evaluate the accuracy wlthrn each verb class In one set of experiments, we used the same C5 0 system, but employed a training and testing methodology that used a single hold-out case We held out a single verb vector, trained on the remaining,58 cases, then tested the resulting classffier on the II Classes \[\[ All Classes I Unergatv~e Unaccusatwe I ObjectDrop Percent ~ccuracy 61 0 75 0 57 9 50 0 Table 2 Percentage Accuracy of C5 0 With Single Hold-Out Training single hold-out case, and recorded the collect and assigned classes for that verb Tius was then zepeated for each of the 59 verbs This approach ~ raids both an overall accuracy rate (when the results are averaged across all 59 trials), as well as pio~ldmg the data necessary for determining accuracy fol each verb class (because we have the classification of each verb when It is the test case) The results ale presented m Table 2 The overall accuracy IS a little less than that achieved with the 10-fold cross-validation methodology (61 0% versus 63 7%) However, we can see clearly now that the unergatlve verbs ate dassffied with much greater accuracy (75%), Mule the unaccusatwe and obJect-drop verbs are classified with much lower accuracy (57 9% and 50% respectrvely) The distributional features we have appear to be much better at dmtmgmshmg unergatwes than unaccusatlve or obJect-drop verbs To test thrs drrectly under our original tiammg assumptrons, we ran two different experiments, u~mg 10-fold cross-vahdation repeated 10 time~ The first experiment tested the abdit:~ of the classifier to distinguish between unergatlves and the other t~o verb types, wrthout having to distinguish bct~een the latter two The data included the 20 unergarive,,erbs and a random sample of 10 unaccusatave and 10 obJect-drop verbs, 10 different random ~ampies were selected to form 10 such data sets In these data sets, the ~erbs were labeled as unergatire or "of;her" The baseline (chance) classzficatmn accuracy for this data is 50%, the mean accmac~ achmved across all data sets was 78 5% (standard ellot 0 8%), a srzable improvement o~er chance The second expeim~ent ~as intended to det, etmme ho~ well the classifier can dlstmgm~h.unaccusatl~e from object-drop verbs The data consisted of one ~et that included all the unaccusative and object-drop verbs, with no unergatives Because there ate only i9 unaceusauve verbs, the basehne accuracy late is 51% (20/39), here the classifier achieved an accuracy only slightly above chance, at 58 3% (standard elror 1 8%) These results, summarized in Table 3 clearly confirm the higher accuracy of classifying uneigatlvo verbs with the current feature set This pattern of results ~as repeated under a ~oi3 19 Classes Acc% SE% \[I Unergatlve vs Other 78 5 0 8 \] Unaccusatlve vs ObjectDrop 58 3 1 8 I Table 3 Percentage Accuracy (Ace%) and Standard Error (SE%) of C5 0 (50-51% baseline) II Cl es \[PCA%\[ FMP% II \[l All Classes \[ 65 0 1 63 9 II Unergatlve 85 0 71 7 Unaccusative 60 0 55 0 ObjectDrop 50 0 65 0 Table 4 Percentage Accuracy of PCA (PCA%) and Feature Map (FMP%) Neural Networks different type of learning algorithm as well We performed a set of neural network experiments, using NeuroSolutlons 3 0 (see http//www nd corn), and report here on the networks that achieve the best performance on our data These are principal components analysis and automatic feature map networks, which are essentially feed-forward perceptrons with pre-processmg units that transform the existing features rata a more useful format In our tests, both methods performed best overall when there were no hidden layer units, and the networks were trained for 1000 epochs The mean accuracy rates of 10-fold cross-validations with these parameter settings are summarized in Table 4 Again, the overall percentage accuracy is in the low sixties, with better performance on the unergattves than on the other two verb classes, the difference was particularly striking with the PCA networks This overall pattern doesn't change with further training, in fact, training up to 10,000 epochs resulted in very low accuracy (of 45%) for either unaccusatives, objectdrops, or both To summarize, following a different training approach with C5 0 (the single hold-out method), and applying very different learning approaches (two kinds of neural networks), resulted in mmllai o~erall performance to our original C5 0 results This indicates that the accurac3 achieved is at lea.st somewhat independent of specific learning or trainIng techniques Moreover, these different methods, along with experiments directly testing unergative versus unaccusatlve/object-drop classification, allow us to examine more closely where the resulting classifters have the most serious problems In all cases, the accuracy is best for unergattves, and the accuracy of unaccusatives, object-drops, or both, is degraded If this performance is indeed a reliable mdiClasses Unerg vs Unacc Uaerg vs ObjDrop Unacc vs ObjDrop I vBo I AcT I INTR I CAI'S II ns ns ** * *** p< 001 ** p< 01 * p_< 05 as non-significant Table 5 Significance Levels of T-Tests Comparing Feature Values Between Verb Classes cation of the inherent dtscnmmabd~ty of tile dastnbutlonal data, then we must examine more closely the properties of the data itself to understand (and potentially improve) the performance 4 3 Dsscrlmmatmg Unaccusative and ObJect-Drop Verbs To understand why the data discriminates unergattves reasonably well, but not unaccusatlves and object-drops, we need to directly test the discnminabilityof the features across the classes We do so by using t-tests to compare the values of the different features--VBD, ACT, INTR. 
Clustering methods have also been extensively researched for verb classification (Stevenson and Merlo, 1999; Schulte im Walde, 2000; McCarthy, 2001; Korhonen, 2002; Korhonen et al., 2003; Schulte im Walde, 2003). 
This approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of Baldwin and Bond (2003) and Stevenson and Merlo (1999). 
3 Which frequency dlstnbuUons work best to distinguish the verb classes ~ In exploring these quesUons, we focus on verb classlficaUon for several reasons Verbs are very important sources of knowledge in many language engineering tasks, and the relationships among verbs appear to play a major role m the orgamzatmn and use of this knowledge Knowledge about verb classes is crucml for lex,cal acqmsltton m support of language generation and machine translatmn (Dolt, 1997) and document cl~sfficatmn (Klavans and Kan, 1998), yet manual classfficauon of large numbers of verbs is a difficult and resource intensive task (Levm, 1993 Miller et al, 1990, Dang et al, 1998) To address these issues, we suggest that one can tram an automatic classffier for verbs on the basts of staUstmal approxlmaUons to verb dlatheses We use dlatheses--alternatmns m the expression of the arguments of the verb--following Levm and Dorr, for two reasons Fnst, verb dlatheses are syntacuc cues 1 We are aware that a dlstnbutmnal approach rests on one strong assumptmn regarding the nature of the representatmns under study semantic notmns and syntacuc notmns are correlated, at least m part This assurapuon is under debate (Bnscoe and Copestake, 1995, Levm, 1993, Dorr and Jones, 1996, Dorr, 1997), but we adopt ~t here without further dlscussmn 15 '  to semantic classes, hence they can be more easily captured by corpus-based techniques Second, using verb d~atheses reduces no,se There ~s a certain consensus (Bnscoe and Copestake, 1995, Pustejovsky, 1995, Palmer, 1999) that verb dmtheses are regular sense extensmns Hence focussing on thin type of classfficatmn allows one to abstract from the problem of word sense dmamb,guatmn and treat remdual d~fferences m word senses as no~se m the classfficatmn task We present an m-depth case study, m which we apply machine learning techmques to automaUcally classify a set of verbs based on d~stnbutmns of grammaucal indicators of dmtheses, extracted from a very large corpus We look at three very mterestmg classes of verbs unergaUves, unaccusauves, and obJect-drop verbs (Levm, 1993) These are Interestmg classes because they all parUcapate m the trans~uvlty alternatmn, and they are minimal parrs that as, a small number of well-defined dmtmctmns d~fferentmte their trans,tlve/mtranmUve behavmr Thus, we expect the differences m their dmtnbuttons to be small, entailing a fine-grained dlscr,mmaUon task that prowdes a challenging testbed for automatic classfficatmn The specffic theoretical questmn we mvesUgate ~s whether the factors underlying the verb class dmtmctmns are reflected m the statmttcal dmtnbutmns of lex~cal features related to dmtheses presented by the md,v~dual verbs m the corpus In doing th~s, we address the questmns above by determining what are the lexmal features that could d~stmgmsh the behavtor of the classes of verbs w~th respect to the relevant dmtheses, ~hmh of those features can be gleaned from the corpus, and which of those, once the staUstmal dmtnbutmns are available, can be used successfully by an automatic classifier In m~ttal work (Stevenson and Merlo, 1999), ~e found that hngmstlcally motivated features that d~stmgmsh the verb classes can be extracted from an annotated, and m one case parsed, corpus These features are sufficient to almost halve the error rate compared to chance (45% reductmn) m automaUc verb classtficaUon, suggesting that d~stnbuUonal data prowdes knowledge useful to the class~ficaUon of verbs The focus of our original stud~ was tho demonstration m prmctple of l~a.nmg verb classes from frequency d~stnbutmns ofsyntactm features, and an analysm of the relaUve contrtbutmn of the various features to learmng Th~s paper turns to the nnportant next steps of rephcatmg our findrags using other training methods and learning algorithms, and analyzing the performance on each of tbe three classes of verbs This more detailed analys~s of accuracy within each class m turn leads to the development of a new dlstrtbutmnal feature mtended to improve dlscnmmabthty among t~o of the classes The addltmn of the ne~ feature successfully reduces the error rate of out mltml results m classlficatmn by 19%, for a 56% overall reductmn m error rate compared to chance 2 Determining the Features In this sectmn, we present mouvatmn for the mttml features that we mvesUgated m terms of their role m learmng the verb classes We first present the hngmstlcally den~ed features then turn to e~tdence from experimental psychohngutstlcs to e\tend the set of potentially relevant features 2.1 Features of the Velb Classes The three verb classes under mvesugatmn unergaUves, unaccusaUves, and object-drop -differ m the properties of their translttve/mtranslhve a\[ternaUons, which are exemphfied below UnergaUve (la) The horse raced past the barn (lb) The jockey raced the horse past the barn Wnaccusatave (2a) The butter melted m the pan (2b) The cook melted the butter m the pan ObJect-drop (3a) The boy washed the hall (3b) The boy washed The sentences m (1) use an unergatwe vvelb. 
There has also been some work on both clustering and supervised classification of verbs based on their alternation behavior (Stevenson and Merlo, 1999; Schulte im Walde, 2000; Merlo and Stevenson, 2001). 
