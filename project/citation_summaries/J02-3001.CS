In their seminal proposal, Gildea and Jurafsky (2002) approached the task using various features such as headword, phrase type, and parse tree path. 
produced by a semantic role labeling system (c.f. , Gildea and Jurafsky, 2002). 
An important baseline study of this process has recently appeared in the literature (Gildea and Jurafsky, 2002). 
Thetaskofsemanticrolelabelling(SRL),ashas been defined by previous researchers (Gildea and Jurafsky, 2002), requires collecting all the arguments that together with a verb form a predicateargument structure. 
Gildea and Jurafsky (2002) presented a compact set of features across these three types, which has served as the core of most of the subsequent SRL work: (1) the phrase type, headword, and governing category of the constituent; (2) the lemma, voice, and subcategorization pattern of the verb; and (3) the left/right position of the constituent with respect to the verb, and the category path between them.Extensions to these features have been proposed in various directions.Exploiting the ability of some machine learning algorithms to work with very large feature spaces, some authors have largely extended the representation of the constituent and its context, including among others: rst and last words (and part-of-speech) in the constituent, bag-of-words, n-grams of part of speech, and sequence of top syntactic elements in the constituent.Parent and sibling constituents in the tree may also be codied with all the previous structural and lexical features (Pradhan et al.2005a; Surdeanu et al.2007).Other authors have designed new features with specic linguistic motivations.For instance, Surdeanu et al.(2003) generalized the concept of headword with the content word feature.They also used named entity labels as features.Xue and Palmer (2004) presented the syntactic frame feature, which captures the overall sentence structure using the verb predicate and the constituent as pivots.All these features resulted in a signicant increase in performance. 
