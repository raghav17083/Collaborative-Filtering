Thereafter, we employ the standard CTK (Collins and Duffy, 2001) to compute the similarity between two UPSTs, since this CTK and its variations are successfully applied in syntactic parsing, semantic role labeling (Moschitti, 2004) and relation extraction (Zhang et al., 2006; Zhou et al., 2007) as well. 
While kernel methods using the dependency tree (Culotta and Sorensen, 2004) and the shortest dependency path (Bunescu and Mooney, 2005) suffer from low recall performance, convolution tree kernels (Zhang et al., 2006; Zhou et al., 2007) over syntactic parse trees achieve comparable or even better performance than feature-based methods. 
Systems P(%) R(%) F Ours: composite kernel 83.0 72.0 77.1 Zhou et al., (2007): composite kernel 82.2 70.2 75.8 Zhang et al., (2006): composite kernel 76.1 68.4 72.1 Zhao and Grishman, (2005): 4 composite kernel 69.2 70.5 70.4 Ours: CTK with UPST 80.1 70.7 75.1 Zhou et al., (2007): contextsensitive CTK with CS-SPT 81.1 66.7 73.2 Zhang et al., (2006): CTK with SPT 74.1 62.4 67.7 Table 4. 
ACE systems then extract a wide variety of lexical, syntactic, and semantic features, and use supervised classifiers to label the relation mention holding between a given pair of entities in a test set sentence, optionally combining relation mentions (Zhou et al., 2005; Zhou et al., 2007; Surdeanu and Ciaramita, 2007). 
Comparison of different systems on the ACE RDC 2004 corpus 3  We arrive at these values by subtracting P/R/F (79.6/5.6/71.9) of Shortest-enclosed Path Tree from P/R/F (81.1/6.7/73.2) of Dynamic Context-Sensitive Shortestenclosed Path Tree according to Table 2 (Zhou et al., 2007) 4  There might be some typing errors for the performance reported in Zhao and Grishman (2005) since P, R and F do not match. 
