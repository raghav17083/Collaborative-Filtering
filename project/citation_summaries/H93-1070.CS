3.1 Term weighting models The standard term weighting model is defined by chosing a set of parameters {c~ij } (one for each worddescriptor pair) and {fli} (one for each desc,'iptor) so that a likelihood or appropriateness function, /2, can be defined by C(alw) = (1) wEW This has been widely used, and is provably equivalent to a large class of probabilistic models (e.g. Van Risjbergen, 1979) which make various assumptions about the independence between descriptors and diagnostic units (Fuhr & Buckley, 1993). 
The performance of cross-language information retrieval with a uniform T is likely to be limited in the same way as the performance of conventional information retrieval without term-frequency information, i.e., where the system knows which terms occur in which documents, but not how often (Buckley 1993). 
Nevertheless, the problem of estimating the huge number of parameters needed for such a model is statistically problematic, and as Buckley (1993) points out, the choice of weights has a large influence on the effectiveness of any model for classification or for retrieval. 
uk Abstract The use of NLP techniques for document classification has not produced significant improvements in performance within the standard term weighting statistical assignment paradigm (Fagan 1987; Lewis, 1992bc; Buckley, 1993). 
Various strategies for estimating the parameters for this model have been proposed (e.g. Salton & Yang, 1973, Buckley 1993, Fuhr & Buekley, 1993). 
