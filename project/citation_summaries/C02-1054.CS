D09-1119:1	64:258	SVMs with a polynomial kernel of degree 2 were shown to provide state-of-the-art performance in many NLP application, see for example (Kudo and Matsumoto, 2000; Nivre et al., 2006; Isozaki and Kazawa, 2002; Goldberg et al., 2006).
---------------------------------------------------
I08-1044:2	15:215	Statistical methods often suffer from the problem of data sparsity, and machine learning approaches (e.g., Hidden Markov Models (HMMs) (Bikel et al., 1999; Zhou and Su, 2002), Support Vector Machines (SVMs) (Isozaki and Kazawa, 2002), Maximum Entropy (MaxEnt) (Borthwick, 1999; Chieu and Ng, 2003), Transformation-based Learning (TBL) (Brill, 1995) or variants of them) might be unsatisfactory to learn linguistic information in Chinese NEs.
---------------------------------------------------
P03-1004:3	158:242	Isozaki et al. propose an XQK (eXpand the Quadratic Kernel) which can make their Named-Entity recognizer drastically fast (Isozaki and Kazawa, 2002).
---------------------------------------------------
P03-1004:4	53:242	This property is critical and some reports say that, in NLP, the polynomial kernel outperforms the simple linear kernel (Kudo and Matsumoto, 2000; Isozaki and Kazawa, 2002).
---------------------------------------------------
P03-1004:5	10:242	Examples include Part-of-Speech tagging (Nakagawa et al. , 2002) Text Chunking (Kudo and Matsumoto, 2001), Named Entity Recognition (Isozaki and Kazawa, 2002), and Japanese Dependency Parsing (Kudo and Matsumoto, 2000; Kudo and Matsumoto, 2002).
---------------------------------------------------
P03-1004:6	20:242	For example, an SVM-based NE-chunker runs at a rate of only 85 byte/sec, while previous rulebased system can process several kilobytes per second (Isozaki and Kazawa, 2002).
---------------------------------------------------
N03-1002:7	22:203	Isozaki (Isozaki and Kazawa, 2002) controls the parameters of a statistical morphological analyzer so as to produce more fine-grained output.
---------------------------------------------------
N03-1002:8	153:203	Isozaki (Isozaki and Kazawa, 2002) introduces the thesaurus  NTT Goi Taikei (Ikehara et al. , 1999)  to augment the Table 5: The depth of redundant analysis and the extraction accuracy Pair Wise Method Depth of morph.
---------------------------------------------------
C04-1040:9	18:230	Figure 1: A word dependency tree ferent tasks of Natural Language Processing (Kudo and Matsumoto, 2001; Isozaki and Kazawa, 2002).
---------------------------------------------------
C04-1040:10	219:230	(Since we used Isozakis methods (Isozaki and Kazawa, 2002), the run-time complexity is not a problem.)
---------------------------------------------------
I05-3013:11	76:246	The latter is currently dominating in NER amongst which the most popular methods are decision tree (Sekine et al. , 1998; Pailouras et al. , 2000), Hidden Markov Model (Zhang et al. , 2003; Zhao, 2004), maximum entropy (Chieu and Ng, 2002; Bender et al. , 2003), and support vector machines (Isozaki and Kazawa, 2002; Takeuchi and Collier, 2002; Mayfield, 2003).
---------------------------------------------------
P08-2060:12	50:114	However, even the sparse-representation version of w tends to be very large: (Isozaki and Kazawa, 2002) report that some of their second degree expanded NER models were more than 80 times slower to load than the original models (and 224 times faster to classify).1 This approach obviously does not scale well, both to tasks with more features and to larger degree kernels.
---------------------------------------------------
P08-2060:13	87:114	Thus, only pairs of common features appear in the resulting weight vector using the same expansion as in (Kudo and Matsumoto, 2003; Isozaki and Kazawa, 2002).
---------------------------------------------------
P08-2060:14	46:114	Kernel Expansion (Isozaki and Kazawa, 2002) is used to transform the d-degree polynomial kernel based classifier into a linear one, with a modified decision function y(x) = sgn(wxd + b).
---------------------------------------------------
P08-2060:15	48:114	(the calculation details appear in (Isozaki and Kazawa, 2002; Kudo and Matsumoto, 2003)).
---------------------------------------------------
P08-2060:16	31:114	In natural language applications, the size|SV|tends to be very large (Isozaki and Kazawa, 2002), often above 10,000.
---------------------------------------------------
P08-2060:17	10:114	For this reason, research effort was directed at speeding up the classification process of polynomial-kernel SVMs (Isozaki and Kazawa, 2002; Kudo and Matsumoto, 2003; Wu et al., 2007).
---------------------------------------------------
W03-1024:18	92:257	For this task, we use a named entity recognizer (Isozaki and Kazawa, 2002).
---------------------------------------------------
W03-1024:19	153:257	Support Vector Machines (SVMs) have shown good performance in various tasks in Natural Language Processing (Kudo and Matsumoto, 2001; Isozaki and Kazawa, 2002; Hirao et al. , 2002).
---------------------------------------------------
W03-1208:20	125:156	Words, chunks and their relations in the texts were analyzed by CaboCha (Kudo and Matsumoto, 2002), and named entities were analyzed by the SVM-based NE tagger (Isozaki and Kazawa, 2002).
---------------------------------------------------
P06-1078:21	17:177	On the other hand, in text-based NER, better results are obtained using discriminative schemes such as maximum entropy (ME) models (Borthwick, 1999; Chieu and Ng, 2003), support vector machines (SVMs) (Isozaki and Kazawa, 2002), and conditional random fields (CRFs) (McCallum and Li, 2003).
---------------------------------------------------
P06-1078:22	29:177	In this paper, we employ an SVM-based NER method in the following way that showed good NER performance in Japanese (Isozaki and Kazawa, 2002).
---------------------------------------------------
W06-1660:23	10:202	The relevant algorithms include Maximum Entropy (Borthwick, 1999; Klein et al. , 2003), Hidden Markov Model (HMM) (Bikel et al. , 1999; Klein et al. , 2003), AdaBoost (Carreras et al. , 2003), Memorybased learning (Meulder and Daelemans, 2003), Support Vector Machine (Isozaki and Kazawa, 2002), Robust Risk Minimization (RRM) Classification method (Florian et al. , 2003), etc. For Chinese NER, most of the existing approaches use hand-crafted rules with word (or character) frequency statistics.
---------------------------------------------------
P04-1081:24	98:119	4.2 KPCA versus SVM models Support vector machines (e.g. , Vapnik (1995), Joachims (1998)) are a different kind of kernel method that, unlike KPCA methods, have already gained high popularity for NLP applications (e.g. , Takamura and Matsumoto (2001), Isozaki and Kazawa (2002), Mayfield et al.
---------------------------------------------------
P03-1005:25	106:148	The chunks and their relations in the texts were analyzed by cabocha (Kudo and Matsumoto, 2002), and named entities were analyzed by the method of (Isozaki and Kazawa, 2002).
---------------------------------------------------
I08-5007:26	18:229	2 Approaches to NER There has been a considerable amount of work on NER in English (Isozaki and Kazawa, 2002; Zhang and Johnson, 2003; Petasis et al., 2001; Mikheev et al., 1999).
---------------------------------------------------
W05-0610:27	20:275	, 2002), the SVM (Isozaki and Kazawa, 2002; May eld et al. , 2003), and Perceptron (Carreras et al. , 2003).
---------------------------------------------------
W05-0610:28	39:275	Isozaki and Kazawa (2002) compared three commonly used methods for named entity recognition the SVM with quadratic kernel, maximal entropy method, and a rule based learning system, and showed that the SVM-based system performed better than the other two.
---------------------------------------------------
D09-1160:29	29:244	Examples include not only log-linear models but also support vector machines with kernel expansion (Isozaki and Kazawa, 2002; Kudo and Matsumoto, 2003).
---------------------------------------------------
D09-1160:30	12:244	The kernelbased classification is, however, known to be very slow in NLP tasks, so efficient classifiers should sum up the weights of the explicit conjunctive features (Isozaki and Kazawa, 2002; Kudo and Matsumoto, 2003; Goldberg and Elhadad, 2008).
---------------------------------------------------
D09-1160:31	53:244	Kernel expansion (KE) was proposed by Isozaki and Kazawa (2002) to convert Eq.
---------------------------------------------------
P07-2017:32	8:97	They yielded very competitive and satisfactory performance in many classification tasks, such as part-of-speech (POS) tagging (Gimenez and Marquez, 2003), shallow parsing (Kudo and Matsumoto, 2001, 2004; Lee and Wu, 2007), named entity recognition (Isozaki and Kazawa, 2002), and parsing (Nivre et al. , 2006).
---------------------------------------------------
P07-2017:33	38:97	In particular to the use of polynomial kernel-based SVM, it was shown to be the most successful kernels for many natural language processing (NLP) problems (Kudo and Matsumoto, 2001; Isozaki and Kazawa, 2002; Nivre et al. , 2006).
---------------------------------------------------
