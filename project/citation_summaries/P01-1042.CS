Generative and discriminative models have been comparedanddiscussedagreatdeal(NgandJordan, 2002), including for NLP models (Johnson, 2001; Klein and Manning, 2002). 
Discriminative parsing has been investigated before, such as in Johnson (2001), Clark and Curran (2004), Henderson (2004), Koo and Collins (2005), Turian et al. 
The generative-all results were trained on all sentences regardless of length 6 Comparison With Related Work The most similar related work is (Johnson, 2001), which did discriminative training of a generative PCFG. 
Heemans (1998) POS LM achieves a perplexity reduction compared to a trigram LM by instead rede ning the speech recognition problem as determining: W ;T = arg max W;T P(W;TjA) = arg max W;T P(W;T)P(AjW;T) arg max W;T P(W;T)P(AjW) where T is the POS sequence t N 1 associated with the word sequence W = w N 1 given the speech utterance A.TheLMP(W;T)isajoint probabilistic model that accounts for both the sequence of words w N 1 and their tag assignments t N 1 by estimating the joint probabilities of words and tags: P(w N 1 ;t N 1 )= N Y i=1 P(w i ;t i jw i1 1 ;t i1 1 )(2) Johnson (2001) and La erty et al. 
However, the advantage of the discriminative models can be very slight (Johnson, 2001) and for small training set sizes generative models can be better because they need fewer training samples to converge to the optimal parameter setting (Ng and Jordan, 2002). 
