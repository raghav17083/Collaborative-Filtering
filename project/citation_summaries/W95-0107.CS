W06-0113:1	19:224	Ramshaw and Marcus (1995) first introduced the machine learning techniques to chunking problem.
---------------------------------------------------
W06-0113:2	204:224	6 Related works After the work of Ramshaw and Marcus (1995), many machine learning techniques have been applied to the basic chunking task, such as Support Vector Machines (Kudo and Matsumoto, 2001), Hidden Markov Model(Molina and Pla 2002), Memory Based Learning (Sang, 2002), Conditional Random Fields (Sha and Pereira, 2003), and so on.
---------------------------------------------------
D09-1119:3	123:258	5.2 NP Chunking The goal of this task (Marcus and Ramshaw, 1995) is the identification of non-recursive NPs.
---------------------------------------------------
D09-1119:4	24:258	1142 We show that by using a variant of SVM  Anchored SVM Learning (Goldberg and Elhadad, 2007) with a polynomial kernel, one can learn accurate models for English NP-chunking (Marcus and Ramshaw, 1995), base-phrase chunking (CoNLL 2000), and Dutch Named Entity Recognition (CoNLL 2002), on a heavily pruned feature space.
---------------------------------------------------
P06-1028:5	123:242	These tasks are generally treated as sequential labeling problems incorporating the IOB tagging scheme (Ramshaw and Marcus, 1995).
---------------------------------------------------
W01-0908:6	52:179	Wall-Street Journal (WSJ) Sections 15-18 and 20 were used by Ramshaw and Marcus (1995) as training and test data respectively for evaluating their base-NP chunker.
---------------------------------------------------
W99-0621:7	161:205	This is similar to results in the literature (Ramshaw and Marcus, 1995).
---------------------------------------------------
W99-0621:8	25:205	These problems formulations are similar to those studied in (Ramshaw and Marcus, 1995) and (Church, 1988; Argamon et al. , 1998), respectively.
---------------------------------------------------
W99-0621:9	59:205	Of the several slightly different definitions of a base NP in the literature we use for the purposes of this work the definition presented in (Ramshaw and Marcus, 1995) and used also by (Argamon et al. , 1998)and others.
---------------------------------------------------
W99-0621:10	9:205	The observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local part-of-speech information has motivated the use of learning methods to recognize these patterns (Church, 1988; Ramshaw and Marcus, 1995; Argamon et al. , 1998; Cardie and Pierce, 1998).
---------------------------------------------------
W99-0621:11	156:205	The results are comparable to other results reported using the Inside/Outside method (Ramshaw and Marcus, 1995) (see Table 7.
---------------------------------------------------
W99-0621:12	139:205	4 Methodology 4.1 Data In order to be able to compare our results with the results obtained by other researchers, we worked with the same data sets already used by (Ramshaw and Marcus, 1995; Argamon et al. , 1998) for NP and SV detection.
---------------------------------------------------
W99-0621:13	133:205	We do not consider mixed features between words and POS tags as in (l:tamshaw and Marcus, 1995), that is, a single feature consists of either words or tags.
---------------------------------------------------
W99-0621:14	191:205	Perhaps this was not observed earlier since (Ramshaw and Marcus, 1995) studied only base NPs, most of which are short.
---------------------------------------------------
W99-0621:15	142:205	Instead of using the NP bracketing information present in the tagged Treebank data, Ramshaw and Marcus modified the data so as to include bracketing information related only to the non-recursive, base NPs present in each sentence while the subject verb phrases were taken as is. The data sets include POS tag information generated by Ramshaw and Marcus using Brill's transformational part-of-speech tagger (Brill, 1995).
---------------------------------------------------
W99-0621:16	83:205	For example, the sentence I went to California last May would be marked for base NPs as: I went to California last May I 0 0 I B I indicating that the NPs are I, California and last May. This approach has been studied in (Ramshaw and Marcus, 1995).
---------------------------------------------------
P09-3007:17	103:186	As in the work of (Ramshaw and Marcus, 1995), each word or punctuation mark within a sentence is labeled with IOB tag together with its function type.
---------------------------------------------------
I08-5010:18	48:141	The general label sequence ln1 has the highest probability of occuring for the word sequence W n1 among all possible label sequences, that is Ln1 = argmax {Pr (Ln1 | W n1 ) } 3.2 Tagging Scheme We followed the IOB tagging scheme (Ramshaw and Marcus, 1995) for all the three languages (English, Hindi and Telugu).
---------------------------------------------------
I08-5010:19	56:141	This tagging scheme is the IOB scheme originally put forward by Ramshaw and Marcus (Ramshaw and Marcus, 1995).
---------------------------------------------------
W00-0713:20	55:124	(Veenstra, 1998) used the Base-NP tag set as presented in (Ramshaw and Marcus, 1995): I for inside a Base-NP, O for outside a Base-NP, and B for the first word in a Base-NP following another Base-NP.
---------------------------------------------------
P98-1010:21	168:194	Vilain and Day (1996) identify (and classify) name phrases such as company names, locations, etc. Ramshaw and Marcus (1995) detect noun phrases, by classifying each word as being inside a phrase, outside or on the boundary between phrases.
---------------------------------------------------
P98-1010:22	157:194	The last line shows the results of Ramshaw and Marcus (1995) (recognizing NP's) with the same train/test data.
---------------------------------------------------
P98-1010:23	26:194	Surprisingly, though, rather little work has been devoted to learning local syntactic patterns, mostly noun phrases (Ramshaw and Marcus, 1995; Vilain and Day, 1996).
---------------------------------------------------
P98-1010:24	124:194	We used the NP data prepared by Ramshaw and Marcus (1995), hereafter RM95.
---------------------------------------------------
C00-1034:25	74:229	a(Mufioz et al. , 1999) showed that this representation tends to provide better results than the representation used in (Ramshaw and Marcus, 1995) where each word is tagged with a tag I(inside), O(outskte), or B(breaker).
---------------------------------------------------
C00-1034:26	226:229	We (:an tin(l 1;11(: sam(; l;yl)olop;y in other works (\]{anlshaw :rod Marcus, 1995), (Ca rdi(: and Pierc(:, 1998).
---------------------------------------------------
C00-1034:27	7:229	(levelopment of cor1)ora with morl)ho-synta(:ti(: and syntacti(: mmotation (Marcus et al. , 1993), (Sampson, 1995).
---------------------------------------------------
P06-3006:28	85:138	We annotated with the BIO tagging scheme used in syntactic chunkers (Ramshaw and Marcus, 1995).
---------------------------------------------------
N04-4037:29	57:109	Then the words are tagged as inside a phrase (I), outside a phrase (O) or beginning of a phrase (B) (Ramhsaw and Marcus, 1995).
---------------------------------------------------
H05-1048:30	78:228	If one reduces the problem of entity mention detection to the detection of its head, the nature of the problem changes and the annotation of data becomes at; The [GPE Jordanian] [ORG military] [PER spokesman]  This allows us to consider the problem as a tagging/chunking problem and describe each word as beginning (B) an entity mention, inside (I) an entity mention or outside (O) an entity mention (Ramhsaw and Marcus, 1995; Sang and Veenstra, 1999).
---------------------------------------------------
P98-2234:31	35:278	By core phrases, we mean the kind of nonrecursive simplifications of the NP and VP that in the literature go by names such as noun/verb groups (Appelt et al. , 1993) or chunks, and base NPs (Ramshaw and Marcus, 1995).
---------------------------------------------------
P03-1004:32	118:242	We use a standard data set (Ramshaw and Marcus, 1995) consisting of sections 15-19 of the WSJ corpus as training and section 20 as testing.
---------------------------------------------------
W06-0112:33	12:131	Ramshaw and Marcus (1995) introduced a transformationbased learning method which considered chunking as a kind of tagging problem.
---------------------------------------------------
W06-0112:34	38:131	2 Task Description 2.1 Data Representation Ramshaw and Marcus (1995) gave mainly two kinds of base NPs representation  the open/close bracketing and IOB tagging.
---------------------------------------------------
P00-1015:35	40:153	This second expression is similar to that used in [Marcus 1995].
---------------------------------------------------
D08-1075:36	122:253	Our conception of the task is inspired by Ramshaw and Marcus representation of text chunking as a tagging problem (Ramshaw and Marcus, 1995) . The information that can be used to train the system appears in columns 1 to 8 of Table 1.
---------------------------------------------------
C00-2138:37	55:200	Rmnshaw and Marcus (1995) introdu(:e(l a 1)aseNl' whi(:h is a non-re(:ursive NIL They used trmlsfornmtion-1)ase(l learning to i(lentif~y n(/nrecto'sire l)aseNPs in a s(mtence.
---------------------------------------------------
P99-1009:38	18:119	Much previous work has been done on this problem and many different methods have been used: Church's PARTS (1988) program uses a Markov model; Bourigault (1992) uses heuristics along with a grammar; Voutilainen's NPTool (1993) uses a lexicon combined with a constraint grammar; Juteson and Katz (1995) use repeated phrases; Veenstra (1998), Argamon, Dagan & Krymolowski(1998) and Daelemaus, van den Bosch & Zavrel (1999) use memory-based systems; Ramshaw & Marcus (In Press) and Cardie & Pierce (1998) use rule-based systems.
---------------------------------------------------
P99-1009:39	8:119	Among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part-of-speech tagging (Brill, 1995; Ramshaw and Marcus, 1994), spelling correction (Mangu and Brill, 1997), word-sense disambiguation (Gale et al. , 1992), message understanding (Day et al. , 1997), discourse tagging (Samuel et al. , 1998), accent restoration (Yarowsky, 1994), prepositional-phrase attachment (Brill and Resnik, 1994) and base noun phrase identification (Ramshaw and Marcus, In Press; Cardie and Pierce, 1998; Veenstra, 1998; Argamon et al. , 1998).
---------------------------------------------------
P99-1009:40	21:119	1 To train their system, R&M used a 200k-word chunk of the Penn Treebank Parsed Wall Street Journal (Marcus et al. , 1993) tagged using a transformation-based tagger (Brill, 1995) and extracted base noun phrases from its parses by selecting noun phrases that contained no nested noun phrases and further processing the data with some heuristics (like treating the possessive marker as the first word of a new base noun phrase) to flatten the recursive structure of the parse.
---------------------------------------------------
W05-0634:41	35:111	This is referred to as an IOB representation (Ramshaw and Marcus, 1995).
---------------------------------------------------
I08-2079:42	11:159	On the base of the chunk scheme proposed by Abney (1991) and the BIO tagging system proposed in Ramshaw and Marcus(1995), many machine learning techniques are used to deal with the problem.
---------------------------------------------------
P05-2004:43	87:237	This segmentation task can be achieved by assigning words in a sentence to one of three tokens: B for Begin-NP, I for Inside-NP, or O for OutsideNP (Ramshaw and Marcus, 1995).
---------------------------------------------------
A00-2007:44	48:180	They have used the (Ramshaw and Marcus, 1995) representation as well (IOB1).
---------------------------------------------------
A00-2007:45	118:180	We have applied it to the two data sets mentioned in (Ramshaw and Marcus, 1995).
---------------------------------------------------
A00-2007:46	81:180	Like the data used by (Ramshaw and Marcus, 1995), this data was retagged by the Brill tagger in order to obtain realistic part-of-speech (POS) tags 3.
---------------------------------------------------
A00-2007:47	34:180	And third, 1This (Ramshaw and Marcus, 1995) baseNP data set is available via ftp://ftp.cis.upenn.edu/pub/chunker/ 2Software for generating the data is available from http://lcg-www.uia.ac.be/conl199/npb/ 50 with the FZ=I rate which is equal to (2*precision*recall)/(precision+recall).
---------------------------------------------------
A00-2007:48	140:180	(Ramshaw and Marcus, 1995) have build a chunker by applying transformation-based learning to sections of the Penn Treebank.
---------------------------------------------------
A00-2007:49	161:180	They compare two data representations and report that a representation with bracket structures outperforms the IOB tagging representation introduced by (Ramshaw and Marcus, 1995).
---------------------------------------------------
A00-2007:50	108:180	section 20 Majority voting (Mufioz et al. , 1999) (Tjong Kim Sang and Veenstra~ 1999) (Ramshaw and Marcus, 1995) (Argarnon et al. , 1998) accuracy precision O:98.10% C:98.29% 93.63% O:98.1% C:98.2% 93.1% 97.58% 92.50% 97.37% 91.80% 91.6% recall FZ=I 92.89% 93.26 92.4% 92.8 92.25% 92.37 92.27% 92.03 91.6% 91.6 section 00 accuracy precision Majority voting 0:98.59% C:98.65% 95.04% r (Tjong Kim Sang and Veenstra, 1999) 98.04% 93.71% (Ramshaw and Marcus, 1995) 97.8% 93.1% recall FB=I 94.75% 94.90 93.90% 93.81 93.5% 93.3 Table 3: The results of majority voting of different data representations applied to the two standard data sets put forward by (Ramshaw and Marcus, 1995) compared with earlier work.
---------------------------------------------------
A00-2007:51	30:180	The noun phrases in this data set are the same as in the Treebank and therefore the baseNPs in this data set are slightly different from the ones in the (Ramshaw and Marcus, 1995) data sets.
---------------------------------------------------
A00-2007:52	24:180	Two baseNP data sets have been put forward by (Ramshaw and Marcus, 1995).
---------------------------------------------------
A00-2007:53	41:180	An alternative representation for baseNPs has been put forward by (Ramshaw and Marcus, 1995).
---------------------------------------------------
A00-2007:54	82:180	The data was segmented into baseNP parts and nonbaseNP parts in a similar fashion as the data used by (Ramshaw and Marcus, 1995).
---------------------------------------------------
C08-1106:55	117:203	data set (Sang & Buchholz 2000; Ramshow & Marcus 1995).
---------------------------------------------------
C00-2105:56	17:248	Ramshaw and Marcus (Ramshaw and Marcus, 1995) successflflly applied Eric Brill's transformation-based learning method to the chunking problem.
---------------------------------------------------
I05-6010:57	20:231	Many statistical taggers and parsers have been trained on it, e.g. Ramshaw and Marcus (1995), Srinivas (1997) and Alshawi and Carter (1994).
---------------------------------------------------
C08-2031:58	115:125	This is confirmed by a comparison between our baseline result (F=1=55.4%) and some baseline results of English base-NP chunking task (e.g. precision=81.9%, recall=78.2%, F=1=80.0% (Ramshaw and Marcus, 1995)).
---------------------------------------------------
W00-0721:59	10:97	Our goal is to come up with a mechanism that, given an input string, identifies the phrases in this string, this is a fundamental task with applications in natural language (Church, 1988; Ramshaw and Marcus, 1995; Mufioz et al. , 1999; Cardie and Pierce, 1998).
---------------------------------------------------
W00-0721:60	78:97	The data sets used are the standard data sets for this problem (Ramshaw and Maxcus, 1995; Argamon et al. , 1999; Mufioz et al. , 1999; Tjong Kim Sang and Veenstra, 1999) taken from the Wall Street Journal corpus in the Penn Treebank (Marcus et al. , 1993).
---------------------------------------------------
P07-1029:61	24:237	NP chunks in the shared task data are BaseNPs, which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus (1995).
---------------------------------------------------
P07-1029:62	20:237	Following Ramshaw and Marcus (1995), the current dominant approach is formulating chunking as a classification task, in which each word is classified as the (B)eginning, (I)nside or (O)outside of a chunk.
---------------------------------------------------
P07-1029:63	78:237	For the English experiments, we use the now-standard training and test sets that were introduced in (Marcus and Ramshaw, 1995)2.
---------------------------------------------------
N03-1035:64	16:205	To evaluate the performance of a parser, NP chunks can usefully be evaluated by a gold standard; many systems (e.g. , Ramshaw and Marcus 1995 and Cardie and Pierce 1988) use the Penn Treebank for this type of evaluation.
---------------------------------------------------
N03-1035:65	13:205	NP chunks (Abney 1991; Ramshaw and Marcus 1995; Evans and Zhai 1996; Frantzi and Ananiadou 1996) and technical terms (Dagan and Church 1994; Justeson and Katz 1995; Daille 1996; Jacquemin 2001; Bourigault et al. 2002) fall into this difficult-toassess category.
---------------------------------------------------
N03-1035:66	1:205	Toward a Task-based Gold Standard for Evaluation of NP Chunks and Technical Terms Nina Wacholder Rutgers University nina@scils.rutgers.edu Peng Song Rutgers University psong@paul.rutgers.edu Abstract We propose a gold standard for evaluating two types of information extraction output -noun phrase (NP) chunks (Abney 1991; Ramshaw and Marcus 1995) and technical terms (Justeson and Katz 1995; Daille 2000; Jacquemin 2002).
---------------------------------------------------
W06-0505:67	168:181	The sentences in the training and testing sets were already (perfectly) POS-tagged and noun chunked, and that in a real-life situation additional preprocessing by a POS-tagger (such as the LT-POS-tagger4) and noun chunker (such as described in (Ramshaw and Marcus, 1995)) which will introduce additional errors.
---------------------------------------------------
W05-0629:68	27:96	1http://chasen.org/ taku/software/yamcha/ 2http://chasen.org/ taku/software/TinySVM/ 197 a0 Bracketed representation of roles was converted into IOB2 representation (Ramhsaw and Marcus, 1995) (Sang and Veenstra, 1999).
---------------------------------------------------
W08-0113:69	36:77	Apart from this, the module is a straightforward implementation of (Ramshaw and Marcus, 1995), which in turn adapts (Brill, 1993) for syntactic chunking.
---------------------------------------------------
W08-0113:70	33:77	We hence chose transformation-based learning to create this (shallow) segmentation grammar, converting the segmentation task into a tagging task (as is done in 85 (Ramshaw and Marcus, 1995), inter alia).
---------------------------------------------------
P06-1087:71	33:204	3 Hebrew Simple NP Chunks The standard definition of English base-NPs is any noun phrase that does not contain another noun phrase, with possessives treated as a special case, viewing the possessive marker as the first word of a new base-NP (Ramshaw and Marcus, 1995).
---------------------------------------------------
P06-1087:72	101:204	The results were evaluated using the CoNLL shared task evaluation tools 5 . The approaches tested were Error Driven Pruning (EDP) (Cardie and Pierce, 1998) and Transformational Based Learning of IOB tagging (TBL) (Ramshaw and Marcus, 1995).
---------------------------------------------------
P06-1087:73	107:204	4.2 Support Vector Machines We chose to adopt a tagging perspective for the Simple NP chunking task, in which each word is to be tagged as either B, I or O depending on wether it is in the Beginning, Inside, or Outside of the given chunk, an approach first taken by Ramshaw and Marcus (1995), and which has become the de-facto standard for this task.
---------------------------------------------------
P06-1087:74	103:204	For the Transformation Based method, we have used both the PoS tag and the word itself, with the same templates as described in (Ramshaw and Marcus, 1995).
---------------------------------------------------
P06-1087:75	187:204	Conjunctions are a major source of errors for English chunking as well (Ramshaw and Marcus, 1995, Cardie and Pierce, 1998)9, and we plan to address them in future work.
---------------------------------------------------
P06-1087:76	27:204	The NP chunks in the shared task data are base-NP chunks  which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus (1995).
---------------------------------------------------
W01-0719:77	18:158	For extracting simple noun phrases we first used Ramshaw and Marcuss base NP chunker (Ramshaw and Marcus, 1995).
---------------------------------------------------
N01-1025:78	11:201	Various machine learning approaches have been proposed for chunking (Ramshaw and Marcus, 1995; Tjong Kim Sang, 2000a; Tjong Kim Sang et al. , 2000; Tjong Kim Sang, 2000b; Sassano and Utsuro, 2000; van Halteren, 2000).
---------------------------------------------------
N01-1025:79	143:201	a176 Base NP standard data set (baseNP-S) This data set was first introduced by (Ramshaw and Marcus, 1995), and taken as the standard data set for baseNP identification task2.
---------------------------------------------------
N01-1025:80	58:201	Inside/Outside This representation was first introduced in (Ramshaw and Marcus, 1995), and has been applied for base NP chunking.
---------------------------------------------------
E99-1016:81	202:231	Results for chunking Penn Treebank data were previously presented by several authors (Ramshaw and Marcus, 1995; Argamon et al. , 1998; Veenstra, 1998; Cardie and Pierce, 1998).
---------------------------------------------------
C04-1067:82	48:135	This approach is also used in base-NP chunking (Ramshaw and Marcus, 1995) and named entity recognition (Sekine et al. , 1998) as well as word segmentation.
---------------------------------------------------
W00-0737:83	32:107	 00: the current input token and the previous one have the same parent  90: one ancestor of the current input token and the previous input token have the same parent  09: the current input token and one ancestor of the previous input token have the same parent  99 one ancestor of the current input token and one ancestor of the previous input token have the same parent Compared with the B-Chunk and I-Chunk used in Ramshaw and Marcus(1995)~, structural relations 99 and 90 correspond to B-Chunk which represents the first word of the chunk, and structural relations 00 and 09 correspond to I-Chunk which represents each other in the chunk while 90 also means the beginning of the sentence and 09 means the end of the sentence.
---------------------------------------------------
W97-0104:84	223:235	\[RM95\] Lance A. Ramshaw & Mitchell P. Marcus (1995).
---------------------------------------------------
W01-0706:85	9:129	Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers (Collins, 1997; Charniak, 1997a; Charniak, 1997b; Ratnaparkhi, 1997), significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns  syntactic phrases or words that participate in a syntactic relationship (Church, 1988; Ramshaw and Marcus, 1995; Argamon et al. , 1998; Cardie and Pierce, 1998; Munoz et al. , 1999; Punyakanok and Roth, 2001; Buchholz et al. , 1999; Tjong Kim Sang and Buchholz, 2000).
---------------------------------------------------
N03-1002:86	39:203	Five chunk tag sets, IOB1, IOB2, IOE1, IOE2 (Ramshaw and Marcus, 1995) and SE (Uchimoto et al. , 2000), are commonly used.
---------------------------------------------------
W07-1509:87	22:105	Given a weight vector w, the score wf(x,y) ranks possible labelings of x, and we denote by Yk,w(x) the set of k top scoring labelings for x. We use the standard B,I,O encoding for named entities (Ramshaw and Marcus, 1995).
---------------------------------------------------
W02-0301:88	46:341	Several representations to encode region information are proposed and examined (Ramshaw and Marcus, 1995; Uchimoto et al. , 2000; Kudo and Matsumoto, 2001).
---------------------------------------------------
P05-1027:89	68:223	The class labeling system in our experiment is IOB2 (Sang, 2000), which is a variation of IOB (Ramshaw and Marcus, 1995).
---------------------------------------------------
P06-2054:90	37:262	Following (Ramshaw and Marcus, 1995), the slot labels are drawn from a set of classes constructed by extending each label by three additional symbols, Beginning/Inside/Outside (B/I/O).
---------------------------------------------------
W07-1022:91	189:197	The concept of baseNP has undergone a number of revisions (Ramshaw and Marcus, 1995; Tjong Kim Sang and Buchholz, 2000) but has previously always been tied to extraction from a more completely annotated treebank, whose annotations are subject to other pressures than just initial material up to the head . To our knowledge, our gures for inter-annotator agreement on the baseNP task itself 169 (i.e. not derived from a larger annotation task) are the rst to be reported.
---------------------------------------------------
W07-1022:92	7:197	1 Introduction Base noun phrases (baseNPs), broadly the initial portions of non-recursive noun phrases up to the head (Ramshaw and Marcus, 1995), are valuable pieces of linguistic structure which minimally extend beyond the scope of named entities.
---------------------------------------------------
W07-1022:93	69:197	Ramshaw and Marcus (1995) state that a baseNP aims to identify essentially the initial portions of nonrecursive noun phrases up to the head, including determiners but not including postmodifying prepositional phrases or clauses . However, work on baseNPs has essentially always proceeded via algorithmic extraction from fully parsed corpora such as the Penn Treebank.
---------------------------------------------------
W00-0744:94	193:204	Ramshaw and Marcus (Ramshaw and Marcus, 1995) views chunking as a tagging problem.
---------------------------------------------------
W02-2024:95	24:92	The tagging scheme is a variant of the IOB scheme originally put forward by Ramshaw and Marcus (1995).
---------------------------------------------------
W03-0613:96	52:187	We split the returned documents into classes encompassing n-grams (terms of word length n), adjectives (using a part-of-speech tagger (Brill, 1992)) and noun phrases (using a lexical chunker (Ramshaw and Marcus, 1995)).
---------------------------------------------------
W09-1317:97	74:224	4.4 Text chunking Next, a rule-based text chunker (Ramshaw and Marcus, 1995) is applied on the tagged sentences to further identify phrasal units, such as base noun phrases NP and verbal units VB.
---------------------------------------------------
P03-1060:98	73:160	The simplest one is the BIO representation scheme (Ramshaw and Marcus, 1995), where a B denotes the first item of an element and an I any non-initial item, and a syllable with tag O is not a part of any element.
---------------------------------------------------
C00-2124:99	31:195	The data contains words, their part-of-speech 1This Ramshaw and Marcus (1995) bascNP data set is availal)le via ffp://fti).cis.upe,m.edu/pub/chunker/ 857 (POS) tags as computed by the Brill tagger and their baseNP segmentation as derived from the %'eebank (with some modifications).
---------------------------------------------------
C00-2124:100	138:195	The data was seglnente.d into baseNP parts and non-lmseNP t)arts ill a similar fitshion as the data used 1)y Ramshaw and Marcus (1995).
---------------------------------------------------
C00-2124:101	29:195	been put forward by Ramshaw and Marcus (1995).
---------------------------------------------------
C00-2124:102	137:195	Like the data used by Ramshaw and Marcus (1995), this data was retagged by the Brill tagger in order to obtain realistic part-of speech (POS) tags 5.
---------------------------------------------------
C00-2124:103	161:195	(1999) 91.6% 91.6% F/3=1 93.86 93.26 92.8 92.03 91.6 Table 3: The overall pertbrmance of the majority voting combination of our best five systems (selected on tinting data perfbrnmnce) applied to the standard data set pnt tbrward by Ramshaw and Marcus (1995) together with an overview of earlier work.
---------------------------------------------------
C00-2124:104	52:195	He used the Ramshaw and Marcus (1995) representation as well (IOB1).
---------------------------------------------------
C00-2124:105	160:195	(1999) O:98.1% C:98.2% 92.4% 93.1% Ramshaw and Marcus (1995) IOB1:97.37% 91.80% 92.27% Argamon et al.
---------------------------------------------------
C00-2124:106	45:195	An alternative representation for baseNPs has been put tbrward by Ramshaw and Marcus (1995).
---------------------------------------------------
C00-2124:107	174:195	tile data put tbrward by ll,amshaw and Marcus (1995).
---------------------------------------------------
W00-0736:108	8:70	The first is a baseline of sorts, our own version of the "chunking as tagging" approach introduced by Ramshaw and Marcus (Ramshaw and Marcus, 1995).
---------------------------------------------------
A00-1011:109	38:163	First, it recognizes non-recursive Base Noun Phrase (BNP) (our specifications for BNP resemble those in Ramshaw and Marcus 1995).
---------------------------------------------------
W00-0726:110	7:150	There has been a large interest in recognizing non-overlapping noun phrases (Ramshaw and Marcus (1995) and follow-up papers) but relatively little has been written about identifying phrases of other syntactic categories.
---------------------------------------------------
W00-0726:111	35:150	Adverbs/adverbial phrases becorae part of the VP chunk (as long as they are in front of the main verb): (VP could (ADVP very well) (VP show  )) "-+ \[ve could very well show \]  In contrast to Ramshaw and Marcus (1995), predicative adjectives of the verb are not part of the VP chunk, e.g. in "\[NP they \] \[vP are \] \[ADJP unhappy \]'.
---------------------------------------------------
W00-0726:112	29:150	3.1 NP Our NP chunks are very similar to the ones of Ramshaw and Marcus (1995).
---------------------------------------------------
W00-0726:113	72:150	The first solution might also introduce errors elsewhere As Ramshaw and Marcus (1995) already noted: "While this automatic derivation process introduced a small percentage of errors on its own, it was the only practical way both to provide the amount of training data required and to allow for fully-automatic testing".
---------------------------------------------------
W00-0726:114	81:150	B-X I-X 0 first word of a chunk of type X non-initial word in an X chunk word outside of any chunk This representation type is based on a representation proposed by Ramshaw and Marcus (1995) for noun phrase chunks.
---------------------------------------------------
W00-0726:115	133:150	Ramshaw and Marcus (1995) approached chunking by using a machine learning method.
---------------------------------------------------
W00-0726:116	73:150	4 Data and Evaluation For the CoNLL shared task, we have chosen to work with the same sections of the Penn Treebank as the widely used data set for base noun phrase recognition (Ramshaw and Marcus, 1995): WSJ sections 15-18 of the Penn Treebank as training material and section 20 as test material 3.
---------------------------------------------------
W06-0139:117	28:74	2.1 Word Sequence Classification Similar to English text chunking (Ramshaw and Marcus, 1995; Wu et al. , 2006a), the word sequence classification model aims to classify each word via encoding its context features.
---------------------------------------------------
D07-1084:118	170:269	Training and testing were performed using the noun phrase chunking corpus described in Ramshaw & Marcus (1995) (Ramshaw and Marcus, 1995).
---------------------------------------------------
W06-1618:119	65:221	al. 2003b) 147 is (B)eginning, (I)nside or (O)utside of a chunk (Ramshaw & Marcus, 1995).
---------------------------------------------------
D08-1071:120	33:260	Co-training (Yarowsky, 1995; Blum and Mitchell, 1998) is related to self-training, in that an algorithm is trained on its own predictions.
---------------------------------------------------
D08-1071:121	70:260	We use 3500 sentences from CoNLL (Tjong Kim Sang and De Meulder, 2003) as the NER data and section 20-23 of the WSJ (Marcus et al., 1993; Ramshaw and Marcus, 1995) as the POS/chunk data (8936 sentences).
---------------------------------------------------
W04-1107:122	9:195	(Ramshaw and Marcus, 1995) represent chunking as tagging problem and the CoNLL2000 shared task (Kim Sang and Buchholz, 2000) is now the standard evaluation task for chunking English.
---------------------------------------------------
I05-6003:123	11:256	Among the chunk types, NP chunking is the first to receive the attention (Ramshaw and Marcus, 1995), than other chunk types, such as VP and PP chunking (Veenstra, 1999).
---------------------------------------------------
W05-0611:124	49:171	The examples represent seven-word windows of words and their respective (predicted) part-of-speech tags, and each example is labeled with a class using the IOB type of segmentation coding as introduced by Ramshaw and Marcus (1995), marking whether the middle word is inside (I), outside (O), or at the beginning (B) of a chunk.
---------------------------------------------------
P98-1034:125	14:227	More recently, Ramshaw & Marcus (In press) apply transformation-based learning (Brill, 1995) to the problem.
---------------------------------------------------
E06-1046:126	74:194	These tags are drawn from a tagset which is constructed by 363 extending each argument label by three additional symbols a80a44a81a83a82a84a81a86a85, following (Ramshaw and Marcus, 1995).
---------------------------------------------------
D08-1112:127	148:169	All corpora are formatted in the IOB sequence representation (Ramshaw and Marcus, 1995).
---------------------------------------------------
W05-1514:128	35:207	Sang used the IOB tagging method proposed by Ramshow(Ramshaw and Marcus, 1995) and memory-based learning for each level of chunking and achieved an f-score of 80.49 on the Penn Treebank corpus.
---------------------------------------------------
C00-2102:129	15:126	This means that the 1)roblem of recognizing named entities in those cases can be solved by incorporating techniques of base noun phrase chunking (Ramshaw and Marcus, 1995).
---------------------------------------------------
C00-2102:130	45:126	3.2.1 Inside/Outside Encoding The Inside/Outside scheme of encoding chunking states of base noun phrases was studied in Ibmlshaw and Marcus (1995).
---------------------------------------------------
W99-0707:131	132:186	Since part of the chunking errors could be caused by POS errors, we also compared the same baseNP chunker on the santo corpus tagged with i) the Brill tagger as used in \[Ramshaw and Marcus, 1995\], ii) the Memory-Based Tagger (MBT) as described in \[Daelemans et al. , 1996\].
---------------------------------------------------
W99-0707:132	129:186	Chunking For NP chunking, \[Argamon et al. , 1998\] used data extracted from section 15-18 of the WS.J as a fixed train set and section 20 as a fixed test set, the same data as \[Ramshaw and Marcus, 1995\].
---------------------------------------------------
W99-0707:133	133:186	We also present the results of \[Argamon et al. , 1998\], \[Ramshaw and Marcus: 1995\] and \[Cardie and Pierce, 1998\] in Table 4.
---------------------------------------------------
W99-0707:134	3:186	Introduction Recently, there has been an increased interest in approaches to automatically learning to recognize shallow linguistic patterns in text \[Ramshaw and Marcus, 1995, Vilain and Day, 1996, Argamon et al. , 1998, Buchholz, 1998, Cardie and Pierce, 1998, Veenstra, 1998, Daelemans et aI.
---------------------------------------------------
P03-1064:135	42:231	We repeat Ramshaw and Marcus Transformation Based NP chunking (Ramshaw and Marcus, 1995) algorithm by substituting supertags for POS tags in the dataset.
---------------------------------------------------
P03-1064:136	225:231	On the same dataset as that of (Chen et al. , 1999), our new supertagger achieves an accuracy of a2a4a3a6a5a8a7a10a9a12a11 . Compared with the supertaggers with the same decoding complexity (Chen, 2001), our algorithm achieves an error reduction of a22a23a5a26a9a12a11 . We repeat Ramshaw and Marcus Transformation Based NP chunking (Ramshaw and Marcus, 1995) test by substituting supertags for POS tags in the dataset.
---------------------------------------------------
P03-1064:137	16:231	(Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL).
---------------------------------------------------
N04-1001:138	34:189	Similarly to classical NLP tasks such as base noun phrase chunking (Ramshaw and Marcus, 1994), text chunking (Ramshaw and Marcus, 1995) or named entity recognition (Tjong Kim Sang, 2002), we formulate the mention detection problem as a classification problem, by assigning to each token in the text a label, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions.
---------------------------------------------------
W99-0705:139	8:366	Introduction Since Eric Brill first introduced the method of Transformation-Based Learning (TBL) it has been used to learn rules for many natural language processing tasks, such as part-of-speech tagging \[Brill, 1995\], PPattachment disambiguation \[Brill and Resnik, 1994\], text chunking \[Ramshaw and Marcus, 1995\], spelling correction \[Mangu and Brill, 1997\], dialogue act tagging \[Samuel et al. , 1998\] and ellipsis resolution \[Hardt, 1998\].
---------------------------------------------------
N03-1028:140	86:169	4.1 Data Preparation NP chunking results have been reported on two slightly different data sets: the original RM data set of Ramshaw and Marcus (1995), and the modi ed CoNLL-2000 version of Tjong Kim Sang and Buchholz (2000).
---------------------------------------------------
N03-1028:141	22:169	In contrast, generative models are trained to maximize the joint probability of the training data, which is 1Ramshaw and Marcus (1995) used transformation-based learning (Brill, 1995), which for the present purposes can be tought of as a classi cation-based method.
---------------------------------------------------
N03-1028:142	83:169	Following Ramshaw and Marcus (1995), the input to the NP chunker consists of the words in a sentence annotated automatically with part-of-speech (POS) tags.
---------------------------------------------------
N03-1028:143	10:169	The pioneering work of Ramshaw and Marcus (1995) introduced NP chunking as a machine-learning problem, with standard datasets and evaluation metrics.
---------------------------------------------------
H05-1099:144	7:185	1 Introduction Finite-state parsing (also called chunking or shallow parsing) has typically been motivated as a fast firstpass for  or approximation to  more expensive context-free parsing (Abney, 1991; Ramshaw and Marcus, 1995; Abney, 1996).
---------------------------------------------------
H05-1099:145	90:185	They mention that the resulting shallow parse tags are somewhat different than those used by Ramshaw and Marcus (1995), but that they found no significant accuracy differences in training on either set.
---------------------------------------------------
H05-1099:146	22:185	2 Evaluating Heterogeneous Parser Output Two commonly reported shallow parsing tasks are Noun-Phrase (NP) Chunking (Ramshaw and Marcus, 1995) and the CoNLL-2000 Chunking task (Sang and Buchholz, 2000), which extends the NPChunking task to recognition of 11 phrase types1 annotated in the Penn Treebank.
---------------------------------------------------
H05-1099:147	79:185	task, originally introduced in Ramshaw and Marcus (1995) and also described in (Collins, 2002; Sha and Pereira, 2003), brackets just base NP constituents5.
---------------------------------------------------
H05-1099:148	66:185	(2002) 94.17 Li and Roth (2001) 93.02 94.64 Table 2: Baseline results on three shallow parsing tasks: the NP-Chunking task (Ramshaw and Marcus, 1995); the CoNLL-2000 Chunking task (Sang and Buchholz, 2000); and the Li & Roth task (Li and Roth, 2001), which is the same as CoNLL-2000 but with more training data and a different test section.
---------------------------------------------------
E99-1023:149	117:160	Again the best result was obtained with IOB1 (F~=I =92.37) which is an imI)rovement of the best reported F,~=1 rate for this data set ((Ramshaw and Marcus, 1995): 92.03).
---------------------------------------------------
E99-1023:150	65:160	~lr~l-l(; is a part of the TiMBL software package which is available from http://ilk.kub.nl 3 Results We have used the baseNP data presented in (Ramshaw and Marcus, 1995) 2.
---------------------------------------------------
E99-1023:151	142:160	With all but two formats IBI-IG achieves better FZ=l rates than the best published result in (Ramshaw and Marcus, 1995).
---------------------------------------------------
E99-1023:152	2:160	(l~mshaw and Marcus, 1995) have introduced a "convenient" data representation for chunking by converting it to a tagging task.
---------------------------------------------------
E99-1023:153	125:160	Ramshaw and Marcus used transformationbased learning (TBL) for developing two chunkers (Ramshaw and Marcus, 1995).
---------------------------------------------------
E99-1023:154	26:160	in their treatment of chunk-initial and chunk-final \[ + \] words: IOB1 IOB2 IOE1 IOE2 The first word inside a baseNP immediately following another baseNP receives a B tag (Ramshaw and Marcus, 1995).
---------------------------------------------------
E99-1023:155	7:160	(Ramshaw and Marcus, 1995) describe an error-driven transformation-based learning (TBL) method for finding NP chunks in texts.
---------------------------------------------------
E99-1023:156	114:160	We have used the optimal experiment configurations that we had obtained from the fourth experiment series for processing the complete (Ramshaw and Marcus, 1995) data set.
---------------------------------------------------
E99-1023:157	80:160	All formats 2The data described in (Ramshaw and Marcus, 1995) is available from ftp://ftp.cis.upenn.edu/pub/chunker/ 175 Proceedings of EACL '99 word/POS context chunk tag context IOB1 L=2/R=I IOB2 L--2/R=I IOE1 L=I/R=2 IOE2 L=I/R=2 \[ +\] L=2/R=I + L=0/R=2 \[ + IO L=2/R=0 + L=I/R=I IO +\] L=I/R=I+L=0/R=2 F~=I 1/2 90.12 1/0 89.30 1/2 89.55 0/1 89.73 0/0 + 0/0 89.32 0/0 + I/I 89.78 1/1 + 0/0 89.86 Table 3: Results second experiment series: the best F~=I scores for different left (L) and right (R) chunk tag context sizes for the seven representation formats using 5-fold cross-validation on section 15 of the WSJ corpus.
---------------------------------------------------
E99-1023:158	137:160	177 Proceedings of EACL '99 IOB1 IOB2 IOE1 IOE2 \[+\] \[+ IO IO +\] (Ramshaw and Marcus, 1995) (Veenstra, 1998) (Argamon et al. , 1998) (Cardie and Pierce, 1998) accuracy 97.58% 96.50% 97.58% 96.77% 97.37% 97.2% precision 92.50% 91.24% 92.41% 91.93% 93.66% 91.47% 91.25% 91.80% 89.0% 91.6 % 90.7% recall F~=I 92.25% 92.37 92.32% 91.78 92.04% 92.23 92.46% 92.20 90.81% 92.22 92.61% 92.04 92.54% 91.89 92.27% 92.03 94.3% 91.6 91.6% 91.6 91.1% 90.9 Table 6: The F~=I scores for the (Ramshaw and Marcus, 1995) test set after training with their training data set.
---------------------------------------------------
E99-1023:159	22:160	2.1 Data representation We have compared four complete and three partial data representation formats for the baseNP recognition task presented in (Ramshaw and Marcus, 1995).
---------------------------------------------------
E99-1023:160	121:160	This time the chunker achieved a F~=l score of 93.81 which is half a point better than the results obtained by (Ramshaw and Marcus, 1995): 93.3 (other chunker rates for this data: accuracy: 98.04%; precision: 93.71%; recalh 93.90%).
---------------------------------------------------
E99-1023:161	152:160	The IOB1 format, introduced in (Ramshaw and Marcus, 1995), consistently (:ame out as the best format.
---------------------------------------------------
E99-1023:162	148:160	However, they use the (Ramshaw and Marcus, 1995) data set in a different training-test division (10-fold cross validation) which makes it (tifficult to compare their results with others.
---------------------------------------------------
E99-1023:163	118:160	We would like to apply our learning approach to the large data set mentioned in (Ramshaw and Marcus, 1995): Wall Street Journal corpus sections 2-21 as training material and section 0 as test material.
---------------------------------------------------
E99-1023:164	129:160	(Ramshaw and Marcus, 1995) shows that baseNP recognition (Fz=I =92.0) is easier than finding both NP and VP chunks (Fz=1=88.1) and that increasing the size of the training data increases the performance on the test set.
---------------------------------------------------
E99-1023:165	133:160	It performed slightly worse on baseNP recognition than the (Ramshaw and Marcus, 1995) experiments (Fz=1=91.6).
---------------------------------------------------
E99-1023:166	54:160	In (Ramshaw and Marcus, 1995) a set of transformational rules is used for modifying the classification of words.
---------------------------------------------------
E99-1023:167	70:160	The chunking classification was made by (Ramshaw and Marcus, 1995) based on the parsing information in the WSJ corpus.
---------------------------------------------------
H05-1033:168	56:234	We adopted the chunk representation proposed by Ramshaw and Marcus (1995) and used four different tags: B-NUC and B-SAT for nucleus and satellite-initial tokens, and I-NUC and I-SAT for non-initial tokens, i.e., tokens inside a nucleus and satellite span.
---------------------------------------------------
D09-1153:169	59:244	With IOB2 representation (Ramshaw and Marcus, 1995), the problem of Chinese chunking can be regarded as a sequence labeling task.
---------------------------------------------------
W07-1009:170	12:187	The difficulty of this task is that the standard method for converting NER to a sequence tagging problem with BIOencoding (Ramshaw and Marcus, 1995), where each 1http://www.nist.gov/speech/tests/ace/ index.htm token is assigned a tag to indicate whether it is at the beginning (B), inside (I), or outside (O) of an entity, is not directly applicable when tokens belong to more than one entity.
---------------------------------------------------
I08-1050:171	96:142	Meanwhile, it is common for NP chunking tasks to represent a chunk (e.g., NP) with two labels, the begin (e.g., B-NP) and inside (e.g., I-NP) of a chunk (Ramshaw and Marcus, 1995).
---------------------------------------------------
N04-1029:172	117:203	We then apply Brills rule-based tagger (Brill 1995) and BaseNP noun phrase chunker (Ramshaw and Marcus 1995) to extract noun phrases from these sentences.
---------------------------------------------------
W06-2602:173	124:196	Each token is labelled with a class using the IOB type of segmentation coding as introduced by Ramshaw and Marcus (1995), marking whether the middle word is inside (I), outside (O), or at the beginning (B) of a chunk, or named entity.
---------------------------------------------------
P06-2098:174	119:155	(Ramshaw and Marcus, 1995) To reduce the inference time, following (McCallum et al, 2003), we collapsed the 45 different POS labels contained in the original data.
---------------------------------------------------
W99-0629:175	63:225	Ramshaw and Marcus (1995) first assigned a chunk tag to each word in the sentence: I for inside a chunk, O for outside a chunk, and 240 type precision B tbr inside a chunk, but tile preceding word is in another chunk.
---------------------------------------------------
D08-1063:176	20:196	Similarly to classical NLP tasks such as text chunking (Ramshaw and Marcus, 1995) and named entity recognition (Tjong Kim Sang, 2002), we formulate mention detection as a sequence classification problem, by assigning a label to each token in the text, indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions.
---------------------------------------------------
C04-1066:177	77:232	Table 2 shows the unknown word tags for chunking, which are known as the IOB2 model (Ramshaw and Marcus, 1995).
---------------------------------------------------
W03-0419:178	54:153	This tagging scheme is the IOB scheme originally put forward by Ramshaw and Marcus (1995).
---------------------------------------------------
C00-2089:179	77:178	Precision and recall rates were 92.4% on the same data used in (Ramshaw and Marcus, 1995).
---------------------------------------------------
W07-0812:180	16:226	Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus (1995), the task is performed with greater efficiency and is easily portable to new languages in a supervised manner (Diab et al. , 2004; Diab et al. , 2007).
---------------------------------------------------
W07-0812:181	35:226	A la Ramshaw and Marcus (1995), they represent the words as a sequence of labeled words with IOB annotations, where the B marks a word at the beginning of a chunk, I marks a word inside a chunk, and O marks those words (and punctuation) that are outside chunks.
---------------------------------------------------
W07-0812:182	30:226	It was first cast as a classification problem by Ramshaw and Marcus (1995), as a problem of NP chunking.
---------------------------------------------------
W07-0812:183	49:226	A la Ramshaw and Marcus (1995), and Kudo and Matsumato (2000), we use the IOB tagging style for modeling and classification.
---------------------------------------------------
I08-4029:184	53:118	3.1 Word Sequence Classification Similar to English text chunking (Ramshaw and Marcus, 1995; Lee and Wu, 2007), the word sequence classification model aims to classify each word via encoding its context features.
---------------------------------------------------
W01-0712:185	189:210	The original Ramshaw and Marcus (1995) publication evaluated their NP chunker on two data sets, the second holding a larger amount of training data (Penn Treebank sections 02-21) while using 00 as test data.
---------------------------------------------------
W01-0712:186	29:210	The data set that has become standard for evaluation machine learning approaches is the one first used by Ramshaw and Marcus (1995).
---------------------------------------------------
W01-0712:187	164:210	Standard data sets for machine learning approaches to this task were put forward by Ramshaw and Marcus (1995).
---------------------------------------------------
P02-1055:188	56:174	For the chunk part of the code, we adopt the Inside, Outside, and Between (IOB) encoding originating from (Ramshaw and Marcus, 1995).
---------------------------------------------------
P02-1055:189	139:174	5 Related Research Ramshaw and Marcus (1995), Munoz et al.
---------------------------------------------------
D07-1033:190	131:389	We adopted IOB (IOB2) labeling (Ramshaw and Marcus, 1995), where the rst word of an entity of class C is labeled B-C, the words in the entity are labeled I-C, and other words are labeled O.
---------------------------------------------------
W01-0702:191	61:165	5 The task: Base NP chunking The task is base NP chunking on section 20 of the Wall Street Journal corpus, using sections 15 to 18 of the corpus as training data as in (Ramshaw and Marcus, 1995).
---------------------------------------------------
C08-1061:192	96:297	The noun phrase chunking (NP chunking) module uses the basic NP chunker software from 483 (Ramshaw and Marcus, 1995) to recognize the noun phrases in the question.
---------------------------------------------------
W00-1309:193	143:149	Type Precision Recall Fa=l Overall 96.40 96.47 96.44 NP 96.49 96.99 96.74 VP 97.13 97.36 97.25 ADJP 89.92 88.15 89.03 ADVP 91.52 87.57 89.50 97.13 97.36 PP 97.25 Table 16: Results of 25-fold cross-validation chunking experiments with the merged context-dependent lexicon Tables 14 and 16 shows that our new chunk tagger greatly outperforms other reported chunk taggers on the same training data and test data by 2%-3%.(Buchholz S. , Veenstra J. and Daelmans W.(1999), Ramshaw L.A. and Marcus M.P.(1995), Daelemans W. , Buchholz S. and Veenstra J.(1999), and Veenstra J.(1999)).
---------------------------------------------------
W00-1309:194	65:149	NULL) Compared with the B-Chunk and I-Chunk used in Ramshaw and Marcus(1995), structural relations 99 and 90 correspond to B-Chunk which represents the first word of the chunk, and structural relations 00 and 09 correspond to I-Chunk which represnts each other in the chunk while 90 also means the beginning of the sentence and 09 means the end of the sentence.
---------------------------------------------------
W00-1309:195	16:149	Ramshaw and Marcus(1995) used transformation-based learning, an error-driven learning technique introduced by Eric Bn11(1993), to locate chunks in the tagged corpus.
---------------------------------------------------
I05-2022:196	23:163	(Ramshaw and Marcus, 1995) used transformation based learning using a large annotated corpus for English.
---------------------------------------------------
W00-0733:197	8:79	Chunks can be represented with bracket structures but alternatively one can use a tagging representation which classifies words as being inside a chunk (I), outside a chunk (O) or at a chunk boundary (B) (Ramshaw and Marcus, 1995).
---------------------------------------------------
P97-1041:198	48:179	Transformation-based learning has also been successfully applied to text chunking (Ramshaw and Marcus, 1995), morphological disambiguation (Oflazer and Tur, 1996), and phrase parsing (Vilain and Day, 1996).
---------------------------------------------------
W09-1412:199	30:85	All our experiments used the standard BIO encoding (Ramshaw and Marcus, 1995) with different feature sets and learning procedures.
---------------------------------------------------
W00-0731:200	7:77	1 Introduction Shallow parsing has received a reasonable amount of attention in the last few years (for example (Ramshaw and Marcus, 1995)).
---------------------------------------------------
W01-1011:201	47:172	The noun phrase extraction module uses Brill's POS tagger [Brill (1992)]and a base NP chunker [Ramshaw and Marcus (1995)].
---------------------------------------------------
W01-1011:202	69:172	3.1 Candidate NPs Noun phrases were extracted using Ramshaw and Marcus's base NP chunker [Ramshaw and Marcus (1995)].
---------------------------------------------------
P06-2013:203	58:216	We only describe these models briefly since full details are presented elsewhere(Kudo and Matsumoto, 2001; Sha and Pereira, 2003; Ramshaw and Marcus, 1995; Sang, 2002).
---------------------------------------------------
P06-2013:204	12:216	Ramshaw and Marcus(Ramshaw and Marcus, 1995) first represented base noun phrase recognition as a machine learning problem.
---------------------------------------------------
P07-1031:205	21:226	240 2 Motivation Many approaches to identifying base noun phrases have been explored as part of chunking (Ramshaw and Marcus, 1995), but determining sub-NP structure is rarely addressed.
---------------------------------------------------
N04-1005:206	135:207	These tags are drawn from a tagset which is constructed by extending each argument label by three additional symbols a11 a24 a35 a24a4a12, following (Ramshaw and Marcus, 1995).
---------------------------------------------------
P03-1063:207	6:224	1 Introduction Text chunking has been one of the most interesting problems in natural language learning community since the first work of (Ramshaw and Marcus, 1995) using a machine learning method.
---------------------------------------------------
C00-1082:208	14:172	l lhmsetsu ideni,illcation is a ln'oblem similar to ohm,king (lLamshaw and Marcus, 1995; Sang and \h;ellsl;ra, 1999) in other l;mguages.
---------------------------------------------------
W04-2416:209	18:89	2 System Description 2.1 Data Representation In this paper, we change the representation of the original data as follows: Bracketed representation of roles is converted into IOB2 representation (Ramhsaw and Marcus, 1995; Sang and Veenstra, 1995) Word tokens are collapsed into base phrase (BP) tokens.
---------------------------------------------------
W03-1706:210	89:142	Like baseNP chunking(Church, 1988; Ramshaw & Marcus 1995), content chunk parsing is also a kind of shallow parsing.
---------------------------------------------------
