In another study, a factored LM using POS information achieved the same results as the 4-gram LM (Kirchhoff and Yang, 2005).


This result corresponds to known work in the literature (Kirchhoff and Yang, 2005; Hasan et al. , 2006), when using POS only as a post-processing step during reranking.


In (Kirchhoff and Yang, 2005), a factored language model using POS information showed similar performance to a 4-gram word language model.


Kirchhoff and Yang (2005) used a factored 3gram model and a 4-gram LM (modified KN smoothing) together with seven system scores to re-rank an SMT N-best.


