Such templatic patterns can be learned using seed examples of the attribute in question and, there has been a plethora of work in the seed-based bootstrapping literature which addresses this problem (Ravichandran and Hovy, 2002; Thelen and Riloff, 2002; Mann and Yarowsky, 2005; Alfonseca et al., 2006; Pasca et al., 2006) Thus for our baseline we implemented a standard Ravichandran and Hovy (2002) pattern learning model using 100 seed2 examples from an online biographic database called NNDB (http://www.nndb.com) for each of the biographic attributes: Birthdate, Birthplace, Deathdate, Gender, Nationality, Occupation and Religion. 
and Yarowsky (2005) present an incremental approach where co-occurrence with a known relationship is a feature added in training and test. 
2.1 Rote extractors Rote extractors (Mann and Yarowsky, 2005) estimate the probability of a relation r(p,q) given the surrounding context A1pA2qA3. 
Several similar approaches have been proposed (Brin, 1998; Agichtein and Gravano, 2000; Ravichandran and Hovy, 2002), with various applications: Question-Answering (Ravichandran and Hovy, 2002), multi-document Named Entity Coreference (Mann and Yarowsky, 2003), and generating 15 biographical information (Mann and Yarowsky, 2005). 
The second and more closely related class deals with extracting specific facts such as birthplace, occupation, etc. For this task, the primary theme of work in the literature has been to treat the task as a general semantic-class learning problem where one starts with a few seeds of the semantic relationship of interest and learns contextual patterns such as <NAME> was born in <Birthplace> or <NAME> (born <Birthdate>) (Hearst, 1992; Riloff, 1996; Thelen and Riloff, 2002; Agichtein and Gravano, 2000; Ravichandran and Hovy, 2002; Mann and Yarowsky, 2003; Jijkoun et al., 2004; Mann and Yarowsky, 2005; Alfonseca et al., 2006; Pasca et al., 2006). 
