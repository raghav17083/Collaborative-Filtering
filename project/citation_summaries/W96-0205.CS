In contrast, previously proposed supervised approaches have used segmented training sets ranging from 1000-5000 sentences (Kashioka et al. , 1998) to 190,000 sentences (Nagata, 1996a). 
Nagao and Mori (1994) and Nagata (1996) proposed n-gram methods for Japanese. 
We use a statistical word model to assign a probat>ility to each subs|ring (Nagata, 1996). 
5 Related Work Japanese Many previously proposed segmentation methods for Japanese text make use of either a pre-existing lexicon (Yamron et al. , 1993; Matsumoto and Nagao, 1994; Takeuchi and Matsumoto, 1995; Nagata, 1997; Fuchi and Takagi, 1998) or pre-segmented training data (Nagata, 1994; Papa: georgiou, 1994; Nagata, 1996a; Kashioka et al. , 1998; Mori and Nagao, 1998). 
Nagata (1996) recently proposed a generalized forward-backward algorithm that is a character synchronous method for unsegmented languages. 
