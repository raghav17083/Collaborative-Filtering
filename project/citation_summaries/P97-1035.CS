For example, the PARADISE framework allows designers to predict user satisfaction from a linear combination of objective metrics such as mean recognition score and task completion (Kamm et al. , 1999; Litman & Pan, 1999; Walker et al. , 1997). 
To assess the relative contribution of each evaluation measure to performance, we use PARADISE (Walker et al., 1997) to derive a performance function from our data. 
This has prompted some researchers to argue that a common inventory of concepts is necessary to have standard metrics for evaluation across systems and domain tasks (Kamm et al. , 1997; Glass et al. , 2000). 
The answer has to do with more than just the absence of agreed upon standards in the research community, notwithstanding significant efforts in that direction (Gibbon et al. , 1997). 
To measure task success, we compared the scenario key and scenario execution AVMs for each dialogue, using the Kappa statistic (Walker et al., 1997). 
