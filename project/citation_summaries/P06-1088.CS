Our baseline approach outperformed previously published results on this test 4The accuracy figures for the dependency parsers is expressed as unlabeled accuracy of the surface dependencies only, and are not comparable to the HPSG parsing accuracy figures 629 Parser LP LR F-score HPSG Baseline 87.4 87.0 87.2 Shift-Reduce + HPSG 88.2 87.7 87.9 C1 + HPSG 88.5 88.0 88.2 C2 + HPSG 88.4 87.9 88.1 Baseline(gold) 89.8 89.4 89.6 Shift-Reduce(gold) 90.62 90.23 90.42 C1+HPSG(gold) 90.9 90.4 90.6 C2+HPSG(gold) 90.8 90.4 90.6 Miyao and Tsujii, 2005 85.0 84.3 84.6 Ninomiya et al. , 2006 87.4 86.3 86.8 Table 2: Final results on test set. 
2.1 The Supertagger The supertagger uses Maximum Entropy tagging techniques (Section 3) to assign a set of lexical categories to each word (Curran et al. , 2006). 
The tokenizer-tagger that is currently used in the grammar is developed by Beijing University (PKU)3 and is incorporated as a library transducer (Crouch et al., 2006). 
Supertagging has been more recently extended to a multitagging paradigm in CCG (Clark, 2002; Curran et al., 2006), leading to extremely efficient parsing with state-of-the-art dependency recovery (Clark and Curran, 2007). 
These distributions are then used to assign a set of lexical categories to each word (Curran et al. , 2006). 
