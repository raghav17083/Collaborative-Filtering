Various state-of-the-art machine learning algorithms such as Maximum Entropy (Borthwick, 1999), AdaBoost(Carreras et al. , 2002), Hidden Markov Models (Bikel et al. , ), Memory-based Based learning (Tjong Kim Sang, 2002b), have been used1. 
(Daelemans et al. , 1996; Daelemans et al. , 1999; Mooney, 1996; Tjong Kim Sang, 2002; Veenstra et al. , 2000)) shows that the bias of this similarity-based approach is suitable for processing natural language problems. 
Recently, machine learning approaches are widely used in NER, including the hidden Markov model (Zhou and Su, 2000; Miller and Crystal, 1998), maximum entropy model (Borthwick, 1999), decision tree (Qin and Yuan, 2004), transformation-based learning (Black and Vasilakopoulos, 2002), boosting (Collins, 2002; Carreras et al. , 2002), support vector machine (Takeuchi and Collier, 2002; Yu et al. , 2004; Goh et al. , 2003), memory-based learning (Sang, 2002). 
This scheme was initially introduced in CoNLLs (Tjong Kim Sang, 2002a) and (Tjong Kim Sang and De Meulder, 2003) NER competitions, and we decided to adapt it for our experimental work. 
Stages use the output of previous stages for obtaining an improved performance (Spanish test set: F =1 =73.92;; Dutch test set: F =1 =71.36) Tjong Kim Sang (2002) has applied a memory-based learner to the data of the shared task. 
