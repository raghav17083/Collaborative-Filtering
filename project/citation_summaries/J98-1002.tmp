P01-1049:1	Semantic Correlations Although there exists many methods to derive the semantic correlations between words (Lee, 1999; Lin, 1998; Karov & Edelman, 1998; Resnik, 1995; Dagan et al, 1995), we adopt a relatively simple and yet practical and effective approach to derive three topic -oriented semantic correlations: thesaurus-based, co-occurrence-based and contextbased correlation.
---------------------------------------------------
E06-1042:2	3.2 Core Algorithm Since we are attempting to reduce the problem of literal/nonliteral recognition to one of word-sense disambiguation, TroFi makes use of an existing similarity-based word-sense disambiguation algorithm developed by (Karov & Edelman, 1998), henceforth KE.
---------------------------------------------------
E06-1042:3	The target set is built using the 88-89 Wall Street Journal Corpus (WSJ) tagged using the (Ratnaparkhi, 1996) tagger and the (Bangalore & Joshi, 1999) SuperTagger; the feedback sets are built using WSJ sentences con330 Algorithm 1 KE-train: (Karov & Edelman, 1998) algorithm adapted to literal/nonliteral classification Require: S: the set of sentences containing the target word Require: L: the set of literal seed sentences Require: N: the set of nonliteral seed sentences Require: W: the set of words/features, w  s means w is in sentence s, s owner w means s contains w Require: epsilon1: threshold that determines the stopping condition 1: w-sim0(wx,wy) := 1 if wx = wy,0 otherwise 2: s-simI0(sx,sy) := 1, for all sx,sy  S S where sx = sy, 0 otherwise 3: i := 0 4: while (true) do 5: s-simLi+1(sx,sy) := summationtextwxsx p(wx,sx)maxwysy w-simi(wx,wy), for all sx,sy  S L 6: s-simNi+1(sx,sy) := summationtextwxsx p(wx,sx)maxwysy w-simi(wx,wy), for all sx,sy  S N 7: for wx,wy  W W do 8: w-simi+1(wx,wy) := braceleftBigg i = 0 summationtextsxownerwx p(wx,sx)maxsyownerwy s-simIi(sx,sy) else summationtextsxownerwx p(wx,sx)maxsyownerwys-simLi (sx,sy),s-simNi (sx,sy)} 9: end for 10: if wx,maxwyw-simi+1(wx,wy)w-simi(wx,wy)}  epsilon1 then 11: break # algorithm converges in 1epsilon1 steps.
---------------------------------------------------
E06-1042:4	3.1 The Data The TroFi algorithm requires a target set (called original set in (Karov & Edelman, 1998))  the set of sentences containing the verbs to be classified into literal or nonliteral  and the seed sets: the literal feedback set and the nonliteral feedback set.
---------------------------------------------------
P05-1049:5	They roughly fall into three categories according to what is used for supervision in learning process: (1) using external resources, e.g., thesaurus or lexicons, to disambiguate word senses or automatically generate sense-tagged corpus, (Lesk, 1986; Lin, 1997; McCarthy et al. , 2004; Seo et al. , 2004; Yarowsky, 1992), (2) exploiting the differences between mapping of words to senses in different languages by the use of bilingual corpora (e.g. parallel corpora or untagged monolingual corpora in two languages) (Brown et al. , 1991; Dagan and Itai, 1994; Diab and Resnik, 2002; Li and Li, 2004; Ng et al. , 2003), (3) bootstrapping sensetagged seed examples to overcome the bottleneck of acquisition of large sense-tagged data (Hearst, 1991; Karov and Edelman, 1998; Mihalcea, 2004; Park et al. , 2000; Yarowsky, 1995).
---------------------------------------------------
P04-1033:6	3) Similarity formulae The similarity of W 1 to W 2 is the average affinity of the contexts that include W 1 to W 2, and the similarity of a context X 1 to X 2 is a weighted average of the affinity of the words in X 1 to X 2 . Similarity formulae are defined as follows: ),(),(),( 21211 1 XWaffXWweightXXsim n XW n =   + (7) (8) ),(),(),( 1),( 21211 211 21 1 WXaffWXweightWWsim else WWsim WWif n XW n n = = =   + + The weights in formula 7 are computed as reflecting global frequency, log-likelihood factors, and part of speech as used in (Karov and Edelman, 1998).
---------------------------------------------------
P04-1033:7	Thus we employ the similarity measure technique by Karov and Edelman (1998).
---------------------------------------------------
P04-1033:8	Affinity formulae are defined as follows (Karov and Edelman, 1998): ),(max),( inXWn WWsimXWaff i  = (5) (6) ),(max),( jnXWn XXsimWXaff j  = In the above formulae, n denotes the iteration number, and the similarity values are defined by WSM n and CSM n . Every word has some affinity to the context, and the context can be represented by a vector indicating the affinity of each word to it.
---------------------------------------------------
P04-1033:9	Contexts are similar to the extent that they contain similar words, and words are similar to the extent that they appear in similar contexts (Karov and Edelman, 1998).
---------------------------------------------------
C02-1058:10	A variety of unsupervised WSD methods, which use a machinereadable dictionary or thesaurus in addition to a corpus, have also been proposed (Yarowsky 1992; Yarowsky 1995; Karov and Edelman 1998).
---------------------------------------------------
P03-1008:11	Our approach to word similarity to overcome data sparseness is perhaps most similar to (Karov and Edelman, 1998).
---------------------------------------------------
P99-1004:12	1The term "similarity-based", which we have used previously, has been applied to describe other models as well (L. Lee, 1997; Karov and Edelman, 1998).
---------------------------------------------------
W07-0104:13	The sentences in the target set and feedback sets were augmented with some shallow syntactic information such as part of speech tags provided 22 Algorithm 1 KE-train: (Karov & Edelman, 1998) algorithm adapted to literal/nonliteral identification Require: S: the set of sentences containing the target word (each sentence is classified as literal/nonliteral) Require: L: the set of literal seed sentences Require: N: the set of nonliteral seed sentences Require: W: the set of words/features, w  s means w is in sentence s, s owner w means s contains w Require: epsilon1: threshold that determines the stopping condition 1: w-sim0(wx,wy) := 1 if wx = wy,0 otherwise 2: s-simI0(sx,sy) := 1, for all sx,sy  S S where sx = sy, 0 otherwise 3: i := 0 4: while (true) do 5: s-simLi+1(sx,sy) :=summationtextwxsx p(wx,sx)maxwysy w-simi(wx,wy), for all sx,sy  S L 6: s-simNi+1(sx,sy) :=summationtextwxsx p(wx,sx)maxwysy w-simi(wx,wy), for all sx,sy  S N 7: for wx,wy  W W do 8: w-simi+1(wx,wy) := braceleftBigg i = 0 summationtextsxownerwx p(wx,sx)maxsyownerwy s-simIi(sx,sy) else summationtextsxownerwx p(wx,sx)maxsyownerwys-simLi (sx,sy), s-simNi (sx,sy)} 9: end for 10: if wx,maxwyw-simi+1(wx,wy) w-simi(wx,wy)}  epsilon1 then 11: break # algorithm converges in 1epsilon1 steps.
---------------------------------------------------
W07-0104:14	(Karov & Edelman, 1998) state that the results are not likely to change much after the third iteration and we have confirmed this independently: similarity values continue to change until convergence, but cluster allegiance tends not to.
---------------------------------------------------
W07-0104:15	Since we are attempting to reduce the problem of literal/nonliteral recognition to one of word-sense disambiguation, we use an existing similarity-based word-sense disambiguation algorithm developed by (Karov & Edelman, 1998), henceforth KE.
---------------------------------------------------
