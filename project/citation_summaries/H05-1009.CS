J07-3002:1	162:164	F-Measure with an appropriate setting of  will be useful during the development process of new alignment models, or as a maximization criterion for discriminative training of alignment models (Cherry and Lin 2003; Ayan, Dorr, and Monz 2005; Ittycheriah and Roukos 2005; Liu, Liu, and Lin 2005; Fraser and Marcu 2006; Lacoste-Julien et al. 2006; Moore, Yih, and Bode 2006).
---------------------------------------------------
P06-1002:2	40:186	Two supervised alignment combination techniques (SA and SB) using 2 and 4 input alignments as described in (Ayan et al. , 2005).
---------------------------------------------------
P06-1002:3	27:186	Supervised learning techniques, such as perceptron learning, maximum entropy modeling or maximum weighted bipartite matching, have been shown to provide further improvements on word alignments (Ayan et al. , 2005; Moore, 2005; Ittycheriah and Roukos, 2005; Taskar et al. , 2005).
---------------------------------------------------
P06-1002:4	48:186	The details of how the annotations are done can be found in (Ayan et al. , 2005) and (Ittycheriah and Roukos, 2005).
---------------------------------------------------
N06-1013:5	57:176	2 From (Ayan et al. , 2005).
---------------------------------------------------
N06-1013:6	92:176	Partitioning Data: Previous work showed that partitioning the data into disjoint subsets and learning a different model for each partition improves the performance of the alignment systems (Ayan et al. , 2005).
---------------------------------------------------
N06-1013:7	165:176	A recent attempt to combine outputs of different alignments views the combination problem as a classifier ensemble in the neural network framework 102 (Ayan et al. , 2005).
---------------------------------------------------
P09-1105:8	146:165	Regarding word alignment combination, in addition to the commonly used intersection-unionrefine approach (Och and Ney, 2003), (Ayan and Dorr, 2006b) and (Ayan et al., 2005) combined alignment links from multiple word alignment based on a set of linguistic and alignment features within the MaxEnt framework or a neural net model.
---------------------------------------------------
P06-1065:9	8:192	In 2005, however, several independent efforts (Liu et al. , 2005; Fraser and Marcu, 2005; Ayan et al. , 2005; Taskar et al. , 2005; Moore, 2005; Ittycheriah and Roukos, 2005) demonstrated that discriminatively trained models can equal or surpass the alignment accuracy of the standard models, if the usual unlabeled bilingual training corpus is supplemented with human-annotated word alignments for only a small subset of the training data.
---------------------------------------------------
