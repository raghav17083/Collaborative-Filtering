More recently, researchers at Johns Hopkins University and the University of Maryland have been exploring new ways to exploit parallel corpora in order to develop monolingual resources and tools, using a process of annotation, projection, and training: Given a parallel corpus in English and a less resource-rich language, we project English annotations across the parallel corpus to the second language, using word-level alignments as the bridge, and then use robust statistical techniques in learning from the resulting noisy annotations (Cabezas, Dorr, and Resnik 2001; Diab and Resnik 2002; Hwa et al. 2002; Lopez et al. 2002; Yarowsky, Ngai, and Wicentowski 2001; Yarowsky and Ngai 2001; Riloff, Schafer, and Yarowsky 2002). 
(Diab and Resnik, 2002) used a parallel corpus for word sense disambiguation, exploiting the fact that different meanings of the same word tend to be translated into distinct words. 
We use the shorthand a27a29a28 a10 a1a31a30 for a27a29a28a32a0a33a1a35a34 a10 a1a36a30 . 2.2 The Sense Model The Sense Model makes the assumption, inspired by ideas in Diab and Resnik (2002) and Bengio and Kermorvant (2003), that the English word a0a33a1 and the Spanish word a0a37a3 in a translation pair share the same precise sense. 
This idea is explored by several researchers, (Resnik and Yarowsky, 1998; Chugur et al. , 2002; Ide, 2000; Dyvik, 1998). 
Word-level alignment is a critical component of a wide range of NLP applications, such as construction of bilingual lexicons (Melamed, 2000), word sense disambiguation (Diab and Resnik, 2002), projection of language resources (Yarowsky et al. , 2001), and statistical machine translation. 
