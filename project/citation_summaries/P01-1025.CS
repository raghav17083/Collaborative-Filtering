Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). 
Almost all of these measures can be grouped into one of the following three categories: a0 frequency-based measures (e.g. , based on absolute and relative co-occurrence frequencies) a0 information-theoretic measures (e.g. , mutual information, entropy) a0 statistical measures (e.g. , chi-square, t-test, log-likelihood, Dices coefficient) The corresponding metrics have been extensively discussed in the literature both in terms of their mathematical properties (Dunning, 1993; Manning and Schutze, 1999) and their suitability for the task of collocation extraction (see Evert and Krenn (2001) and Krenn and Evert (2001) for recent evaluations). 
She is aware, though, that this test assumes independent samples and is hardly suitable for different ranking methods applied to the same candidate set: Krenn and Evert (2001) suggest several alternative tests for related samples. 
Other potential association measures are mutual information (Damerau, 1993) and the whole battery of statistical and information-theoretic measures (t-test, loglikelihood, entropy) which are typically employed for the extraction of general-language collocations (Manning and Schcurrency1utze, 1999; Evert and Krenn, 2001). 
Although Evert and Krenn (2001) and Wermter and Hahn (2004) provide significance testing of some AMs with respect to mere frequency counting for collocation extraction, they do not differentiate whether this is due to differences in the ranking of true positives or true negatives or a combination thereof.2 As for studies on ATR (e.g. , Wermter and Hahn (2005) or Nenadic et al. 
