Approaches evaluated so far make use of dictionaries with semantic annotation (Piao et al. , 2006), WordNet (Pearce, 2001), automatically generated thesauri (Lin, 1999; McCarthy et al. , 2003; Fazly and Stevenson, 2006), vector-based methods that measure semantic distance (Baldwin et al. , 2003; Katz and Giesbrecht, 2006), translations extracted from parallel corpora (Villada Moiron and Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005). 
Like Lin (1999), we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by a semantically similar word from the automatically-built thesaurus of Lin (1998). 
One of the earliest studies in this area was reported by Lin (1999) who assumes that noncompositional phrases have a significantly different mutual information value than the phrases that are similar to their literal meanings and proposed to identify non-compositional MWEs in a corpus based on distributional characteristics of MWEs. 
Similar to Lin (1999), McCarthy et al. 
We automatically parse the corpus using the Collins parser (Collins, 1999), and further process it using TGrep2 (Rohde, 2004). 
