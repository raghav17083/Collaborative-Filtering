Case-based learning algorithms have been used in NLP for context-sensitive parsing (Simmons and Yu, 1992), for text categorization (Riloffand Lehnert, 1994); for lexical tagging tasks like part-of-speech tagging and semantic feature tagging (Daelemans et al. , submitted, Cardie, 1994, Cardie, 1993a); for semantic interpretation (e.g. , concept extraction (Cardie, 1994, Cardie, 1993a)); and for a number of low-level language acquisition tasks, including stress acquisition (Daelemans et al. , 1994) and graphemeto-phoneme conversion (Bosch and Daelemans, 1993). 
Lastly, Cardie (1992a; 1992b) presents a case-based learning approach for relative pronoun disambiguation. 
Examples include the use of decision trees for syntactic analysis (Magerman, 1995), coreference (Aone and Bennett, 1995; McCarthy and Lehnert, 1995), and cue phrase identification (Litman, 1994); the use of inductive logic programming for learning semantic grammars and building prolog parsers 113 (Zelle and Mooney, 1994; Zelle and Mooney, 1993); the use of conceptual clustering algorithms for relative pronoun resolution (Cardie, 1992a; Cardie 1992b), and the use of case-based learning techniques for lexical tagging tasks (Cardie, 1993a; Daelemans et al. , submitted). 
We then apply the linguistic bias approach to feature set selection in one natural language learning task -the relative pronoun (RP) disambiguation task from Cardie (1992a, 1992b). 
The task-specific subsets for the lexical tagging experiments of Table 1 were obtained automatically using the C4.5 decision tree algorithm (Quinlan, 1992) as described in Cardie(1993b). 
