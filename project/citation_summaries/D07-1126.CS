In the case of grammarbased parsers, a classifier is used to disambiguate in cases where the grammar leaves some ambiguity (Schneider et al. , 2007; Watson and Briscoe, 2007) 5.2.3 Learning Transition-based parsers either maintain a classifier that predicts the next transition or a global probabilistic model that scores a complete parse. 
Instead of assigning HEAD and DEPREL in a single step, some systems use a two-stage approach for attaching and labeling dependencies (Chen et al. , 2007; Dredze et al. , 2007). 
It is worth noting that variants of this scheme were used in two of the participating 928 5 10 15 20 Number of Systems 80 82 84 86 88 Accuracy Unlabeled Accuracy Labeled Accuracy Figure 1: System Combination systems, the Nilsson system (Hall et al. , 2007a) and the system of Sagae and Tsujii (2007). 
5.2.2 Inference The most common inference technique in transitionbased dependency parsing is greedy deterministic search, guided by a classifier for predicting the next transition given the current parser state and history, processing the tokens of the sentence in sequential left-to-right order7 (Hall et al. , 2007a; Mannem, 2007; Marinov, 2007; Wu et al. , 2007). 
5.3.3 Learning Most of the graph-based parsers were trained using an online inference-based method such as passiveaggressive learning (Nguyen et al. , 2007; Schiehlen and Spranger, 2007), averaged perceptron (Carreras, 2007), or MIRA (Shimizu and Nakagawa, 2007), while some systems instead used methods based on maximum conditional likelihood (Nakagawa, 2007; Hall et al. , 2007b). 
