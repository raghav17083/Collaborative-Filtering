The likelihood of realisations given concepts or semantic representations has been modeled directly, but is probably limited to small-scale and specialised applications: summarisation construed as term selection and ordering [Witbrock and Mittal, 1999], grammar-free stochastic surface realisation [Oh and Rudnicky, 2000], and surface realisation construed as attribute selection and lexical choice [Ratnaparkhi, 2000]. 
We distinguish between three types here: NLG with XSLT (Wilcock, 2003), which is basically template-based generation from XML input; stochastic approaches like (Oh and Rudnicky, 2000), where the deep generation grammar is replaced by a stochastic language model, and hybrid generation approaches like D2S (Theune et al. , 2000), which bridges the gap between NLG and speech synthesis by a prosody module. 
Ratnaparkhi (Ratnaparkhi, 2000; Ratnaparkhi, 2002) and Oh and Rudnicky (Oh and Rudnicky, 2000) both studied surface generators for the air travel domain. 
Stochastic methods for NLG may provide such automaticity, but most previous work (Knight and Hatzivassiloglou, 1995), (Langkilde and Knight, 1998), (Oh and Rudnicky, 2000), (Uchimoto et al. , 2000), (Bangalore and Rambow, 2000) concentrate on the speci cs of individual stochastic methods, ignoring other issues such as integrability, portability, and e ciency. 
For these reasons, Oh and Rudnicky (2000) use a101 -gram models and Ratnaparkhi (2000), maximum entropy to choose templates, using hand-written rules to score different candidates. 
