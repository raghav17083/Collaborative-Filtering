We designed these 4 features to capture information that will be helpful to the why questions, since it has been observed in prior work (Charniak et al. , 2000; Riloff and Thelen, 2000) that the answer 127 sentence to a why question tends to follow (or precede) the sentence in the story that has the most number of word matches with the question. 
For comparison, the HumSent scores reported in the work of (Hirschm~.n et al. , 1999), (Charniak et al. , 2000), (Riloff and Thelen, 2000), and (Wang et al. , 2000) are 36.3%, 41%, 39.7%, and 14%, respectively. 
3.1 Feature Representation Our feature representation was designed to capture the information sources that prior work (Hirschman et al. , 1999; Cha_niak et al. , 2000; Riloff and Thelen, 2000) used in their computations or rules. 
Naturally, our current work on question answering for the reading comprehension task is most related to those of (Hirschman et al. , 1999; Charniak et al. , 2000; Riloffand Thelen, 2000; Wang et al. , 2000). 
 keywords in questions It has been observed in the work of (Riloff and Thelen, 2000) that certain words in a when or where question tend to indicate that the dateline is an ~n~wer sentence to the question. 
