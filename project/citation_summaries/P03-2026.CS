The method (Izumi et al. , 2003) aims to detect omission-type and replacement-type errors and transformation-based leaning is employed in (Shi and Zhou, 2005) to learn rules to detect errors for speech recognition outputs. 
For example, (Izumi et al., 2003) reported error rates for English prepositions that were as high as 10% in a Japanese learner corpus. 
To date, single human annotation has typically been the gold standard for grammatical error detection, such as in the work of (Izumi et al., 2004), (Han et al., 2006), (Nagata et al., 2006), (Eeg-Olofsson and Knuttson, 2003)2. 
The above errors are very common among Japanese learners of English (Kawai et al. , 1984; Izumi et al. , 2003). 
A maximum entropy model, using lexical and POS features, is trained in (Izumi et al., 2003) to recognize a variety of errors. 
