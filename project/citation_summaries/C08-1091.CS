Quality assessment of a learning algorithms output and selection of high quality instances have been addressed for supervised algorithms (see (Caruana and Niculescu-Mizil, 2006) for a survey) and specifically for supervised constituency parsers (Yates et al., 2006; Reichart and Rappoport, 2007; Ravi et al., 2008). 
6 Grammar Induction Experiment In this section we analyse the behavior of V, VI, NVI and NVIK using a highly non-trivial NLP application with large real datasets, the unsupervised labeled parse tree induction (LTI) algorithm of (Reichart and Rappoport, 2008). 
Assessing the quality of a learning algorithms output and selecting high quality instances has been addressed for supervised algorithms (Caruana and Niculescu-Mizil, 2006) and specifically for supervised parsers (Yates et al., 2006; Reichart and Rappoport, 2007; Kawahara and Uchimoto, 2008; Ravi et al., 2008). 
This makes sense, because the overall quality of the labeling induction algorithm is indeed not that high: using oneto-one mapping (the more forgiving mapping), the accuracy of the labels induced by MDL+SC is only 4572% (Reichart and Rappoport, 2008). 
4This is in contrast to algorithms for selection from the results of supervised constituency parsers, which were evaluated only for English (Yates et al., 2006; Reichart and Rappoport, 2007; Ravi et al., 2008). 
