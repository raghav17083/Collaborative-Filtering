Supervised learning is used in hybrid modules such as NE [Srihari et al 2000], NE Normalization [Li et al 2002] and Co-reference. 
Document Processor Knowledge Resources Lexicon Resources Grammars Process Manager Tokenlist Legend Output Manager Source Document Linguistic Processor(s)Tokenizer Tokenlist Lexicon Lookup POS Tagging NE Tagging Shallow Parsing Relationship Extraction Document pool NE CE EP SVO Time Normalization Profile/Event Consolidation Event Extraction Abbreviations NE = Named Entity CE = Correlated Entity EP = Entity Profile SVO = Subject-Verb-Object GE = General Event PE = Predefined Event Rule-based Pattern Matching Procedure or Statistical Model Hybrid Module GE Statistical Models PE IE Repository Deep Parsing Coreference Location Normalization Measurement Normalization Figure 1: System Architecture of InfoXtract InfoXtract combines the Maximum Entropy Model (MaxEnt) and Hidden Markov Model for NE tagging [Srihari et al. 2000]. 
Both the linguistic approach (Grishman, 1995; Wakao et al., 1996) and the ML based approach (Borthwick, 1999; Srihari et al., 2000) use gazetteer lists. 
The state-of-the-art exemplified by systems such as NetOwl [Krupka & Hausman 1998], IdentiFinder [Miller et al 1998] and InfoXtract [Srihari et al 2000] has reached near human performance, with 90% or above F-measure. 
In InfoXtract, we combine Maximum Entropy Model (MaxEnt) and Hidden Markov Model for NE tagging (Shrihari et al. ,, 2000). 
