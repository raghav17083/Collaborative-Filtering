The objective metrics that have been used to evaluate a dialog as a whole include (Abella, Brown, and Buntschuh, 1996; Ciaremella, 1993; Danieli and Gerbino, 1995; Hirschman et al. , 1990; Hirschman et al. , 1993; Polifroni et al. , 1992; Price et al. , 1992; Smith and Hipp, 1994; Smith and Gordon, 1997; Walker, 1996):  percentage of correct answers with respect to a set of reference answers  transaction success, task completion, or quality of solution  number of turns or utterances;  dialogue time or task completion time  mean user response time  mean system response time  frequency of diagnostic error messages  percentage of "non-trivial" (more than one word) utterances. 
Speech recognition (ASR) accuracy in limited input systems is better than in flexible input systems (Danieli and Gerbino, 1995; Smith and Gordon, 1997). 
The value of RT in the AVM instantiation for the dialogue would be "reserve" Second, consider the very different domain and task of diagnosing a fault and repairing a circuit (Smith and Gordon, 1997). 
However, task completion rates and times are better in flexible input systems (ChuCarroll and Nickerson, 2000; Smith and Gordon, 1997). 
T ID,CB,RB,FT, FC,T ID,CB,RB,FT, FC,T ID,CB,RB,FT, FC,T ID ID CB Figure 6: A circuit domain dialogue (Smith and Gordon, 1997), with AVM tagging Smith and Gordon collected 144 dialogues for this task, in which agent initiative was varied by using different dialogue strategies, and tagged each dialogue according to the following subtask structure: 13  Introduction (I)--establish the purpose of the task . Assessment (A)--establish the current behavior  Diagnosis (D)---establish the cause for the errant behavior  Repair (R)---establish that the correction for the errant behavior has been made  Test (T)---establish that the behavior is now correct Our informational analysis of this task results in the AVM shown in Table 7. 
