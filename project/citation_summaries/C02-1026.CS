Clearly, this capability can be extended to include (definitional and other) information provided by other sources, including encyclopedias and the web (Lin 2002). 
3.2 Type 2: Qtargets, the QA Typology, and the Semantic Ontology We classify desired answers by their semantic type, which have been taxonomized in the Webclopedia QA Typology (Hovy et al. , 2002), Candidate answer parsing  Steps: parse sentences  Engines: CONTEX Matching  Steps: match general constraint patterns against parse trees match desired semantic type against parse tree elements assign score to words in sliding window  Engine: Matcher Ranking and answer extraction  Steps: rank candidate answers extract and format them  Engine: Answer ranker/formatter QA typology  QA types, categorized in taxonomy Constraint patterns  Identify likely answers in relation to other parts of the sentence Create query Retrieve documents Select & rank sentences Parse top sentences Parse question Input question Perform additional inference Rank and prepare answers Output answers Question parsing  Steps: parse question find desired semantic type  Engines: IdentiFinder (BBN) CONTEX Match sentences against answers Query creation  Steps: extract, combine important words expand query words using WordNet create queries, order by specificity  Engines: Query creator IR  Steps: retrieve top 1000 documents  Engines: MG (RMIT Melbourne) Sentence selection and ranking  Steps: score each sentence in each document rank sentences and pass top 300 along  Engines:Ranker Figure 1. 
The Web track in past TREC conferences shows that URL, HTML structure, anchor text, hyperlinks, and document length tend to contain important heuristic clues for web clustering and information retrieval (Craswell and Hawking, 2002). 
For definitional QA task, Lin (2002) presented an approach in which web-based answer reranking is combined with dictionary-based (e.g. , WordNet) reranking, which leads to a 25% increase in mean reciprocal rank (MRR). 
SVMs offer two important advantages for text classification (Joachims, 1998; Sebastiani, 2002): (1) Term selection is often not needed, as SVMs tend to be fairly robust to overfitting and can scale up to considerable dimensionalities, and (2) No human and machine effort in parameter tuning on a validation set is needed, as there is a theoretically motivated default choice of parameter settings which have been shown to provide best results. 
