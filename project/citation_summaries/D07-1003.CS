We compare lexical phrase and dependency syntax features, as well as a novel com2To date, QG has been used for word alignment (Smith and Eisner, 2006), adaptation and projection in parsing (Smith and Eisner, 2009), and various monolingual recognition and scoring tasks (Wang et al., 2007; Das and Smith, 2009); this paper represents its first application to MT. 219 , T source and target language vocabularies, respectively Trans :  {NULL}  2T function mapping each source word to target words to which it may translate s = s0,,sn  n source language sentence (s0 is the NULL word) t = t1,,tm  Tm target language sentence, translation of s s : {1,,n}  {0,,n} dependency tree of s, where s(i) is the index of the parent of si (0 is the root, $) t : {1,,m}  {0,,m} dependency tree of t, where t(i) is the index of the parent of ti (0 is the root, $) a : {1,,m}  2{1,,n} alignments from words in t to words in s;  denotes alignment to NULL  parameters of the model gtrans(s,a,t) lexical translation features (2.1): flex(s,t) word-to-word translation features for translating s as t fphr(sji,tlscriptk) phrase-to-phrase translation features for translating sji as tlscriptk glm(t) language model features (2.2): fN(tjjN+1) N-gram probabilities gsyn(t,t) target syntactic features (2.3): fatt(t,j,tprime,k) syntactic features for attaching target word tprime at position k to target word t at position j fval(t,j,I) syntactic valence features with word t at position j having children I  {1,,m} greor(s,s,a,t,t) reordering features (2.4): fdist(i,j) distortion features for a source word at position i aligned to a target word at position j gtree2(s,a,t) tree-to-tree syntactic features (3): fqg(i,iprime,j,k) configuration features for source pair si/siprime being aligned to target pair tj/tk gcov(a) coverage features (4.2) fscov(a), fzth(a), fsunc(a) counters for covering each s word each time, the zth time, and leaving it uncovered Table 1: Key notation. 
This paper focuses on dependency parsing, which has become widely used in relation extraction (Culotta and Sorensen, 2004), machine translation (Ding and Palmer, 2005), question answering (Wang et al., 2007), and many other NLP applications. 
Since it loosely links the two sentences syntactic structures, QG is well suited for problems like word alignment for MT (Smith and Eisner, 2006) and question answering (Wang et al., 2007). 
In that paper, QG was applied to word alignment and has since found applications in question answering (Wang et al., 2007), paraphrase detection (Das and Smith, 2009), and machine translation (Gimpel and Smith, 2009). 
These are identical to prior work (Smith and Eisner, 2006; Wang et al., 2007), except that we add a root configuration that aligns the target parent-child pair to null and the head word of the source sentence, respectively. 
