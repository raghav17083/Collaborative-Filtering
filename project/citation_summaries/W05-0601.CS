A more complex way of calculating the semantic similarity as the matrix entries was also proposed (Basili et al., 2005).


Any linear kernel for texts is characterized by K(ai,aj) = aprimeiSprimeSaj, where S is an appropriately shaped matrix commonly referred to as semantic smoothing matrix (Siolas and dAlche Buc, 2000; Shawe-Taylor and Cristianini, 2004; Basili et al., 2005; Mavroeidis et al., 2005; Bloehdorn et al., 2006).


Regarding future work, there are many research line that may be followed: i) Capturing more features by employing external knowledge such as ontological, lexical resource or WordNet-based features (Basili et al., 2005a; Basili et al., 2005b; Bloehdorn et al., 2006; Bloehdorn and Moschitti, 2007) or shallow semantic trees, (Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti and Bejan, 2004; Moschitti et al., 2007; Moschitti, 2008; Moschitti et al., 2008).


In the following we resort to a multiset version of the proximity measure used in (Siolas and dAlche Buc, 2000), though more refined alternatives are also possible (for example using the conceptual density as in (Basili et al. , 2005)).


(Basili et al., 2005; Bloehdorn et al., 2006), will be likely improve our models, especially when combined syntactic and semantic kernels are used, i.e.


