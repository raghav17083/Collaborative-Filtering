N09-3017:1	99:131	98 Ye and Baldwin (2007) participated in the SemEval task using a maximum entropy classifier and achieved the highest accuracy of the participating systems.
---------------------------------------------------
N09-3017:2	23:131	For evaluation, we compared our results to those of the three systems that participated in the task (MELB: Ye and Baldwin (2007); KU: Yuret (2007); IRST: Popescu et al.
---------------------------------------------------
N09-3017:3	128:131	While the contribution of the direct context (+/-7 words) might have a stronger effect than higher level features (Ye and Baldwin, 2007), we conclude from our findings that higher level features do make an important contribution.
---------------------------------------------------
N09-3017:4	86:131	System Accuracy kNN 684 SVM (RBF Kernel) 692 J48 decision trees 712 Multinomial Nave Bayes 731 Maximum Entropy 751 Most Frequent Sense 396 IRST (Popescu et al., 2007) 496 KU (Yuret, 2007) 547 MELB (Ye and Baldwin, 2007) 693 Table 1.
---------------------------------------------------
N09-3017:5	77:131	2.3 Classifier Training We chose maximum entropy (Berger, 1996) as our primary classifier because the highest performing systems in both the SemEval-2007 preposition sense disambiguation task (Ye and Baldwin, 2007) and the general word sense disambiguation task (Tratz et al., 2007) used it.
---------------------------------------------------
N09-3017:6	57:131	2.3 Classifier Training We chose maximum entropy (Berger et al., 1996) as our primary classifier, since it had been successfully applied by the highest performing systems in both the SemEval-2007 preposition sense disambiguation task (Ye and Baldwin, 2007) and the general word sense disambiguation task (Tratz et al., 2007).
---------------------------------------------------
D09-1047:7	93:202	This would have made our system the second best system in the competition, behind the MELB-YB system (Ye and Baldwin, 2007).
---------------------------------------------------
D09-1047:8	184:202	Ye and Baldwin (2007) used semantic role tags from surrounding tokens as part of the MELB-YB preposition WSD system.
---------------------------------------------------
