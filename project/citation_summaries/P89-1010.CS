This algorithm uses mutual information as a measure of the strength of semantic association between two words (Church & Hanks, 1989). 
1 and Church and Hanks 1989). 
The Pointwise Mutual Information (PMI) between two words, word1 and word2, is defined as follows (Church & Hanks, 1989): p(word1 & word2) PMI(word1, word2) = log2 p(word1) p(word2) (1) Here, p(word1 & word2) is the probability that word1 and word2 co-occur. 
6.1.2 Point-wise Mutual Information (a16 ) Point-wise Mutual information of a collocation (Church and Hanks, 1989) is defined as, a16a18a17a19a11a21a20a23a22a25a24a27a26 a15a28a17a19a11a2a20a23a22a25a24a30a29a31a15a28a17a33a32a34a20a35a32a36a24 a15a28a17a19a11a2a20a35a32a36a24a30a29a37a15a28a17a33a32a34a20a23a22a25a24 where, a11 is the verb and a22 is the object of the collocation. 
Many efficient techniques exist to extract multiword expressions, collocations, lexical units and idioms (Church and Hanks, 1989; Smadja, 1993; Dias et al. , 2000; Dias, 2003). 
