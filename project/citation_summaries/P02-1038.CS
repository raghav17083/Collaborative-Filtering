1 Introduction The state-of-the-art statistical machine translation (SMT) model is the log-linear model (Och and Ney, 2002), which provides a framework to incorporate any useful knowledge for machine translation, such as translation model, language model etc. In a SMT system, one important problem is the re-ordering between words and phrases, especially when the source language and target language are very different in word order, such as Chinese and English. 
In the state of the art statistical machine translation, the posterior probability Pr(eI1|f J1 ) is directly maximized using a log-linear combination of feature functions (Och and Ney, 2002): eI1 = argmax eI1 exp parenleftBigsummationtextM m=1 mhm(e I 1, f J 1 ) parenrightBig summationtext eI1 exp parenleftBigsummationtextM m=1 mhm(e I 1, f J 1 ) parenrightBig (3) where hm(eI1, f J1 ) is a feature function, such as a ngram language model or a translation model. 
(2002), and Och and Ney (2002). 
This approach used the same set of features as the alignment template approach in (Och and Ney, 2002). 
This model is a special case of the Direct Translation Model proposed in (Papineni et al. , 1997; Papineni et al. , 1998) for language understanding; (Foster, 2000) demostrated perplexity reductions by using direct models; and (Och and Ney, 2002) employed it very successfully for language translation by using about ten feature functions: p(TjS) = 1Z exp summationdisplay i ii(S, T) Many of the feature functions used for translation are MLE models (or smoothed variants). 
