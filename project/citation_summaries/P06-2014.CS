(Cherry and Lin, 2006) used dependency structures as soft constraints to improve word alignment in an ITG framework. 
An exception to this is the work of Cherry and Lin (2006), who discriminatively trained one-to-one ITG models, albeit with limited feature sets. 
However, few of these methods have explicitly addressed the tension between word alignments and the syntactic processes that employ them (Cherry and Lin, 2006; Daume III and Marcu, 2005; Lopez and Resnik, 2005). 
(2005) and Cherry and Lin (2006), but adding ITG models that are trained to maximize conditional likelihood. 
(Lopez and Resnik, 2005) and (Denero and Klein, 2007) modify the distortion model of the HMM alignment model (Vogel et al., 1996) to reflect tree distance rather than string distance; (Cherry and Lin, 2006) modify an ITG aligner by introducing a penalty for induced parses that violate syntactic bracketing constraints. 
