Uncertainty sampling (Lewis and Gale, 1994) is a popular selective sampling technique, and has been widely studied in natural language processing (NLP) applications such as word sense disambiguation (WSD) (Chen et al., 2006; Chan and Ng, 2007), text classification (TC) (Lewis and Gale, 1994; Zhu et al., 2008), statistical syntactic parsing (Tang et al., 2002), and named entity recognition (Shen et al., 2004). 
With the exception of (Chan and Ng, 2007) which tried to adapt a WSD system trained on the BC part of the DSO corpus to the WSJ part of the DSO corpus, the other researchers simply applied active learning to reduce the annotation effort required and did not deal with the issue of adapting a WSD system to a new domain. 
Chan and Ng (2007) performed supervised domain adaptation on a manually selected subset of 21 nouns from the DSO corpus. 
WSD is one of the fundamental problems in natural language processing and is important for applications such as machine translation (MT) (Chan et al., 2007a; Carpuat and Wu, 2007), information retrieval (IR), etc. WSD is typically viewed as a classification problem where each ambiguous word is assigned a sense label (from a pre-defined sense inventory) during the disambiguation process. 
Instance weighting (Jiang and Zhai, 2007) and active learning (Chan and Ng, 2007) are also employed in domain adaptation. 
