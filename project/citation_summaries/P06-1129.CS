(1) Here, the candidate generator gen(s) enumerates candidates of destination (correct) strings, and the scorer P(t|s) denotes the conditional probability of the string t for the given s. The scorer was modeled by a noisy-channel model (Shannon, 1948; Brill and Moore, 2000; Ahmad and Kondrak, 2005) and maximum entropy framework (Berger et al., 1996; Li et al., 2006; Chen et al., 2007). 
We then scored each query pair (q1,q2) in this subset using the log-likelihood ratio (LLR, Dunning, 1993) between q1 and q2, which measures the mutual dependence within the context of web search queries (Jones et al., 2006a). 
The complexity of query spelling correction task requires the combination of these types of evidence, as done in (Cucerzan and Brill, 2004; Li et al. , 2006). 
Another important contribution of our approach is that we derive our semantic similarity models by mining user query logs, which has been explored for the purposes of collecting related words (e.g., Jones et al., 2006a), improving search results ranking (e.g., Craswell and Szummer, 2007) and learning query intention (e.g., Li et al., 2008), but not for the task of collecting term variations. 
4 Discriminative Model of Identifying Term Variation Recent work in spelling correction (Ahmed and Kondrak, 2005; Li et al., 2006; Chen et al., 2007) and normalization (Okazaki et al., 2008b) formulates the task in a discriminative framework:    = argmax  gen     ( | ) This model consists of two components: gen(q) generates a list of candidates C(q) for an input query q, which are then ranked by the ranking function P(c|q). 
