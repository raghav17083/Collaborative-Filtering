A97-1021:1	32:163	Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Klavans and Tzoukermann, 1995; Wu and Xia, 1995) or extraction of syntactic constructions from online dictionaries and corpora (Brent, 1993).
---------------------------------------------------
P06-2067:2	130:193	Our evaluator has two parts: the Binomial Hypothesis Test (Brent, 1993) and a back-off algorithm (Sarkar and Zeman, 2000).
---------------------------------------------------
J05-3003:3	102:532	The extracted frames are noisy as a result of parser errors and so are filtered using the binomial hypothesis theory (BHT), following Brent (1993).
---------------------------------------------------
J05-3003:4	100:532	Manning (1993) attempts to improve on the approach of Brent (1993) by passing raw text through a stochastic tagger and a finite-state parser (which includes a set of simple rules for subcategorization frame recognition) in order to extract verbs and the constituents with which they co-occur.
---------------------------------------------------
J05-3003:5	92:532	Brent (1993) relies on morphosyntactic cues in the untagged Brown corpus as indicators of six predefined subcategorization frames.
---------------------------------------------------
W05-1529:6	10:45	The first three components are responsible for generating SCF cues from the training corpora and the last component, consisting of the Binomial Hypothesis Test (Brent, 1993) and a back-off algorithm (Sarkar & Zeman, 2000), is used to filter SCF cues on the basis of their reliability and likelihood.
---------------------------------------------------
W97-0116:7	134:161	4 Related Work The automatic extraction of English subcategorization frames has been considered in (Brent, 1991; Brent, 1993), where a procedure is presented that takes untamed text as input and generates a list of verbal subcategorization frames.
---------------------------------------------------
W97-0116:8	143:161	The final component assesses the frames encountered by the parser by using the same model as (Brent, 1993), with the error rate set empirically.
---------------------------------------------------
W94-0115:9	8:139	For the first, even Brent's (1993) 'learning of lexical syntax' takes a distinct component of grammar rules as its starting point in learning a lexicon.
---------------------------------------------------
P07-3016:10	33:140	(Brent, 1993) uses regular patterns.
---------------------------------------------------
P08-1050:11	203:222	Following studies on automatic SCF extraction (Brent, 1993), we apply a statistical test (Binomial Hypothesis Test) to the unfiltered-Levin-SCF to filter out noisy SCFs, and denote the resulting SCF set as filtered-LevinSCF.
---------------------------------------------------
J01-3003:12	13:664	In answering these questions, some approaches to lexical acquisition have focused on learning syntactic information about verbs, by automatically extracting subcategorization frames from a corpus or machine-readable dictionary (Brent 1993; Briscoe and Carroll 1997; Dorr 1997; Lapata 1999; Manning 1993; McCarthy and Korhonen 1998).
---------------------------------------------------
P04-1047:13	39:199	(Briscoe and Carroll, 1997) observe that in the work of (Brent, 1993), (Manning, 1993) and (Ushioda et al. , 1993), the maximum number of distinct subcategorization classes recognized is sixteen, and only Ushioda et al. attempt to derive relative subcategorization frequency for individual predicates.
---------------------------------------------------
P04-1047:14	29:199	(Brent, 1993) relies on local morphosyntactic cues (such as the -ing suffix, except where such a word follows a determiner or a preposition other than to) in the untagged Brown Corpus as probabilistic indicators of six different predefined subcategorisation frames.
---------------------------------------------------
P04-1047:15	31:199	(Manning, 1993) observes that Brents recognition technique is a rather simplistic and inadequate approach to verb detection, with a very high error rate.
---------------------------------------------------
W00-1327:16	14:157	These methods are reported to be particularly unreliable for low frequency scFs (Brent, 1991, 1993; Briscoe and Carroll, 1997; Manning, 1993; Manning and Schiitze, 1999; Korhonen, Gorrell and McCarthy, 2000), resulting in a poor overall performance.
---------------------------------------------------
W00-1327:17	9:157	Over the past years acquiring subcategorization dictionaries from textual corpora has become increasingly popular (e.g. Brent, 1991, 1993; Ushioda et al. , 1993; Briscoe and Carroll, 1997; Manning, 1993; Carroll and Rooth 1998; Gahl, 1998; Lapata, 1999, Sarkar and Zeman, 2000).
---------------------------------------------------
E99-1007:18	8:197	Yet there have been few attempts to learn finegrained lexical classifications from the statistical analysis of distributional data, analogously to the induction of syntactic knowledge (though see, e.g., (Brent, 1993; Klavans and Chodorow, 1992; Resnik, 1992)).
---------------------------------------------------
P06-3014:19	110:139	(ii) Apply some statistical tests such as the Binomial Hypothesis Test (Brent, 1993) and loglikelihood ratio score (Dunning, 1993) to SCCs to filter out false SCCs on the basis of their reliability and likelihood.
---------------------------------------------------
J05-1004:20	70:501	While learning syntactic subcategorization frames from corpora has been shown to be possible with reasonable accuracy (Manning 1993; Brent 1993; Briscoe and Carroll 1997), this work does not address the semantic roles associated with the syntactic arguments.
---------------------------------------------------
W96-0306:21	14:123	Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Klavans and Tzoukermann, 1996; Wu and Xia, 1995), or extraction of syntactic constructions from online dictionaries and corpora (Brent, 1993; Dorr, Garman, and Weinberg, 1995).
---------------------------------------------------
C94-1073:22	165:304	5 Related work Previous natural language acquisition models couht be characterized as interactive acquisition \[tang & tIirschman, 1988; Liu & Soo, I993a, 1993b; Velardi ct al. , 1991\], corpus-based acquisition \[Brent, 1993; 3acobs & Zernik, 1988; Zernik, 1989\], dictionary-based acquisition \[Montemagni & Vanderwende, 1992; Sanfilippo & Pozanski, 1992\], statistics-based acquisition \[Smadja, 1991; Sekine et al, 1992\], and connectionistbased acquisition \[Paisal & Kwasny, 1990; McClelland & Kawamoto, 1986\].
---------------------------------------------------
P08-3010:23	13:124	Automatic acquisition of SCFs has therfore been an active research area since the mid-90s (Manning, 1993; Brent, 1993; Briscoe and Carroll, 1997).
---------------------------------------------------
P08-3010:24	107:124	4.2 Automatic Work Experiments have been made on the automatic acquisition of subcategorization frames since mid 1990s (Brent, 1993; Briscoe and Carroll, 1997).
---------------------------------------------------
P06-2043:25	7:42	Since Brent (1993) a considerable amount of research focusing on large-scaled automatic acquisition of subcategorization frames (SCF) has met with some success not only in English but also in many other languages, including German (Schulte im Walde, 2002), Spanish (Chrupala, 2003), Czech (Sarkar and Zeman, 2000), Portuguese (Gamallo et.
---------------------------------------------------
W02-0906:26	96:241	This shows to which extent the range of arguments is fine grained, in contrast to other works where the range is at the categorial level, such as NP or PP (M. Brent 1993, C. Manning 1993, P. Merlo & M. Leybold 2001).
---------------------------------------------------
W99-0503:27	6:7	and CAUS ate slgmficantly different for unaccusattve and object-dtop verbs, indicating that we need additional featules that have different values across these two classes In Section 2 1, we noted the differing semantic role asmgnments for the verb classes, and hypothesized that these differences would affect the expression of syntactic features that ate countable in a corpus For example, the c ~bs feature approximates sen\]antic role reformation b.~ encoding the oxerlap beh~een nouns that can occur m the ~ubject and object positions of a cau~ative xetb Here x~e suggest another feature, that of ammacy of subject, that is intended to distinguish nouns that receive an Agent role flora those that receive a Theme role Recall that objectdrop verbs assign Agent to their subject in both the transitive and intransitive alternations, while unaccusattves assign Agent to their subject only in the transitive, and Theme m the intransitive We expect then that object-drop verbs will occur more often with an animate subject Note again that ~e are 20 II Features \[Acc% SE% II I VBD ACT INTR CAUS I 63 7 0 6 \] VBD ACT INTR CAUS PRO 70 7 0 4 Table 6 Percentage Accuracy (Acc%) and Standard Error (SE%) of C5 0, W~th and W~thout New PRO Feature, All Verb Classes (33 8% basehne) making use of frequency dmtnbutmns--the clatm ~s not that only Agents can be ammate, but rather that nouns that receive the Agent role will more often be ammate than nouns that receive the Theme role A problem w~th a feature hke ammacy ~s that ~t requires etther manual determmatmn of the antmacy of extracted subjects, or reference to an on-hne resource such as WordNet for determining ammacy To approximate ammacy w~th a feature that can be extracted automatically, and w~thout reference to a resource external to the corpus, we instead count pronouns (other than ~t) m subject positron The assumptmn ~s that the words I, we, you, she, he, and they most often refer to ammate ent~tms The values for the new feature, P~.O, were determined by automatmally extracting all subject/verb tuples including our 59 examples verbs (from the WSJ88 parsed corpus), and computing the ratm of occurrences of pronouns to all subjects We again apply t-tests to our new data to determine whether the sets of PRo values d~ffer across the verb classes Interestingly, we find that the Prto values for unaccusat~ve verbs (the only class to ass~gn Theme role to the sub tect m one of tts alternatmns) are s~gmficantly dtffe~ent from those for both unergatlve and object-drop verbs (p< 05) Moreover, the PRo values for unergat~ve and object-drop verbs (whose subjects are Agents m bo~h alternatmns) are not s~gmficantly d~fferent Th~s pattern confirms the abd~ty of the feature to capture the thematm d~stmctmn between unaccusat~ve verbs and the other two classes Table 6 shows the result of applying C5 0 (10-fold eross-vahdatmn repeated 50 t~mes) to the three-x~ay classfficatmn task using the PRo feature m conjunctmn w~th the four previous features ~.ccuracy ranproves to over 70%, a teductmn m the error rate of almost 20% due to th~s single nex~ feature Moteover, classifying the unaccusat~ve an2 object-drop verbs using the new feature m conjunctmn w~th the prevmus four leads to accuracy of over 68% (compared to 58% w~thout PRo) We conclude that this feature ~s ~mportant in d~stmgmshlng unaccusat~ve and object-drop verbs, and hkely contributes to the tmprovement m the three-way classtficatton because of th~s Future work wdl examine the performance w~thm the verb classes of th~s new set of features to see whether accuracy has also tmproved for unergatire verbs 5 Conclusions In thin paper, we have presented an m-depth case study, m whmh we investigate varmus machine learnmg techmques to automatically classify a set of verbs, based on dlstnbutmnal features extracted from a very large corpus Results show that a small number of hngmstlcally motivated grammatical features are sufficmnt to reduce the error rate by mote than 50% over chance, acluevmg a 70% acctuacy rate m a three-way classfficatmn task Tins leads us to conclude that corpus data is a usable repository of verb class mformatmn On one hand ~e observe that semantlc propemes of verb classes (such as causatlvlty, or ammacy of subject) may be usefully approximated through countable syntactic features Even with some noise, lexmal propertms are reflected m the corpus robustly enough to positively contribute m classlficatmn On the other hand, however, we remark that deep hngumtm analysis cannot be ehmmated--m our approach, it is embedded m the selection of the features to count We also think that using hngumtlcally motivated features makes the approach very effective and easdy scalable we report a 56% reductmn m error rate, w~th only five features that are relatwely straightforward to count Acknowledgements This research was partly sponsored by the S~ lss Natmnal Scmnce Foundatmn, under fello~slup 821046569 to Paola Merlo, by the US Natmnal Scmnce Foundatmn, under grants #9702331 and #9818322 to $uzanne Stevenson, and by the Infotmatton Sciences Councd of Rutgers Umverslty ~,~,e thank Martha Palmer for getting us started on tlus ~ork and Mmhael Colhns for gwmg us access to the output of his parser We gratefully acknowledge the help of Ixlva Dickinson, ~ho calculated no~mahzatmns of the corpus data Appendix A The une~gatx~es are manner of morton ~erbs jumptd rushed, malched, leaped floated, laced, huslwd uandered, vaulted, paraded, galloped, gl,ded, hzked hopped jogged, scooted, ncurlzed, ~kzpped, hptoed, trotted The unaccusau~es are verbs of change of state opened, exploded, flooded, dzs~olved, cracked, hardened bozled, melted,.fractured,,ol,dzfied, collapsed cooled folded, w~dened, changed, clealed, dzwded, ~,mmered stabdzzed The object-dlop verbs are unspecffied object altelnatron verbs played, painted, k,cked, carved, reaped, washed, danced, yelled, typed, kmtted bolrowed mhet21 tted, organtzed, rented, sketched, cleaned, packed, studted, swallowed, called References Thomas G Bever 1970 The cogmtwe basis for hngmstlc structure In J R Hayes, e&tor, Cognttson and the Development of Language John Wdey, New York Michael Brent 1993 From grammar to le~con Unsupervmed learmng of \[ex~cal syntax Computational Linguistics, 19(2) 243-262 Edward Bnscoe and Ann Copestake 1995 Lex~cal rules m the TDFS framework Techmcal report, AcquflexI I Working" Papers Anne-Marm Brousseau and Ehzabeth R~tter 1991 A non-umfied analysis of agent~ve verbs In West Coast Conference on Formal Lmgutstzcs, number 20, pages 53-64 M~chael John Colhns 1997 Three generaUve, lexacahsed models for statistical parsmg In Proc of the ~5th Annual Meeting of the ACL, pages 16-23 Hoa Trang Dang, Kann K~pper, Martha Palmer, and Joseph Rosenzwe~g 1998 Investtgatmg regular sense extenmons based on mteresecttve Levm classes In Proc of the 361h Annual Meeting of the ACL and the 171h \[nternatwnal Conference on Computatwnal L,ngu,st,cs (COLING-A CL '98), pages 293-299, Montreal, Canada Umvers~t6 de Montreal Bonme Dorr and Doug Jones 1996 Role of word sense d~samb~guatmn m lexacal acqms~tmn Predmtmg semantics from syntactic cues In Proc of the 161h Internattonal Conference on Computat*onal Lmgutsttcs, pages 322-327, Copenhagen, Denmark COLING Bonnie Dorr 1997 Large-scale chctmnary constructmn for foreign language tutonng and mterhngual machine translatmn Machine Translatton, 12 1-55 Hana Fd~p M~chael Tanenhaus, Greg Carlson, Paul AIlopenna, and Joshua Blatt 1999 Reduced relatives judged hard require constraint-based analyses In P Merlo and S Stevenson, echtors, Sentence Processmg and the Lextcon Formal, Computational, and Ezpertmental Perspectives, John Benjamms, Holland Ken Hale and Jay Keyser 1993 On argument structure and the lexacal representatmn of s:~ ntact~c relatmns In K Hale and J Keyser, editors, The t',ew from Budding ~0, pages 53-110 MIT Press Juchth L Ixlavans and Martin Chodorow 1992 Degrees of stat~vlty The lexacal representatmn of verb aspect In Proceedmg~ of the Fourteenth International Conference on Computahonal Lmgmst,cs Juchth Ixlavans and Mm-Yen Kan 1998 Role of ~erbs m document analysis In Proc of the 361h Annual Meeting of the ACL and the 171h \[nternatzonal Conference on Computational Lmgutsttcs ( C O L L'v G4 C L '98), pages 680-686, Montreal, Canada Umvers~te de Montreal Beth Levm and/Vlalka Rappapti(t'Hovav 1995 (Jnaccusatwlty MIT Press, Cambridge, MA Beth Le~m 1993 Enghsh Verb Clas~e~ and 4lternatwns Chacago Umvers~ty Press, Chicago, IL Maryellen C MacDonald 1994 Probablhstlc constramts and syntactic amblgtuty resolution Language and Cognltzve Processes, 9(2) 157-201 Paola Merlo and Suzanne Stevenson 1998 What grammars tell us about corpora the case of reduced relative clauses In P1oceedmgs of the Slzth Workshop on Very Large Corpora, pages 134-142, Montreal, CA George Miller, R Beckw~th, C Fellbaum, D Gross, and Ix I~hller 1990 Fwe papers on Wordnet Techmcal report, Cogmtzve Scmnce Lab, Princeton Ual~erstt~ Martha Palmer 1999 Coasmtent criteria for sense distmctmns Computmg \]or the Hamamttes Fernando Perelra, Naftah Tlshby, and Ldhan Lee 1993 Dlstrabutmnal clustering of enghsh words \[n Proc of the 31th 4nnual Meeting of the 4CL, pages 183-190 Fernando Perexra, Ido Dagan, and Lalhan Lee 1997 Slmdanty-based methods for word sense dlsamblguatmn In Proc of the 35th Annual Meeting of the 4 CL and the 8th Conf of the E 4 CL (A CL/EA CL '97) pages 56 -63 Geoffrey K Pullum 1996 Learnabthty, hyperlearnrag, and the poverty of the sttmulus In Jan Johnson, Matthew L Jute, and Jen L Moxley, editors, ~nd Annual Meeting of the Berkeley Lmgutstzcs Soctety General Sesston and Parasesswn on the Role of Learnabdzty m Grammatzcal Theory, pages 498-513, Berkeley, Cahforma Berkeley Linguistics Socmty James Pustejovsky 1995 The Generatwe Lexicon MIT Press J Ross Qumlan 1992 C$ 5 Programs fo~ Machine Learning Series m Machme Learning Morgan Ixaufmann, San Mateo, C 4.
---------------------------------------------------
W99-0503:28	1:7	Supervised Learning of Lexical Semantic Verb Classes Using Frequency Distributions Suzanne Stevenson Rutgers Umverslty suzannecs rutgers edu Paola Merlo Umverslty of Geneva merlolettres unlge ch Natalia Kariaeva Rutgers Umverslty karlaeva@rcl rutgers edu Kamin Whitehouse Rutgers Umverslty kamlnwrcl rutgers edu Abstract Vve zeport a number of computatmnal experiments m supervised learning whose goal Is to automatmally classify a set of verbs into lexmal semanUc classes, based on frequency dlstnbutmn approxlmatmns of grammatical features extracted from a very large annotated corpus DlstnbuUons of five syntactic features that approximate tranmUvlty alternatmns and thematic role assignments are sufficient to reduce error rate by 56% over chance We conclude that corpus data is a usable repository of verb class mformatmn, and that corpusdriven extraction of grammaUcal features Is a promising methodology for automatm lexmal acqum,Uon 1 Introduction Recent years have witnessed a shift in grammar development methodology, from crafting large grammars, to annotation of corpora Correspondingly, there has been a change from developing rule-based parsers to developing statmUcal methods for reducing grammatmal knowledge from annotated corpus data The shift has mostly occurred because buildmg w~de-coverage grammars is ume-consummg, error prone, and difficult The same can be said for crafting the rich lexlcal representatmns that are a central component of hngmstlc knowledge, and research m automaUc lexmal acquisition has sought to address this ((Doff and Jones, 1996, Dorr, 1997), among others) Yet there have been few attempts to learn fine-grained lexical classifications from the statlsUcal analysis of dlstnbutmnal data, analogously to the induction of syntacUc knowledge (though see, e g, (Brent, 1993, Klavans and Chodorow, 1992, Resmk, 1992)) In this paper, we propose such a~ approach for the automaUc classfficauon of ~erbs into lexlcal semantic classes l We can express the Issues raised by this apploach as follows 1 Whmh hngulstlc dlstmcUons among \[exlcsl classes can we expect to find m a corpus ~ 2 How easily can we extract the frequency distributions that approximate the relevant hngmstlc properttes?
---------------------------------------------------
P99-1051:29	151:212	We also experimented with a method suggested by Brent (1993) which applies the binomial test on frame frequency data.
---------------------------------------------------
A97-1052:30	25:163	Preliminary experiments acquiring a few 356 verbal subcategorization classes have been reported by Brent (1991, 1993), Manning (1993), and Ushioda et al.
---------------------------------------------------
A97-1052:31	139:163	4 Related Work Brent's (1993) approach to acquiring subcategorization is based on a philosophy of only exploiting unambiguous and determinate information in unanalysed corpora.
---------------------------------------------------
A97-1052:32	156:163	Developing an analogous system for another language would be harder but not infeasible; similar taggers and parsers have been developed for a number of languages, but no extant subcategorization dictionaries exist to our knowledge, therefore the lexical statistics we utilize for statistical filtering would need to be estimated, perhaps using the technique described by Brent (1993).
---------------------------------------------------
A97-1052:33	80:163	The resulting set of putative classes for a predicate are filtered, following Brent (1993), 358 by hypothesis testing on binomial frequency data.
---------------------------------------------------
A97-1052:34	87:163	2.3 Discussion Our approach to acquiring subcategorization classes is predicated on the following assumptions:  most sentences will not allow the application of all possible rules of English complementation;  some sentences will be unambiguous even given the indeterminacy of the grammar4; 3Brent (1993:249-253) provides a detailed explanation and justification for the use of this measure.
---------------------------------------------------
C00-2100:35	136:139	We have also tried our methods on data which was automatically morphologically tagged which 696 Previous work (Ushioda et al. , 1993) (Brent, 1993) (Mmming, 1993) (Brent, 1994) (Ersan and Charniak, 1996) (Briscoe and Carroll, 1997) (CatToll and Rooth, 1998) Data POS + FS ntles raw + FS rules POS + FS rules raw + heuristics Full parsing Full parsing Unlabeled #SFs Current Work Fully Learned Parsed 137 6 33 6 193 19 3104 12 126 16 30 160 14 9+ 3 914 Method heuristics Hypothesis testing Miscue rate NA iterative estimation Corpus WNJ (300K) Brown ( 1.
---------------------------------------------------
C00-2100:36	14:139	Several techniques and results have been reported on learning subcategorization frames (SFs) from text corpora (Webster and Marcus, 1989; Brent, 1991; Brent, 1993; Brent, 1994; Ushioda et al. , 1993; Manning, 1993; Ersan and Charniak, 1996; Briscoe and Carroll, 1997; Carroll and Minnen, 1998; Carroll and Rooth, 1998).
---------------------------------------------------
C00-2100:37	49:139	This is the method used by several earlier papers on SF extraction starting with (Brent, 1991; Brent, 1993; Brent, 1994).
---------------------------------------------------
C00-2100:38	97:139	(Manning, 1993) applies Brent's method to parsed data and obtains a subcategorization dictionary for a larger set of verbs.
---------------------------------------------------
C00-2100:39	94:139	Brent (Brent, 1993; Brent, 1994) uses the standard method of testing miscue probabilities for filtering frames observed with a verb.
---------------------------------------------------
C00-2100:40	93:139	5 Comparison with related work Preliminary work on SF extraction from coq~ora was done by (Brent, 1991; Brunt, 1993; Brent, 1994) and (Webster and Marcus, 1989; Ushioda et al. , 1993).
---------------------------------------------------
W02-0905:41	9:189	Some of them induce syntactic subcategorisation from tagged texts (Brent, 1993; Briscoe and Carrol, 1997; Marques, 2000).
---------------------------------------------------
J94-4004:42	451:465	This investigation will benefit from the work of several researchers in the field of automatic lexicon construction, most notably, Brent (1993), Boguraev and Briscoe (1989), Boguraev and Pustejovsky (1990), Briscoe and Copestake (1990), Byrd et al.
---------------------------------------------------
C02-1013:43	59:218	Thus, Brent (1993) only creates hypotheses on the basis of instances of verb frames that are reliably and unambiguously cued by closed class items (such as pronouns) so there can be no other attachment possibilities.
---------------------------------------------------
W98-1114:44	19:161	Systems which are able to acquire a small number of verbal subcategorisation classes automatically from corpus text have been described by Brent (1991, 1993), and Ushioda et al.
---------------------------------------------------
W00-1325:45	17:178	Filtering is usually done with a hypothesis test, and frequently with a variation of the binomial filter introduced by Brent (1991, 1993).
---------------------------------------------------
W00-1325:46	14:178	The different approaches (e.g. Brent, !991, 1993; Ushioda et al. , 1993; Briscoe and Carroll, 1997; Manning, 1993; Carroll and Rooth, 1998; Gahl, 1998; Lapata, 1999; Sarkar and Zeman, 2000) vary largely according to the methods used and the number of SCFS being extracted.
---------------------------------------------------
W00-1325:47	25:178	According to one account (Briscoe and Carroll, 1997) the majority of errors arise because of the statistical filtering process, which is reported to be particularly unreliable for low frequency SCFs (Brent, 1993; Briscoe and Carroll, 1997; Manning, 1993; Manning and Schiitze, 1999).
---------------------------------------------------
W00-1325:48	67:178	Brent (1993) estimated the error probabilities for each SCF experimentally from the behaviour of his SCF extractor, which detected simple morpho-syntactic cues in the corpus data.
---------------------------------------------------
W00-1325:49	15:178	Regardless of this, there is a ceiling on the performance of these systems at around 80% token recall 1 zWhere token recall is the percentage.of SCF tokens in a sample of manually analysed text that were The approaches to extracting SCF information from corpora have frequently employed statistical methods for filtering (e.g. Brent, 1993; Manning 1993; Briscoe and Carroll, 1997; Lapata, 1999).
---------------------------------------------------
J98-2002:50	357:393	As we remarked earlier, however, the input data required by our method (triples) could be generated automatically from unparsed corpora making use of existing heuristic rules (Brent 1993; Smadja 1993), although for the experiments we report here we used a parsed corpus.
---------------------------------------------------
J98-2002:51	15:393	For the extraction problem, there have been various methods proposed to date, which are quite adequate (Hindle and Rooth 1991; Grishman and Sterling 1992; Manning 1992; Utsuro, Matsumoto, and Nagao 1992; Brent 1993; Smadja 1993; Grefenstette 1994; Briscoe and Carroll 1997).
---------------------------------------------------
P04-2007:52	23:136	In order to collect the frequency distributions of Spanish subcategorisation frames, we adapt a methodology that has been developed for English to the speci cities of the Spanish language ((Brent, 1993), (Manning, 1993), (Korhonen, 2002b)).
---------------------------------------------------
P95-1007:53	22:186	Brent (1993) has proposed the use of simple word patterns for the acquisition of verb subcategorisation information.
---------------------------------------------------
W98-1239:54	14:141	Other works describe systems that induce structures from corpora, but they use tagged corpora (Brill, 1993), or grammatical informations (Brent, 1993), or work with artificial samples (Elman, 1990).
---------------------------------------------------
