4.2 Learning Models We have experimented with the support vector machines (SVM) model6 and compared the results against two state-of-the-art models: a supervised model, Semantic Scattering (SS), (Moldovan and Badulescu, 2005), and a web-based unsupervised model (Lapata and Keller, 2004). 
In order to test their contribution to the task of semantic interpretation, prepositions and other linguistic clues are employed as features in a supervised, knowledgeintensive model.Furthermore, given a training set of English nominal phrases and compounds along with their translations in the ve Romance languages, our algorithm automatically learns classication rules and applies them to unseen test instances for semantic interpretation.As training and test data we used 3,124 Europarl and 2,023 CLUVI token instances.These instances were annotated with semantic relations and analyzed for inter-annotator agreement.The results are compared against two 187 Computational Linguistics Volume 35, Number 2 state-of-the-art approaches: a supervised machine learning model, semantic scattering (Moldovan and Badulescu 2005), and a Web-based unsupervised model (Lapata and Keller 2005).Moreover, we show that the Romanian linguistic features contribute more substantially to the overall performance than the features obtained for the other Romance languages.This is explained by the fact that the choice of the linguistic constructions (either genitive-marked N N or N P N) in Romanian is highly correlated with their meaning. 
4.3 Learning Models Several learning models can be used to provide the discriminating function f.We have experimented with the support vector machines model and compared the results against two state-of-the-art models: semantic scattering, a supervised model described in Moldovan et al.(2004), Girju et al.(2005), and Moldovan and Badulescu (2005), and Lapata and Kellers Web-based unsupervised model (Lapata and Keller 2005). 
4.2 Feature Space The set of features allows a supervised machine learning algorithm to induce a function that can be applied to accurately classify unseen instances.Based on the study of the instances and their semantic distribution presented in Section 3, we have identied and experimented with the following features presented subsequently for each language involved.Features F1F5 have been employed by us in our previous research (Moldovan et al.2004; Girju et al.2005; Girju, Badulescu, and Moldovan 2006).All the other features are novel. 
The results are compared against two state of the art approaches: a su568 pervised machine learning model, Semantic Scattering (Moldovan and Badulescu, 2005), and a webbased probabilistic model (Lapata and Keller, 2004). 
