Most ASR systems achieve Word Error Rates (WERs) of about 40-45% in realistic and uncontrolled lecture conditions (Leeuwis et al., 2003; Hsu and Glass, 2006).


Following (Hsu and Glass, 2006), we also consider features derived from the HMM-LDA word topic labels.1 Specifically, we compute the empirical probability t that the target word of the n-gram 1HMM-LDA is performed using 20 states and 50 topics with a 3rd-order HMM.


Hsu and Glass (2006) investigated using hidden Markov model with LDA to allow for both topic and style adaptation.


More recently LDA has also been used for unsupervised language model (LM) adaptation in the context of automatic speech recognition (ASR) (Hsu and Glass, 2006; Tam and Schultz, 2007; Heidel et al., 2007).


