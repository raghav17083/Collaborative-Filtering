We considered the three best-ranking WSD systems  GAMBL (Decadt et al. , 2004), SenseLearner (Mihalcea and Faruque, 2004), and Koc Table 4: Performance of WSD systems at Senseval-3 on coarse-grained sense inventories. 
An alternative solution to this second step was suggested in (Mihalcea and Faruque, 2004), using semantic generalizations learned from dependencies identified between nodes in a conceptual network. 
Each model was trained and tested on the Europarl and CLUVI corpora using a 7:3 trainingtesting ratio.All the test nouns were tagged with the corresponding sense in context using a state-of-the-art WSD tool (Mihalcea and Faruque 2004).The default semantic argument frame for each relation was used in the automatic identication of the argument positions. 
We had a significant improvement (p-value<0.05) over the baseline of 52.9%, a marginal improvement over the second best performer (SenseLearner) (Mihalcea and Faruque, 2004), and we were as good as the top performer (GAMBL) (Decadt et al. , 2004).7 System Precision Fraction of Recall Our system 61% 22% GAMBL 59.0% 21.3% SenseLearner 56.1% 20.2% Baseline 52.9% 19.1% Table 3. 
One reason for this choice was that memory based learning has shown to perform well in previous word sense disambiguation tasks, including some best performers in SENSEVAL, such as (Hoste et al. , 2001; Decadt et al. , 2004; Mihalcea and Faruque, 2004). 
