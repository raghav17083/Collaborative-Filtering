Our task has obvious relations to word sense disambiguation (Sanderson, 1997) (Leacock et al. , 1998), since both tasks are based on identifying senses of ambiguous words in a text. 
Many methods have been proposed to deal with this problem, including supervised learning algorithms (Leacock et al. , 1998), semi-supervised learning algorithms (Yarowsky, 1995), and unsupervised learning algorithms (Schutze, 1998). 
For our experiments, we used the implementation of WORDNET similarity and relatedness measures provided by Ted Pedersen.2 The following similarity measures were considered: two measures based on path lenghts between concepts (path and lch (Leacock et al., 1998)), three measures based on information content, i.e., corpus-based measures of the specificity of a concept (res (Resnik, 1999), lin (Lin, 1998), and jcn (Jiang and Conrath, 1997)). 
Inspired by the work of (Leacock et al., 1998), TSWEB was constructed using monosemous relatives from WN (synonyms, hypernyms, direct and indirect hyponyms, and siblings), querying Google and retrieving up to one thousand snippets per query (that is, a word sense), extracting the salient words with distinctive frequency using TFIDF. 
Despite its simplicity, Naive Bayes is claimed to obtain state-of-theart accuracy on supervised WSD in many papers (Mooney, 1996; Ng, 1997a; Leacock et al. , 1998). 
