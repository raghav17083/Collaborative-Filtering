The first approach (Teufel and Moens, 1997) uses a simple surface similarity measure (longest common subsequence of non-stop-list words) for matching abstract sentences with sentences from the source document. 
Several techniques for text summarization have been reported in the literature, including methods based on position (Edmundson, 1969; Hovy and Lin, 1997; Teufel and Moens, 1997), cue phrase (McKeown and Radev, 1995; Mahesh, 1997), word frequency (Teufel and Moens, 1997), and discourse segmentation (Boguraev and Kennedy, 1997). 
to linguistic units such as tokens, names, anaphora, etc. More recently, other approaches have investigated the utility of discourse structure (Marcu, 1997), the combination of information extraction and language generation (Klavans and Shaw, 1995; McKeown et al. , 1995), and using machine learning to find patterns in text (Teufel and Moens, 1997; Barzilay and Elhadad, 1997; Strzalkowski et al. , 1998). 
Many of these documents are likely to repeat much the same information, while differing in certain i Most of these were based on statistical techniques applied to various document entities; examples include frait, 1983; Kupiec et al. , 1995; Paice, 1990, Klavans and Shaw, 1995; MeKeown et al. , 1995; Shaw, 1995; Aon et al. , 1997; Boguraev and Kennedy, 1997; Hovy and Lin, 1997; Mitra et al. , 1997; Teufel and Moens, 1997; Barzilay and Elhadad, 1997; Carbonell and Goldstein, 1998; Baldwin and Mortbn, 1998; Radev and McKeown, 1998; Strzalkowski et al. , 1998). 
Previous approaches include supervised learning (Teufel and Moens, 1997), vectorial similarity computed between an initial abstract and sentences in the given document, or intra-document similarities (Salton et al. , 1997). 
