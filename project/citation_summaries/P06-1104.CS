We also tried the convolution tree kernel method (Zhang et al. , 2006a), using an SVM tree kernel package2. 
System P(%) R(%) F Linear Kernel 78.2 (77.2) 63.4 (60.7) 70.1 (68.0) Context-Sensitive Convolution Tree Kernel 81.1 (80.1) 66.7 (63.8) 73.2 (71.0) Composite Kernel 82.2 (80.8) 70.2 (68.4) 75.8 (74.1) Table 3: Performance of the compos ite kernel via polynomial interpolation on the major relation types of the ACE RDC 2003 (inside the parentheses) and 2004 (outside the parentheses) corpora Comparison with Other Systems ACE RDC 2003 P(%) R(%) F Ours: composite kernel 80.8 (65.2) 68.4 (54.9) 74.1 (59.6) Zhang et al (2006): composite kernel 77.3 (64.9) 65.6 (51.2) 70.9 (57.2) Ours: context-sensitive convolution tree kernel 80.1 (63.4) 63.8 (51.9) 71.0 (57.1) Zhang et al (2006): convolution tree kernel 76.1 (62.4) 62.6 (48.5) 68.7 (54.6) Bunescu et al (2005): shortest path dependency kernel 65.5 (-) 43.8 (-) 52.5 (-) Culotta et al (2004): dependency kernel 67.1 (-) 35.0 (-) 45.8 (-) Zhou et al. 
For the first time, in (Zhang et al., 2006a), this convolution tree kernel was used for relation extraction. 
Later, Zhang et al (2006) developed a composite kernel that combined parse tree kernel with entity kernel and Zhou et al (2007) experimented with a context-sensitive kernel by automatically determining context-sensitive tree spans. 
While kernel methods using the dependency tree (Culotta and Sorensen, 2004) and the shortest dependency path (Bunescu and Mooney, 2005) suffer from low recall performance, convolution tree kernels (Zhang et al., 2006; Zhou et al., 2007) over syntactic parse trees achieve comparable or even better performance than feature-based methods. 
