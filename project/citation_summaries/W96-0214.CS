2 Although Sima'an (1996) and Goodman (1996) also report experiments on unedited ATIS trees, their results do not refer to the most probable parse but to the most probable derivation and the maximum constituents parse respectively. 
1 The DOP1 model, and some variations of it, have been tested by Bod (1993-1995), Sima'an (1995-1996), Sekine & Grishman (1995), Goodman (1996), and Charniak (1996). 
The model I develop in this paper is true to these general DOP ideals, although it differs in important respects from the many DOP implementations that have been studied since its rst inception (Bod, 1993; Goodman, 1996; Bod, 1998; Simaan, 2002; Collins and Duffy, 2002; Bod et al. , 2003, and many others). 
We have used the technique outlined in this paper in other work (Goodman, 1996) to efficiently parse the DOP model; in that model, the only previously known algorithm which summed over all the 182 Criterion Label I Label Brack Cons Brack Cons Brack Algorithm Tree \] Recall Recall Recall Tree Label Tree 4.54~ 48.60% 60.98% 66.35% 12.07% Label Recall 3.71% 49.66~ 61.34% 68.39% 11.63% Bracket Recall 0.11% 4.51% 61.63~ 68.17% 11.19% Table 2: Grammar Induced by Counting: Three Algorithms Evaluated on Five Criteria possible derivations was a slow Monte Carlo algorithm (Bod, 1993). 
1 Goodman's approach is different from Bod (1993-1995) and Sima'an (1995) in that it returns best parses that cannot be generated by the DOP1 model (see Bod, 1996 for a reply to Goodman's paper). 
