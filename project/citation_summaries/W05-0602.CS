Given a training corpus of NL sentences annotated withtheircorrect MRs,thegoalofalearning system for semantic parsing is to induce an efficient and accurate semantic parser that can map novel sentences into their correct MRs. Several learning systems have been developed for semantic parsing, many of them recently (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Ge and Mooney, 2005; Kate and Mooney, 2006). 
Some of this work requires different levels of supervision, including labeled syntactic parse trees (Ge and Mooney, 2005; Ge and Mooney, 2006). 
Figure 6 shows the performance of WASP compared to four other algorithms: SILT (Kate et al. , 2005), COCKTAIL (Tang and Mooney, 2001), SCISSOR (Ge and Mooney, 2005) and Zettlemoyer and Collins (2005). 
622 Input: The root node N of a SAPT Predicate knowledge K Notation: XMR is the MR of node X Output: NMR Begin Ci= the ith child node of N Ch= GETsemanticHEAD(N) ChMR =BuildMR(Ch,K) for each other child Ci where inegationslash= h do CiMR =BuildMR(Ci,K) ComposeMR(ChMR,CiMR,K) end NMR=ChMR End Algorithm 1: BuildMR(N,K): Computing a logical form form an SAPT(Ge and Mooney, 2005) Input: S = (xi;yi;zi),i = 1,2,,l in which xi is1 the sentence and yi, zi is the pair of tree structure and its logical form Output: SSVM model2 repeat3 for i = 1 to n do4 5 SVMs1 : H(y,z)(1i(y),w)(zi,z) SVMs2 : H(y,z)(1i(y),w) radicalbig (zi,z) SVMm1 : H(y,z)((zi,z)i(y),w) SVMm2 : H(y,z)( radicalbig (zi,z)i(y),w) compute <y,z >= argmaxy,zY,Z H(Y,Z);6 compute i = max0,maxy,zSi H(y,z)};7 if H(y,z) >i + then8 SiSiy,z;9 solving optimization with SVM;10 end11 end12 until no Si has changed during iteration;13 Algorithm 2: Algorithm of SSVM learning for semantic parsing. 
1 Introduction Recent work in learning semantics has focused on mapping sentences to meaning representations (e.g., some logical form) given aligned sentence/meaning pairs as training data (Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Lu et al., 2008). 
