This is different from (Ng and Cardie, 2002a; Ng, 2004) where their anaphoricty models are trained independently of the coreference model, and it is either used as a pre-filter, or its output is used as features in the coreference model. 
As an improvement, Ng and Cardie (2002a) and Ng (2004) train a separate model to classify an anaphor as either anaphoric or non-anaphoric. 
581 Broadcast News Newspaper Newswire Approach to Anaphoricity Determination R P F R P F R P F 1 No Anaphoricity 57.7 52.6 55.0 60.8 62.6 61.7 59.1 58.1 58.6 2 Duplicated Ng and Cardie (2002a) 40.3 67.7 50.5 52.1 70.6 60.0 43.0 69.3 53.1 3 Duplicated Ng (2004) 51.9 63.2 57.0 60.0 63.8 61.9 59.3 57.7 58.5 4 Duplicated Luo (2007) 55.4 56.1 55.8 60.6 63.7 62.1 58.4 59.2 58.8 5 Duplicated Denis and Baldridge (2007) 57.3 55.1 56.2 63.8 63.7 63.8 60.4 59.3 59.8 6 Duplicated Finkel and Manning (2008) 56.4 55.3 55.8 63.8 63.7 63.8 59.7 59.2 59.5 7 Graph Minimum Cut 53.1 67.5 59.4 57.9 71.2 63.9 54.1 69.0 60.6 Table 1: MUC scores for the three ACE data sets. 
But there is a crucial difference: the starting model in (Luo et al. , 2004) is an ad-hoc use of the link scores and is not learned automatically, while Pc( jEt, mt) is fully trained. 
Ng (2004) improves recall by optimizing the anaphoricity threshold. 
