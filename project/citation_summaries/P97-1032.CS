To the best of our knowledge, this is the first tagging study that reaches a 98% accuracy level for a data-driven tagger (which must be distinguished from linguistically backuped taggers which come with heavy parsing machinery (Samuelsson and Voutilainen, 1997)). 
Comparing to other approaches, we see that our tagger performs better on the WSJ corpus and under the open vocabulary assumption, than a number of state-of-the-art POS tuggers, and similar to another approach based on the combination of several tuggers s. 8However, it has to be said that the pure statistical or machine-learning based approaches to POS tagging still significantly underperform some sophisticated manually constructed systems, such as the English shallow parser based on Constraint Grammars developed at the Helsinki University (Samuelsson and Voutilainen, 1997). 
Samuelsson and Voutilainen (1997), however, show significantly higher achievement of a rulebased tagger than that of statistical taggers for English text. 
For tagging, (Samuelsson and Voutilainen, 1997) have shown that a manually built tagger can equal a statistical tagger. 
Authors of such systems claim that handwritten systems can perform better than systems based on machine learning (Samuelsson and Voutilainen, 1997); however, except for the work cited, comparison is difficult to impossible due to the fact that they do not use the standard evaluation techniques (and not even the same data). 
