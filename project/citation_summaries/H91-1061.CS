We define the macro-averaged binary F-score over a set A = {a1,,aN} of N assessors as: F = summationtext aAFa N Where Fa is the binary F-score according to the vital/okay judgments of assessor a. The differences between the pyramid F-score and the macroaveraged binary F-score correspond to the distinction between microand macro-averaging discussed in the context of text classification (Lewis, 1991).


Following Turney and Littman (2005), we evaluate the performance by accuracy and also by the macroaveraged F measure (Lewis 1991).


We computed these measures as described in Lewis (1991).


Recent work includes discussion of appropriate statistical methods and metrics for spoken dialogue systems (Bates and Ayuso 1993; Danieli et al. 1992; Hirschman et al. 1990; Hirschman and Pao 1993; Simpson and Fraser 1993), information extraction systems (Lewis 1991; Chinchor, Hirschman, and Lewis 1993; Chinchor and Sundheim 1995), and tagging reliability (Carletta 1996).


Table 10 shows the results in terms of three overall measures: kappa, percentage accuracy, and macro-F (following Lewis [1991]).


