Others use expectation-maximization (EM) to search for the best probabilistic key using letter n-gram models (Knight et al., 2006). 
Methods such as these should also be useful for natural language decipherment problems such as character code conversion, phonetic decipherment, and word substitution ciphers with applications in machine translation (Knight et al., 2006). 
Following Knight et al (2006), we stretch out the P(j|e) model probabilities after decipherment training and prior to decoding our test set, by cubing their values. 
Our use of global key constraints also leads to accuracy that is superior to (Knight et al., 2006). 
Decipherment under the conditions of transliteration is substantially more difficult than solving letter-substitution ciphers (Knight et al., 2006; Ravi and Knight, 2008; Ravi and Knight, 2009) or phoneme-substitution ciphers (Knight and Yamada, 1999). 
