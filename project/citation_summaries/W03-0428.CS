We use a conditional Markov model (CMM) tagger (Klein et al. , 2003; Finkel et al. , 2005) to train two different models on the same data by splitting the feature set. 
Character n-gram based approach (Klein et al., 2003) using generative models, was experimented on English language and it proved to be useful over the word based models. 
The relevant algorithms include Maximum Entropy (Borthwick, 1999; Klein et al. , 2003), Hidden Markov Model (HMM) (Bikel et al. , 1999; Klein et al. , 2003), AdaBoost (Carreras et al. , 2003), Memorybased learning (Meulder and Daelemans, 2003), Support Vector Machine (Isozaki and Kazawa, 2002), Robust Risk Minimization (RRM) Classification method (Florian et al. , 2003), etc. For Chinese NER, most of the existing approaches use hand-crafted rules with word (or character) frequency statistics. 
Two more systems used them in combination with other techniques (Florian et al. , 2003; Klein et al. , 2003). 
2 System Description Our system is a Maximum Entropy Markov Model, which further develops a system earlier used for the CoNLL 2003 shared task (Klein et al. , 2003) and the 2004 BioCreative critical assessment of information extraction systems, a task that involved identifying gene and protein name mentions but not distinguishing between them (Dingare et al. , 2004). 
