Denis (2007) provides multi-metric scores for the JOINT-ILP model of Denis and Baldridge (2007a), which uses integer linear programming for joint inference over coreference resolution and discourse status: f-scores of 73.3%, 68.0%, and 58.9% for MUC, B3, and CEAF, respectively. 
Another advantage of the ranking approach is that its complexity is only square in the number of mentions, while that of the twin-candidate model is cubic (see Denis and Baldridge (2007b) for a more detailed comparison in the context of pronoun resolution). 
While early machine learning approaches for the task relied on local, discriminative classifiers (Soon et al., 2001; Ng and Cardie, 2002b; Morton, 2000; Kehler et al., 2004), more recent approaches use joint and/or global models (McCallum and Wellner, 2004; Ng, 2004; Daume III and Marcu, 2005; Denis and Baldridge, 2007a). 
By using joint inference for anaphoricity and coreference, Denis and Baldridge (2007a) avoid cascade-induced errors without the need to separately optimize the threshold. 
An interesting point of comparison is provided by Ng (2007), who also relies on true mentions and reports MUC fscores only slightly superior to ours (73.8%) while relying on perfect semantic class information. 
