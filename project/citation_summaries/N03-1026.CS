In a discriminative setting (Knight and Marcu 2002; Riezler et al. 2003; McDonald 2006), sentences are represented by a rich feature space (typically induced from parse trees) and the goal is to learn rewrite rules indicating which words should be deleted in a given context. 
Furthermore, we consider an F-score measure that is adapted from dependency-based parsing (Crouch et al. , 2002) and sentence-condensation (Riezler et al. , 2003). 
Previous datadriven approaches (Knight and Marcu, 2003; Riezler et al. , 2003) relied on parallel corpora to determine what is important in a sentence. 
Most approaches are supervised and require training data to learn which words or constituents can be dropped from a sentence (Riezler et al., 2003; McDonald, 2006). 
Our results show that grammatical relationsbased F-score (Riezler et al. 2003) correlates reliably with human judgements and could thus be used to measure compression performance automatically. 
