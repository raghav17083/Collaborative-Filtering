N07-1002:1	174:180	For example Gregory and Altun (2004) used acoustic features 3This result is comparable with the result of (Yuan et al. , 2005) who in their experiment with the same corpus report the best result as 83.9% using three features: unigram, bigram and backwards bigram probability.
---------------------------------------------------
N07-1002:2	71:180	Unfortunately these studies used different parts of the corpus or different labelings (Gregory and Altun, 2004; Yuan et al. , 2005), so our results are not directly comparable.
---------------------------------------------------
N07-1002:3	72:180	Bearing this difference in mind, the best reported results to our knowledge are those in (Gregory and Altun, 2004), where conditional random fields were used with both textual, acoustic, and oracle boundary features to yield 76.36% accuracy.
---------------------------------------------------
N07-1001:4	46:201	Prosody labeling on spontaneous speech corpora like Boston Directions corpus (BDC), Switchboard (SWBD) has garnered attention in (Hirschberg and Nakatani, 1996; Gregory and Altun, 2004).
---------------------------------------------------
N07-1001:5	47:201	Automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (Hirschberg, 1993; Wightman and Ostendorf, 1994; Ma et al. , 2003), rule-based systems (Shimei and McKeown, 1999), bagging and boosting on CART (Sun, 2002), hidden markov models (Conkie et al. , 1999), neural networks (Hasegawa-Johnson et al. , 2005),maximum-entropy models (Brenier et al. , 2005) and conditional random fields (Gregory and Altun, 2004).
---------------------------------------------------
I08-1029:6	33:136	We also consider the binary case of distinguishing accented from unaccented syllables, (Gregory and Altun, 2004; Rosenberg and Hirschberg, 2006; Ananthakrishnan and Narayanan, 2006).
---------------------------------------------------
I08-1029:7	43:136	While they can represent long term dependencies, most applications have employed first-order linear chains for language and speechprocessing tasksincludingPOS tagging, sentence boundary detection (Liu et al., 2005), and even text-oriented pitch accent prediction(Gregory and Altun, 2004).
---------------------------------------------------
I08-1029:8	16:136	These approaches explored a range of machine learning techniques from local classifiers such as decision trees (Sun, 2002)andRIPPER(PanandMcKeown, 1998)tosequence models such as Conditional Random Fields 217 (CRFs)(Gregory and Altun, 2004) more recently.
---------------------------------------------------
I08-1029:9	57:136	In particular, in contrast to (Gregory and Altun, 2004), we employ a rich acoustic feature set, designed to capture and compensate for coarticulatory influences on accent realization, in addition to word-based features.
---------------------------------------------------
