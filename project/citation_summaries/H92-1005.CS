The objective metrics that have been used to evaluate a dialog as a whole include (Abella, Brown, and Buntschuh, 1996; Ciaremella, 1993; Danieli and Gerbino, 1995; Hirschman et al. , 1990; Hirschman et al. , 1993; Polifroni et al. , 1992; Price et al. , 1992; Smith and Hipp, 1994; Smith and Gordon, 1997; Walker, 1996):  percentage of correct answers with respect to a set of reference answers  transaction success, task completion, or quality of solution  number of turns or utterances;  dialogue time or task completion time  mean user response time  mean system response time  frequency of diagnostic error messages  percentage of "non-trivial" (more than one word) utterances. 
1 Introduction The notion of a cooperative response has been the focus of considerable research in natural language and spoken dialogue systems (Allen and Perrault, 1980; Mays, 1980; Kaplan, 1981; Joshi et al., 1984; McCoy, 1989; Pao and Wilpon, 1992; Moore, 1994; Seneff et al., 1995; Goddeau et al., 1996; Pieraccini et al., 1997). 
Subjects, Scenarios, Instructions Data collection will proceed as described in Shriberg et al. 1992 \[16\] with the following exceptions: (1) updated versions of the SRI Template Matcher and recognizer will be used; (2) subjects will use a new data collection facility (the room is smaller and has no window but is acoustically similar to the room used previously); (3) the scenarios to be solved have unique solutions; (4) the debriefing questionnalre will be a merged version of the questions used on debriefing questionnaires at SRI and at MIT in separate experiments; and (5) each subject will solve two scenarios, one using the SRI SLS and one using the SRI/MIT hybrid SLS. 
User satisfaction ratings (Kamm, 1995; Shriberg, Wade, and Price, 1992; Polifroni et al. , 1992) have been frequently used in the literature as an external indicator of the usability of a dialogue agent. 
Evaluation methods independent of dialogue strategy have focused on measuring the extent to which systems for interactive problem solving aid users via log-file evaluations (Polifroni et al. , 1992), quantifying repair attempts via turn correction ratio, tracking user detection and correction of system errors (Hirschman and Pao, 1993), and considering transaction success (Shriberg et al. , 1992). 
